{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to IronCore Documentation","text":"<p>IronCore is an open-source platform designed to empower users with robust infrastructure management and bare metal  automation. Built with flexibility and scalability in mind, IronCore combines two powerful layers to streamline  your computing needs: an Infrastructure as a Service (IaaS) layer and a Bare Metal Automation layer. Whether  you're managing cloud-like resources or maintaining physical servers, IronCore has you covered.</p>"},{"location":"#overview","title":"Overview","text":"<p>IronCore bridges the gap between virtualized infrastructure and physical hardware management, offering a unified  solution for developers, system administrators, and enterprises. Explore the two core layers below to see how IronCore can transform your workflows.</p>"},{"location":"#ironcore-architecture","title":"IronCore Architecture","text":"<p>Here\u2019s a visual representation of IronCore\u2019s two layers:</p> <p>Infrastructure as a Service (IaaS)</p> <pre><code>graph TD\n    A[\"Infrastructure as a Service (IaaS)\"]\n\n    A --&gt; D[Compute]\n    A --&gt; E[Networking]\n    A --&gt; F[Storage]\n\n    D --&gt;|Virtual Machines| J[Workloads]\n    E --&gt;|Virtual Networks| K[Connectivity]\n    F --&gt;|Block/Object/File| L[Data]</code></pre> <p>Bare Metal Automation</p> <pre><code>graph TD\n    A[\"Bare Metal Automation\"] \n\n    A --&gt; G[Server Provisioning]\n    A --&gt; H[Day 2 Operations]\n    A --&gt; I[Lifecycle Management]\n\n    G --&gt;|Discovery &amp; Deployment| M[Servers]\n    H --&gt;|BIOS/Firmware Updates| N[Maintenance]\n    I --&gt;|Health Monitoring| O[Reliability]</code></pre>"},{"location":"#infrastructure-as-a-service-iaas","title":"Infrastructure as a Service (IaaS)","text":"<p>The IaaS layer provides a flexible, user-friendly environment to create and manage Compute, Networking, and  Storage resources. With IronCore, you can:</p> <ul> <li>Compute: Spin up virtual machines or containers tailored to your workload needs.</li> <li>Networking: Configure virtual networks, load balancers, and firewalls with ease.</li> <li>Storage: Provision scalable block, object, or file storage to suit your applications.</li> </ul> <p>Designed for simplicity and power, this layer abstracts the complexity of resource management, giving you cloud-like  control at your fingertips.</p> <p>Get Started with IaaS | API Reference</p>"},{"location":"#bare-metal-automation","title":"Bare Metal Automation","text":"<p>The Bare Metal Automation layer takes server management to the next level, handling everything from provisioning to ongoing maintenance. Key features include:</p> <ul> <li>Server Provisioning: Automate the discovery, configuration, and deployment of bare metal servers.</li> <li>Day 2 Operations: Simplify maintenance tasks like OS updates, BIOS/firmware upgrades, and hardware diagnostics.</li> <li>Lifecycle Management: Monitor and manage server health, ensuring peak performance and reliability.</li> </ul> <p>This layer is perfect for those who need fine-grained control over physical hardware without sacrificing automation.</p> <p>Get Started with Bare Metal Automation | API Reference</p>"},{"location":"#why-ironcore","title":"Why IronCore?","text":"<ul> <li>Open Source: Fully transparent, community-driven, and free to use.</li> <li>Dual-Layer Design: Seamlessly integrate IaaS and bare metal management in one platform. Or use them independently.</li> <li>Scalable: From small deployments to enterprise-grade clusters, IronCore grows with you.</li> </ul>"},{"location":"#get-involved","title":"Get Involved","text":"<ul> <li>GitHub Repository: Explore the code, report issues, or submit pull requests.</li> </ul>"},{"location":"baremetal/getting-started/","title":"Baremetal Management","text":"<p>TODO:</p> <ul> <li>Give an overview of the baremetal management capabilities of IronCore.</li> </ul>"},{"location":"baremetal/architecture/discovery/","title":"Discovery Boot","text":"<p>TODO:</p> <ul> <li>Describe the discovery boot process</li> <li>Describe the role of the discovery image/metalprobe</li> </ul>"},{"location":"baremetal/architecture/maintenance/","title":"Server Maintenance","text":"<p>TODO:</p> <ul> <li>Describe the maintenance process</li> <li>Describe the extension points here</li> </ul>"},{"location":"baremetal/architecture/overview/","title":"Bare Metal Automation","text":"<p>TODO:</p> <ul> <li>Important: A lot of this is already described in the <code>metal-operator</code> documentation. (cross ref)</li> <li>Give an overview over the bare metal automation</li> <li>What are the core aspects here</li> <li>Describe the role of FeDHCP/ipam, boot and metal operator</li> </ul>"},{"location":"baremetal/architecture/provisioning/","title":"Server Provisioning","text":"<p>TODO: </p> <ul> <li>Describe the provisioning process</li> <li>Describe the components involved</li> </ul>"},{"location":"baremetal/operations-guide/landscape-setup/","title":"Landscape Setup","text":"<p>TODO:</p> <ul> <li>Describe pre-requisites needed for bootstrapping the bare metal automation</li> <li>Describe the deployment process (where to install what)</li> <li>Highlight configuration details in the metal and boot operator</li> </ul>"},{"location":"baremetal/operations-guide/overview/","title":"Operations Guide","text":"<p>This guide provides operational instructions for system operators, covering deployment, maintenance, and troubleshooting of the IronCore project.</p>"},{"location":"baremetal/operations-guide/overview/#topics","title":"Topics","text":"<ul> <li>Deployment procedures</li> <li>Routine maintenance tasks</li> <li>Monitoring &amp; alerts</li> </ul> <p>For more detailed troubleshooting information, refer to the Troubleshooting section.</p>"},{"location":"baremetal/troubleshooting/","title":"Troubleshooting","text":"<p>This section provides answers to common issues and FAQs about the IronCore project.</p>"},{"location":"baremetal/upgrade-guide/","title":"Upgrade Guide","text":"<p>This Upgrade Guide provides step-by-step instructions for updating component repositories to ensure seamless integration across the IronCore project.</p>"},{"location":"baremetal/user-guide/","title":"User Guide","text":"<p>This guide is designed to help end-users understand and effectively use the IronCore project.</p>"},{"location":"contribute/contributing/","title":"Contributing to IronCore Documentation","text":"<p>We welcome contributions from the community! Follow these guidelines to help us maintain high-quality, consistent documentation.</p>"},{"location":"contribute/contributing/#how-to-contribute","title":"How to Contribute","text":"<ol> <li>Fork the repository and create a new branch.</li> <li>Make your changes following the Style Guide.</li> <li>Submit a pull request with a clear description of your changes.</li> </ol>"},{"location":"contribute/contributing/#code-review","title":"Code Review","text":"<ul> <li>All contributions will be reviewed for clarity, accuracy, and consistency.</li> <li>Feedback will be provided if any adjustments are necessary.</li> </ul> <p>Thank you for helping improve our documentation!</p>"},{"location":"contribute/style-guide/","title":"Documentation Style Guide","text":"<p>This style guide outlines the standards for writing and formatting documents for the IronCore project.</p>"},{"location":"developer-guide/","title":"Developer Guide","text":"<p>This guide covers setup, coding conventions, and contribution guidelines for IronCore developers.</p>"},{"location":"iaas/getting-started/","title":"Getting Started with IronCore (IaaS)","text":"<p>TODO:</p> <ul> <li>usage of ironcore-in-a-box</li> <li>followup links to operations guide and cluster setup</li> </ul>"},{"location":"iaas/architecture/networking/","title":"Networking","text":"<p>TODO:</p> <ul> <li>Describe how networking is done in IronCore</li> <li>Describe the role of ironcore-net</li> <li>Describe the role of metalnet and dpservice</li> <li>Describe the role of metalbond</li> <li>Describe how they all interact with each other (image)</li> </ul>"},{"location":"iaas/architecture/os-images/","title":"Operating System Images","text":"<p>TODO:</p> <ul> <li>Describe the concept of OS images</li> <li>Describe the usage of OCI</li> <li>Describe the OCI image format</li> </ul>"},{"location":"iaas/architecture/overview/","title":"IaaS Architecture","text":"<p>The Infrastructure as a Service (IaaS) layer of IronCore is a modular and scalable system designed to manage compute, networking, and storage resources efficiently. This page provides an in-depth overview of the core components that  make up the IaaS layer, their roles, and how they interact to deliver a seamless infrastructure management experience.</p>"},{"location":"iaas/architecture/overview/#architecture-overview","title":"Architecture Overview","text":"<p>The IaaS layer of IronCore is composed of several interconnected components, each responsible for a specific aspect  of infrastructure management. The following diagram illustrates the architecture:</p> <pre><code>%%{\n  init: {\n    \"theme\": \"neutral\",\n    \"fontFamily\": \"monospace\",\n    \"logLevel\": \"info\",\n    \"flowchart\": {\n      \"htmlLabels\": true,\n      \"curve\": \"linear\"\n    },\n    \"sequence\": {\n      \"mirrorActors\": true\n    }\n  }\n}%%\nblock-beta\n    block:ID\n        columns 2\n        A[\"ironcore\"]\n        B[\"ironcore-net\"]\n        C[\"metalnet + dpservice\"]\n        D[\"metalbond\"]\n        E[\"libvirt-provider\"]\n        F[\"ceph-provider\"]\n    end</code></pre>"},{"location":"iaas/architecture/overview/#core-components","title":"Core Components","text":"<ul> <li> <p>IronCore   IronCore is the central component of the IaaS layer, implemented as an aggregated Kubernetes API server. It provides    a declarative, Kubernetes-style API for managing compute, networking, and storage resources. Through its scheduler,    poollets, and broker components, IronCore orchestrates resource allocation and coordination, ensuring that resources    are efficiently distributed and utilized across the infrastructure. By leveraging Kubernetes' API extension    mechanisms, IronCore offers a familiar and powerful interface for infrastructure management, serving as the backbone    of the IaaS layer.</p> </li> <li> <p>IronCore-Net   IronCore-Net is the global networking control plane for IronCore. It provides centralized management of networking    resources, enabling other components to request public IP addresses, LoadBalancer instances, or NatGateways.    IronCore-Net ensures consistent and scalable network operations, making it a critical component for global    connectivity within the platform.</p> </li> <li> <p>Metalnet + DPService   Metalnet and DPService together form the low-level Software-Defined Networking (SDN) implementation. They leverage    the DPDK (Data Plane Development Kit) framework to deliver high-performance networking. Additionally, these    components support hardware offloading of packet filtering to a Data Processing Unit (DPU), optimizing network    traffic handling and improving overall performance.</p> </li> <li> <p>MetalBond   MetalBond is a route reflector responsible for distributing routes across hypervisor nodes. It also manages routes    announced to the outside world, ensuring efficient and reliable network connectivity. By handling route distribution,    MetalBond enables seamless communication between internal resources and external networks.</p> </li> <li> <p>Libvirt-Provider   The Libvirt-Provider is the hypervisor manager that interacts with Libvirt to create and manage virtual machines on    hypervisor hosts. It uses Libvirt/QEMU to handle the lifecycle of virtual machines, providing a robust compute    foundation for the IaaS layer. This component ensures that compute resources are effectively provisioned and managed.</p> </li> <li> <p>Ceph-Provider   The Ceph-Provider is responsible for managing block and object storage by interfacing with a Ceph cluster. It enables    the provisioning of scalable storage resources for applications, supporting both block and object storage needs.    Importantly, IronCore does not manage the Ceph cluster itself\u2014it makes no assumptions about how or where the Ceph    cluster is installed and operated, offering flexibility in storage deployment.</p> </li> </ul>"},{"location":"iaas/architecture/overview/#how-it-works-together","title":"How It Works Together","text":"<p>The components of the IaaS layer work in tandem to provide a cohesive infrastructure management experience:</p> <ul> <li>IronCore orchestrates the overall system, using its scheduler and broker to allocate resources efficiently.</li> <li>IronCore-Net and Metalnet + DPService handle networking, providing both global control and low-level SDN    capabilities, with MetalBond ensuring proper route distribution.</li> <li>Libvirt-Provider manages compute resources by interfacing with Libvirt/QEMU to deploy and manage virtual machines.</li> <li>Ceph-Provider integrates with a Ceph cluster to provision and manage storage resources, offering flexibility    for various storage needs.</li> </ul> <p>This modular design allows each component to operate independently while integrating seamlessly, enabling IronCore to  scale from small deployments to large, enterprise-grade clusters.</p>"},{"location":"iaas/architecture/overview/#next-steps","title":"Next Steps","text":"<p>TODO: define next steps for users to explore the IaaS layer further.</p> <ul> <li>Learn how to set up the IaaS layer: Get Started with IaaS</li> <li>Explore the APIs for managing resources: API Reference</li> <li>Dive into networking configurations: Networking Guide</li> <li>Understand storage integration: Storage Guide</li> </ul>"},{"location":"iaas/architecture/scheduling/","title":"Scheduling and Orchestration","text":"<p>TODO:</p> <ul> <li>Describe the pool concept</li> <li>Describe the scheduling process</li> <li>Describe the broker concept</li> <li>Next chapters to read: Runtime Interface</li> </ul>"},{"location":"iaas/architecture/providers/compute/","title":"Machine Runtime Interface","text":"<p>TODO:</p> <ul> <li>What is the Machine Runtime Interface?</li> <li>Next read: libvirt-provider</li> </ul>"},{"location":"iaas/architecture/providers/overview/","title":"Provider Concept","text":"<p>TODO: </p> <ul> <li>Describe the provider concept in IronCore</li> <li>Describe how the various RuntimeInterface are implemented</li> <li>Next read: RuntimeInterface</li> </ul>"},{"location":"iaas/architecture/providers/runtime-interface/","title":"IronCore Runtime Interface (IRI)","text":"<p>TODO:</p> <ul> <li>Descibe the IronCore Runtime Interface (IRI) concept and why we need it</li> <li>Describe how it is implemented </li> <li>Next read: compute and storage provider</li> </ul>"},{"location":"iaas/architecture/providers/storage/","title":"Volume and Bucket Runtime Interface","text":"<p>TODO:</p> <ul> <li>Describe the Volume Runtime Interface (VRI) concept and why we need it</li> <li>Describe the Bucket Runtime Interface (BRI) concept and why we need it</li> <li>Next read: ceph-provider</li> </ul>"},{"location":"iaas/operations-guide/landscape-setup/","title":"Landscape Setup","text":"<p>TODO:</p> <ul> <li>Describe various landscape setup options</li> </ul>"},{"location":"iaas/operations-guide/overview/","title":"Operator Guide","text":"<p>This guide provides operational instructions for system operators, covering deployment, maintenance, and troubleshooting of the IronCore project.</p>"},{"location":"iaas/operations-guide/overview/#topics","title":"Topics","text":"<ul> <li>Deployment procedures</li> <li>Routine maintenance tasks</li> <li>Monitoring &amp; alerts</li> </ul> <p>For more detailed troubleshooting information, refer to the Troubleshooting section.</p>"},{"location":"iaas/troubleshooting/","title":"Troubleshooting","text":"<p>This section provides answers to common issues and FAQs about the IronCore project.</p>"},{"location":"iaas/upgrade-guide/","title":"Upgrade Guide","text":"<p>This Upgrade Guide provides step-by-step instructions for updating component repositories to ensure seamless integration across the IronCore project.</p>"},{"location":"iaas/user-guide/","title":"User Guide","text":"<p>This guide is designed to help end-users understand and effectively use the IronCore project.</p>"},{"location":"releases/","title":"Releases","text":"<p>This section documents the version history and release notes for the IronCore project and its components.</p>"},{"location":"roadmap/","title":"Roadmap","text":"<p>This document outlines the future plans and roadmap for the IronCore project.</p>"},{"location":"support/","title":"Support","text":"<ol> <li>Make sure you've read understanding the basics and the getting started guide.</li> <li>Looked for an answer in the troubleshooting.</li> <li>Check the issue tracker of the respective component repository for existing issues.</li> <li>Report a bug or request a feature through the issue tracker of the respective component repository.</li> </ol>"},{"location":"infrastructure-as-a-service/components/ironcore/","title":"IronCore Documentation","text":"<p>This page contains the documentation of the ironcore project which is part  of the ironcore-dev organization.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/common/","title":"Common","text":"<p>Packages:</p> <ul> <li> common.ironcore.dev/v1alpha1 </li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/common/#common.ironcore.dev/v1alpha1","title":"common.ironcore.dev/v1alpha1","text":"<p>Package v1alpha1 is the v1alpha1 version of the API.</p> <p>Resource Types:</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/common/#common.ironcore.dev/v1alpha1.ConfigMapKeySelector","title":"ConfigMapKeySelector","text":"<p>ConfigMapKeySelector is a reference to a specific \u2018key\u2019 within a ConfigMap resource. In some instances, <code>key</code> is a required field.</p> Field Description <code>name</code>  string  <p>Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names</p> <code>key</code>  string  (Optional) <p>The key of the entry in the ConfigMap resource\u2019s <code>data</code> field to be used. Some instances of this field may be defaulted, in others it may be required.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/common/#common.ironcore.dev/v1alpha1.IP","title":"IP","text":"<p> (Appears on:IPRange) </p> <p>IP is an IP address.</p> Field Description <code>-</code>  net/netip.Addr"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/common/#common.ironcore.dev/v1alpha1.IPPrefix","title":"IPPrefix","text":"<p>IPPrefix represents a network prefix.</p> Field Description <code>-</code>  net/netip.Prefix"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/common/#common.ironcore.dev/v1alpha1.IPRange","title":"IPRange","text":"<p>IPRange is an IP range.</p> Field Description <code>from</code>  IP  <code>to</code>  IP"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/common/#common.ironcore.dev/v1alpha1.LocalUIDReference","title":"LocalUIDReference","text":"<p>LocalUIDReference is a reference to another entity including its UID</p> Field Description <code>name</code>  string  <p>Name is the name of the referenced entity.</p> <code>uid</code>  k8s.io/apimachinery/pkg/types.UID  <p>UID is the UID of the referenced entity.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/common/#common.ironcore.dev/v1alpha1.SecretKeySelector","title":"SecretKeySelector","text":"<p>SecretKeySelector is a reference to a specific \u2018key\u2019 within a Secret resource. In some instances, <code>key</code> is a required field.</p> Field Description <code>name</code>  string  <p>Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names</p> <code>key</code>  string  (Optional) <p>The key of the entry in the Secret resource\u2019s <code>data</code> field to be used. Some instances of this field may be defaulted, in others it may be required.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/common/#common.ironcore.dev/v1alpha1.Taint","title":"Taint","text":"<p>The resource pool this Taint is attached to has the \u201ceffect\u201d on any resource that does not tolerate the Taint.</p> Field Description <code>key</code>  string  <p>The taint key to be applied to a resource pool.</p> <code>value</code>  string  <p>The taint value corresponding to the taint key.</p> <code>effect</code>  TaintEffect  <p>The effect of the taint on resources that do not tolerate the taint. Valid effects are NoSchedule, PreferNoSchedule and NoExecute.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/common/#common.ironcore.dev/v1alpha1.TaintEffect","title":"TaintEffect (<code>string</code> alias)","text":"<p> (Appears on:Taint, Toleration) </p> Value Description <p>\"NoSchedule\"</p> <p>Do not allow new resources to schedule onto the resource pool unless they tolerate the taint, but allow all already-running resources to continue running. Enforced by the scheduler.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/common/#common.ironcore.dev/v1alpha1.Toleration","title":"Toleration","text":"<p>The resource this Toleration is attached to tolerates any taint that matches the triple  using the matching operator . Field Description <code>key</code>  string  <p>Key is the taint key that the toleration applies to. Empty means match all taint keys. If the key is empty, operator must be Exists; this combination means to match all values and all keys.</p> <code>operator</code>  TolerationOperator  <p>Operator represents a key\u2019s relationship to the value. Valid operators are Exists and Equal. Defaults to Equal. Exists is equivalent to wildcard for value, so that a resource can tolerate all taints of a particular category.</p> <code>value</code>  string  <p>Value is the taint value the toleration matches to. If the operator is Exists, the value should be empty, otherwise just a regular string.</p> <code>effect</code>  TaintEffect  <p>Effect indicates the taint effect to match. Empty means match all taint effects. When specified, allowed values are NoSchedule.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/common/#common.ironcore.dev/v1alpha1.TolerationOperator","title":"TolerationOperator (<code>string</code> alias)","text":"<p> (Appears on:Toleration) </p> <p>A toleration operator is the set of operators that can be used in a toleration.</p> Value Description <p>\"Equal\"</p> <p>\"Exists\"</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/common/#common.ironcore.dev/v1alpha1.UIDReference","title":"UIDReference","text":"<p>UIDReference is a reference to another entity in a potentially different namespace including its UID.</p> Field Description <code>namespace</code>  string  <p>Namespace is the namespace of the referenced entity. If empty, the same namespace as the referring resource is implied.</p> <code>name</code>  string  <p>Name is the name of the referenced entity.</p> <code>uid</code>  k8s.io/apimachinery/pkg/types.UID  <p>UID is the UID of the referenced entity.</p> <p> Generated with <code>gen-crd-api-reference-docs</code> </p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/compute/","title":"Compute","text":"<p>Packages:</p> <ul> <li> compute.ironcore.dev/v1alpha1 </li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/compute/#compute.ironcore.dev/v1alpha1","title":"compute.ironcore.dev/v1alpha1","text":"<p>Package v1alpha1 is the v1alpha1 version of the API.</p> <p>Resource Types:</p> <ul><li> Machine </li><li> MachineClass </li><li> MachinePool </li></ul>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/compute/#compute.ironcore.dev/v1alpha1.Machine","title":"Machine","text":"<p>Machine is the Schema for the machines API</p> Field Description <code>apiVersion</code> string <code> compute.ironcore.dev/v1alpha1 </code> <code>kind</code> string  <code>Machine</code> <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>spec</code>  MachineSpec  <code>machineClassRef</code>  Kubernetes core/v1.LocalObjectReference  <p>MachineClassRef is a reference to the machine class/flavor of the machine.</p> <code>machinePoolSelector</code>  map[string]string  <p>MachinePoolSelector selects a suitable MachinePoolRef by the given labels.</p> <code>machinePoolRef</code>  Kubernetes core/v1.LocalObjectReference  <p>MachinePoolRef defines machine pool to run the machine in. If empty, a scheduler will figure out an appropriate pool to run the machine in.</p> <code>power</code>  Power  <p>Power is the desired machine power state. Defaults to PowerOn.</p> <code>image</code>  string  (Optional) <p>Image is the optional URL providing the operating system image of the machine.</p> <code>imagePullSecret</code>  Kubernetes core/v1.LocalObjectReference  <p>ImagePullSecretRef is an optional secret for pulling the image of a machine.</p> <code>networkInterfaces</code>  []NetworkInterface  (Optional) <p>NetworkInterfaces define a list of network interfaces present on the machine</p> <code>volumes</code>  []Volume  (Optional) <p>Volumes are volumes attached to this machine.</p> <code>ignitionRef</code>  github.com/ironcore-dev/ironcore/api/common/v1alpha1.SecretKeySelector  <p>IgnitionRef is a reference to a secret containing the ignition YAML for the machine to boot up. If key is empty, DefaultIgnitionKey will be used as fallback.</p> <code>efiVars</code>  []EFIVar  (Optional) <p>EFIVars are variables to pass to EFI while booting up.</p> <code>tolerations</code>  []github.com/ironcore-dev/ironcore/api/common/v1alpha1.Toleration  <p>Tolerations define tolerations the Machine has. Only MachinePools whose taints covered by Tolerations will be considered to run the Machine.</p> <code>status</code>  MachineStatus"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/compute/#compute.ironcore.dev/v1alpha1.MachineClass","title":"MachineClass","text":"<p>MachineClass is the Schema for the machineclasses API</p> Field Description <code>apiVersion</code> string <code> compute.ironcore.dev/v1alpha1 </code> <code>kind</code> string  <code>MachineClass</code> <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>capabilities</code>  github.com/ironcore-dev/ironcore/api/core/v1alpha1.ResourceList"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/compute/#compute.ironcore.dev/v1alpha1.MachinePool","title":"MachinePool","text":"<p>MachinePool is the Schema for the machinepools API</p> Field Description <code>apiVersion</code> string <code> compute.ironcore.dev/v1alpha1 </code> <code>kind</code> string  <code>MachinePool</code> <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>spec</code>  MachinePoolSpec  <code>providerID</code>  string  <p>ProviderID identifies the MachinePool on provider side.</p> <code>taints</code>  []github.com/ironcore-dev/ironcore/api/common/v1alpha1.Taint  <p>Taints of the MachinePool. Only Machines who tolerate all the taints will land in the MachinePool.</p> <code>status</code>  MachinePoolStatus"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/compute/#compute.ironcore.dev/v1alpha1.DaemonEndpoint","title":"DaemonEndpoint","text":"<p> (Appears on:MachinePoolDaemonEndpoints) </p> <p>DaemonEndpoint contains information about a single Daemon endpoint.</p> Field Description <code>port</code>  int32  <p>Port number of the given endpoint.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/compute/#compute.ironcore.dev/v1alpha1.EFIVar","title":"EFIVar","text":"<p> (Appears on:MachineSpec) </p> <p>EFIVar is a variable to pass to EFI while booting up.</p> Field Description <code>name</code>  string  <p>Name is the name of the EFIVar.</p> <code>uuid</code>  string  <p>UUID is the uuid of the EFIVar.</p> <code>value</code>  string  <p>Value is the value of the EFIVar.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/compute/#compute.ironcore.dev/v1alpha1.EmptyDiskVolumeSource","title":"EmptyDiskVolumeSource","text":"<p> (Appears on:VolumeSource) </p> <p>EmptyDiskVolumeSource is a volume that\u2019s offered by the machine pool provider. Usually ephemeral (i.e. deleted when the surrounding entity is deleted), with varying performance characteristics. Potentially not recoverable.</p> Field Description <code>sizeLimit</code>  k8s.io/apimachinery/pkg/api/resource.Quantity  <p>SizeLimit is the total amount of local storage required for this EmptyDisk volume. The default is nil which means that the limit is undefined.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/compute/#compute.ironcore.dev/v1alpha1.EphemeralNetworkInterfaceSource","title":"EphemeralNetworkInterfaceSource","text":"<p> (Appears on:NetworkInterfaceSource) </p> <p>EphemeralNetworkInterfaceSource is a definition for an ephemeral (i.e. coupled to the lifetime of the surrounding object) networking.NetworkInterface.</p> Field Description <code>networkInterfaceTemplate</code>  github.com/ironcore-dev/ironcore/api/networking/v1alpha1.NetworkInterfaceTemplateSpec  <p>NetworkInterfaceTemplate is the template definition of the networking.NetworkInterface.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/compute/#compute.ironcore.dev/v1alpha1.EphemeralVolumeSource","title":"EphemeralVolumeSource","text":"<p> (Appears on:VolumeSource) </p> <p>EphemeralVolumeSource is a definition for an ephemeral (i.e. coupled to the lifetime of the surrounding object) storage.Volume.</p> Field Description <code>volumeTemplate</code>  github.com/ironcore-dev/ironcore/api/storage/v1alpha1.VolumeTemplateSpec  <p>VolumeTemplate is the template definition of the storage.Volume.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/compute/#compute.ironcore.dev/v1alpha1.MachineExecOptions","title":"MachineExecOptions","text":"<p>MachineExecOptions is the query options to a Machine\u2019s remote exec call</p> Field Description <code>insecureSkipTLSVerifyBackend</code>  bool"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/compute/#compute.ironcore.dev/v1alpha1.MachinePoolAddress","title":"MachinePoolAddress","text":"<p> (Appears on:MachinePoolStatus) </p> Field Description <code>type</code>  MachinePoolAddressType  <code>address</code>  string"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/compute/#compute.ironcore.dev/v1alpha1.MachinePoolAddressType","title":"MachinePoolAddressType (<code>string</code> alias)","text":"<p> (Appears on:MachinePoolAddress) </p> Value Description <p>\"ExternalDNS\"</p> <p>MachinePoolExternalDNS identifies a DNS name which resolves to an IP address which has the characteristics of MachinePoolExternalIP. The IP it resolves to may or may not be a listed MachineExternalIP address.</p> <p>\"ExternalIP\"</p> <p>MachinePoolExternalIP identifies an IP address which is, in some way, intended to be more usable from outside the cluster than an internal IP, though no specific semantics are defined.</p> <p>\"Hostname\"</p> <p>MachinePoolHostName identifies a name of the machine pool. Although every machine pool can be assumed to have a MachinePoolAddress of this type, its exact syntax and semantics are not defined, and are not consistent between different clusters.</p> <p>\"InternalDNS\"</p> <p>MachinePoolInternalDNS identifies a DNS name which resolves to an IP address which has the characteristics of a MachinePoolInternalIP. The IP it resolves to may or may not be a listed MachinePoolInternalIP address.</p> <p>\"InternalIP\"</p> <p>MachinePoolInternalIP identifies an IP address which may not be visible to hosts outside the cluster. By default, it is assumed that ironcore-apiserver can reach machine pool internal IPs, though it is possible to configure clusters where this is not the case.</p> <p>MachinePoolInternalIP is the default type of machine pool IP, and does not necessarily imply that the IP is ONLY reachable internally. If a machine pool has multiple internal IPs, no specific semantics are assigned to the additional IPs.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/compute/#compute.ironcore.dev/v1alpha1.MachinePoolCondition","title":"MachinePoolCondition","text":"<p> (Appears on:MachinePoolStatus) </p> <p>MachinePoolCondition is one of the conditions of a volume.</p> Field Description <code>type</code>  MachinePoolConditionType  <p>Type is the type of the condition.</p> <code>status</code>  Kubernetes core/v1.ConditionStatus  <p>Status is the status of the condition.</p> <code>reason</code>  string  <p>Reason is a machine-readable indication of why the condition is in a certain state.</p> <code>message</code>  string  <p>Message is a human-readable explanation of why the condition has a certain reason / state.</p> <code>observedGeneration</code>  int64  <p>ObservedGeneration represents the .metadata.generation that the condition was set based upon.</p> <code>lastTransitionTime</code>  Kubernetes meta/v1.Time  <p>LastTransitionTime is the last time the status of a condition has transitioned from one state to another.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/compute/#compute.ironcore.dev/v1alpha1.MachinePoolConditionType","title":"MachinePoolConditionType (<code>string</code> alias)","text":"<p> (Appears on:MachinePoolCondition) </p> <p>MachinePoolConditionType is a type a MachinePoolCondition can have.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/compute/#compute.ironcore.dev/v1alpha1.MachinePoolDaemonEndpoints","title":"MachinePoolDaemonEndpoints","text":"<p> (Appears on:MachinePoolStatus) </p> <p>MachinePoolDaemonEndpoints lists ports opened by daemons running on the MachinePool.</p> Field Description <code>machinepoolletEndpoint</code>  DaemonEndpoint  (Optional) <p>Endpoint on which machinepoollet is listening.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/compute/#compute.ironcore.dev/v1alpha1.MachinePoolSpec","title":"MachinePoolSpec","text":"<p> (Appears on:MachinePool) </p> <p>MachinePoolSpec defines the desired state of MachinePool</p> Field Description <code>providerID</code>  string  <p>ProviderID identifies the MachinePool on provider side.</p> <code>taints</code>  []github.com/ironcore-dev/ironcore/api/common/v1alpha1.Taint  <p>Taints of the MachinePool. Only Machines who tolerate all the taints will land in the MachinePool.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/compute/#compute.ironcore.dev/v1alpha1.MachinePoolState","title":"MachinePoolState (<code>string</code> alias)","text":"<p> (Appears on:MachinePoolStatus) </p> <p>MachinePoolState is a state a MachinePool can be in.</p> Value Description <p>\"Error\"</p> <p>MachinePoolStateError marks a MachinePool in an error state.</p> <p>\"Offline\"</p> <p>MachinePoolStateOffline marks a MachinePool as offline.</p> <p>\"Pending\"</p> <p>MachinePoolStatePending marks a MachinePool as pending readiness.</p> <p>\"Ready\"</p> <p>MachinePoolStateReady marks a MachinePool as ready for accepting a Machine.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/compute/#compute.ironcore.dev/v1alpha1.MachinePoolStatus","title":"MachinePoolStatus","text":"<p> (Appears on:MachinePool) </p> <p>MachinePoolStatus defines the observed state of MachinePool</p> Field Description <code>state</code>  MachinePoolState  <code>conditions</code>  []MachinePoolCondition  <code>availableMachineClasses</code>  []Kubernetes core/v1.LocalObjectReference  <code>addresses</code>  []MachinePoolAddress  <code>daemonEndpoints</code>  MachinePoolDaemonEndpoints  <code>capacity</code>  github.com/ironcore-dev/ironcore/api/core/v1alpha1.ResourceList  <p>Capacity represents the total resources of a machine pool.</p> <code>allocatable</code>  github.com/ironcore-dev/ironcore/api/core/v1alpha1.ResourceList  <p>Allocatable represents the resources of a machine pool that are available for scheduling.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/compute/#compute.ironcore.dev/v1alpha1.MachineSpec","title":"MachineSpec","text":"<p> (Appears on:Machine) </p> <p>MachineSpec defines the desired state of Machine</p> Field Description <code>machineClassRef</code>  Kubernetes core/v1.LocalObjectReference  <p>MachineClassRef is a reference to the machine class/flavor of the machine.</p> <code>machinePoolSelector</code>  map[string]string  <p>MachinePoolSelector selects a suitable MachinePoolRef by the given labels.</p> <code>machinePoolRef</code>  Kubernetes core/v1.LocalObjectReference  <p>MachinePoolRef defines machine pool to run the machine in. If empty, a scheduler will figure out an appropriate pool to run the machine in.</p> <code>power</code>  Power  <p>Power is the desired machine power state. Defaults to PowerOn.</p> <code>image</code>  string  (Optional) <p>Image is the optional URL providing the operating system image of the machine.</p> <code>imagePullSecret</code>  Kubernetes core/v1.LocalObjectReference  <p>ImagePullSecretRef is an optional secret for pulling the image of a machine.</p> <code>networkInterfaces</code>  []NetworkInterface  (Optional) <p>NetworkInterfaces define a list of network interfaces present on the machine</p> <code>volumes</code>  []Volume  (Optional) <p>Volumes are volumes attached to this machine.</p> <code>ignitionRef</code>  github.com/ironcore-dev/ironcore/api/common/v1alpha1.SecretKeySelector  <p>IgnitionRef is a reference to a secret containing the ignition YAML for the machine to boot up. If key is empty, DefaultIgnitionKey will be used as fallback.</p> <code>efiVars</code>  []EFIVar  (Optional) <p>EFIVars are variables to pass to EFI while booting up.</p> <code>tolerations</code>  []github.com/ironcore-dev/ironcore/api/common/v1alpha1.Toleration  <p>Tolerations define tolerations the Machine has. Only MachinePools whose taints covered by Tolerations will be considered to run the Machine.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/compute/#compute.ironcore.dev/v1alpha1.MachineState","title":"MachineState (<code>string</code> alias)","text":"<p> (Appears on:MachineStatus) </p> <p>MachineState is the state of a machine.</p> Value Description <p>\"Pending\"</p> <p>MachineStatePending means the Machine has been accepted by the system, but not yet completely started. This includes time before being bound to a MachinePool, as well as time spent setting up the Machine on that MachinePool.</p> <p>\"Running\"</p> <p>MachineStateRunning means the machine is running on a MachinePool.</p> <p>\"Shutdown\"</p> <p>MachineStateShutdown means the machine is shut down.</p> <p>\"Terminated\"</p> <p>MachineStateTerminated means the machine has been permanently stopped and cannot be started.</p> <p>\"Terminating\"</p> <p>MachineStateTerminating means the machine that is terminating.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/compute/#compute.ironcore.dev/v1alpha1.MachineStatus","title":"MachineStatus","text":"<p> (Appears on:Machine) </p> <p>MachineStatus defines the observed state of Machine</p> Field Description <code>machineID</code>  string  <p>MachineID is the provider specific machine ID in the format \u2018://\u2019. <code>observedGeneration</code>  int64  <p>ObservedGeneration is the last generation the MachinePool observed of the Machine.</p> <code>state</code>  MachineState  <p>State is the infrastructure state of the machine.</p> <code>networkInterfaces</code>  []NetworkInterfaceStatus  <p>NetworkInterfaces is the list of network interface states for the machine.</p> <code>volumes</code>  []VolumeStatus  <p>Volumes is the list of volume states for the machine.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/compute/#compute.ironcore.dev/v1alpha1.NetworkInterface","title":"NetworkInterface","text":"<p> (Appears on:MachineSpec) </p> <p>NetworkInterface is the definition of a single interface</p> Field Description <code>name</code>  string  <p>Name is the name of the network interface.</p> <code>NetworkInterfaceSource</code>  NetworkInterfaceSource  <p> (Members of <code>NetworkInterfaceSource</code> are embedded into this type.) </p> <p>NetworkInterfaceSource is where to obtain the interface from.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/compute/#compute.ironcore.dev/v1alpha1.NetworkInterfaceSource","title":"NetworkInterfaceSource","text":"<p> (Appears on:NetworkInterface) </p> Field Description <code>networkInterfaceRef</code>  Kubernetes core/v1.LocalObjectReference  <p>NetworkInterfaceRef instructs to use the NetworkInterface at the target reference.</p> <code>ephemeral</code>  EphemeralNetworkInterfaceSource  <p>Ephemeral instructs to create an ephemeral (i.e. coupled to the lifetime of the surrounding object) NetworkInterface to use.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/compute/#compute.ironcore.dev/v1alpha1.NetworkInterfaceState","title":"NetworkInterfaceState (<code>string</code> alias)","text":"<p> (Appears on:NetworkInterfaceStatus) </p> <p>NetworkInterfaceState is the infrastructure attachment state a NetworkInterface can be in.</p> Value Description <p>\"Attached\"</p> <p>NetworkInterfaceStateAttached indicates that a network interface has been successfully attached.</p> <p>\"Pending\"</p> <p>NetworkInterfaceStatePending indicates that the attachment of a network interface is pending.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/compute/#compute.ironcore.dev/v1alpha1.NetworkInterfaceStatus","title":"NetworkInterfaceStatus","text":"<p> (Appears on:MachineStatus) </p> <p>NetworkInterfaceStatus reports the status of an NetworkInterfaceSource.</p> Field Description <code>name</code>  string  <p>Name is the name of the NetworkInterface to whom the status belongs to.</p> <code>handle</code>  string  <p>Handle is the MachinePool internal handle of the NetworkInterface.</p> <code>state</code>  NetworkInterfaceState  <p>State represents the attachment state of a NetworkInterface.</p> <code>networkInterfaceRef</code>  Kubernetes core/v1.LocalObjectReference  <p>networkInterfaceRef is the reference to the networkinterface attached to the machine</p> <code>lastStateTransitionTime</code>  Kubernetes meta/v1.Time  <p>LastStateTransitionTime is the last time the State transitioned.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/compute/#compute.ironcore.dev/v1alpha1.Power","title":"Power (<code>string</code> alias)","text":"<p> (Appears on:MachineSpec) </p> <p>Power is the desired power state of a Machine.</p> Value Description <p>\"Off\"</p> <p>PowerOff indicates that a Machine should be powered off.</p> <p>\"On\"</p> <p>PowerOn indicates that a Machine should be powered on.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/compute/#compute.ironcore.dev/v1alpha1.Volume","title":"Volume","text":"<p> (Appears on:MachineSpec) </p> <p>Volume defines a volume attachment of a machine</p> Field Description <code>name</code>  string  <p>Name is the name of the Volume</p> <code>device</code>  string  <p>Device is the device name where the volume should be attached. Pointer to distinguish between explicit zero and not specified. If empty, an unused device name will be determined if possible.</p> <code>VolumeSource</code>  VolumeSource  <p> (Members of <code>VolumeSource</code> are embedded into this type.) </p> <p>VolumeSource is the source where the storage for the Volume resides at.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/compute/#compute.ironcore.dev/v1alpha1.VolumeSource","title":"VolumeSource","text":"<p> (Appears on:Volume) </p> <p>VolumeSource specifies the source to use for a Volume.</p> Field Description <code>volumeRef</code>  Kubernetes core/v1.LocalObjectReference  <p>VolumeRef instructs to use the specified Volume as source for the attachment.</p> <code>emptyDisk</code>  EmptyDiskVolumeSource  <p>EmptyDisk instructs to use a Volume offered by the machine pool provider.</p> <code>ephemeral</code>  EphemeralVolumeSource  <p>Ephemeral instructs to create an ephemeral (i.e. coupled to the lifetime of the surrounding object) Volume to use.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/compute/#compute.ironcore.dev/v1alpha1.VolumeState","title":"VolumeState (<code>string</code> alias)","text":"<p> (Appears on:VolumeStatus) </p> <p>VolumeState is the infrastructure attachment state a Volume can be in.</p> Value Description <p>\"Attached\"</p> <p>VolumeStateAttached indicates that a volume has been successfully attached.</p> <p>\"Pending\"</p> <p>VolumeStatePending indicates that the attachment of a volume is pending.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/compute/#compute.ironcore.dev/v1alpha1.VolumeStatus","title":"VolumeStatus","text":"<p> (Appears on:MachineStatus) </p> <p>VolumeStatus is the status of a Volume.</p> Field Description <code>name</code>  string  <p>Name is the name of a volume attachment.</p> <code>handle</code>  string  <p>Handle is the MachinePool internal handle of the volume.</p> <code>state</code>  VolumeState  <p>State represents the attachment state of a Volume.</p> <code>lastStateTransitionTime</code>  Kubernetes meta/v1.Time  <p>LastStateTransitionTime is the last time the State transitioned.</p> <code>volumeRef</code>  Kubernetes core/v1.LocalObjectReference  <p>VolumeRef reference to the claimed Volume</p> <p> Generated with <code>gen-crd-api-reference-docs</code> </p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/core/","title":"Core","text":"<p>Packages:</p> <ul> <li> core.ironcore.dev/v1alpha1 </li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/core/#core.ironcore.dev/v1alpha1","title":"core.ironcore.dev/v1alpha1","text":"<p>Package v1alpha1 is the v1alpha1 version of the API.</p> <p>Resource Types:</p> <ul><li> ResourceQuota </li></ul>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/core/#core.ironcore.dev/v1alpha1.ResourceQuota","title":"ResourceQuota","text":"<p>ResourceQuota is the Schema for the resourcequotas API</p> Field Description <code>apiVersion</code> string <code> core.ironcore.dev/v1alpha1 </code> <code>kind</code> string  <code>ResourceQuota</code> <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>spec</code>  ResourceQuotaSpec  <code>hard</code>  ResourceList  <p>Hard is a ResourceList of the strictly enforced amount of resources.</p> <code>scopeSelector</code>  ResourceScopeSelector  <p>ScopeSelector selects the resources that are subject to this quota. Note: By using certain ScopeSelectors, only certain resources may be tracked.</p> <code>status</code>  ResourceQuotaStatus"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/core/#core.ironcore.dev/v1alpha1.ClassType","title":"ClassType (<code>string</code> alias)","text":"Value Description <p>\"machine\"</p> <p>\"volume\"</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/core/#core.ironcore.dev/v1alpha1.ObjectSelector","title":"ObjectSelector","text":"<p>ObjectSelector specifies how to select objects of a certain kind.</p> Field Description <code>kind</code>  string  <p>Kind is the kind of object to select.</p> <code>LabelSelector</code>  Kubernetes meta/v1.LabelSelector  <p> (Members of <code>LabelSelector</code> are embedded into this type.) </p> <p>LabelSelector is the label selector to select objects of the specified Kind by.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/core/#core.ironcore.dev/v1alpha1.ResourceName","title":"ResourceName (<code>string</code> alias)","text":"<p>ResourceName is the name of a resource, most often used alongside a resource.Quantity.</p> Value Description <p>\"cpu\"</p> <p>ResourceCPU is the amount of cpu in cores.</p> <p>\"iops\"</p> <p>ResourceIOPS defines max IOPS in input/output operations per second.</p> <p>\"memory\"</p> <p>ResourceMemory is the amount of memory in bytes.</p> <p>\"requests.cpu\"</p> <p>ResourceRequestsCPU is the amount of requested cpu in cores.</p> <p>\"requests.memory\"</p> <p>ResourceRequestsMemory is the amount of requested memory in bytes.</p> <p>\"requests.storage\"</p> <p>ResourceRequestsStorage is the amount of requested storage in bytes.</p> <p>\"storage\"</p> <p>ResourceStorage is the amount of storage, in bytes.</p> <p>\"tps\"</p> <p>ResourceTPS defines max throughput per second. (e.g. 1Gi)</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/core/#core.ironcore.dev/v1alpha1.ResourceQuotaSpec","title":"ResourceQuotaSpec","text":"<p> (Appears on:ResourceQuota) </p> <p>ResourceQuotaSpec defines the desired state of ResourceQuotaSpec</p> Field Description <code>hard</code>  ResourceList  <p>Hard is a ResourceList of the strictly enforced amount of resources.</p> <code>scopeSelector</code>  ResourceScopeSelector  <p>ScopeSelector selects the resources that are subject to this quota. Note: By using certain ScopeSelectors, only certain resources may be tracked.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/core/#core.ironcore.dev/v1alpha1.ResourceQuotaStatus","title":"ResourceQuotaStatus","text":"<p> (Appears on:ResourceQuota) </p> <p>ResourceQuotaStatus is the status of a ResourceQuota.</p> Field Description <code>hard</code>  ResourceList  <p>Hard are the currently enforced hard resource limits. Hard may be less than used in case the limits were introduced / updated after more than allowed resources were already present.</p> <code>used</code>  ResourceList  <p>Used is the amount of currently used resources.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/core/#core.ironcore.dev/v1alpha1.ResourceScope","title":"ResourceScope (<code>string</code> alias)","text":"<p> (Appears on:ResourceScopeSelectorRequirement) </p> <p>ResourceScope is a scope of a resource.</p> Value Description <p>\"BucketClass\"</p> <p>ResourceScopeBucketClass refers to the bucket class of a resource.</p> <p>\"MachineClass\"</p> <p>ResourceScopeMachineClass refers to the machine class of a resource.</p> <p>\"VolumeClass\"</p> <p>ResourceScopeVolumeClass refers to the volume class of a resource.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/core/#core.ironcore.dev/v1alpha1.ResourceScopeSelector","title":"ResourceScopeSelector","text":"<p> (Appears on:ResourceQuotaSpec) </p> <p>ResourceScopeSelector selects</p> Field Description <code>matchExpressions</code>  []ResourceScopeSelectorRequirement  <p>MatchExpressions is a list of ResourceScopeSelectorRequirement to match resources by.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/core/#core.ironcore.dev/v1alpha1.ResourceScopeSelectorOperator","title":"ResourceScopeSelectorOperator (<code>string</code> alias)","text":"<p> (Appears on:ResourceScopeSelectorRequirement) </p> <p>ResourceScopeSelectorOperator is an operator to compare a ResourceScope with values.</p> Value Description <p>\"DoesNotExist\"</p> <p>\"Exists\"</p> <p>\"In\"</p> <p>\"NotIn\"</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/core/#core.ironcore.dev/v1alpha1.ResourceScopeSelectorRequirement","title":"ResourceScopeSelectorRequirement","text":"<p> (Appears on:ResourceScopeSelector) </p> <p>ResourceScopeSelectorRequirement is a requirement for a resource using a ResourceScope alongside a ResourceScopeSelectorOperator with Values (depending on the ResourceScopeSelectorOperator).</p> Field Description <code>scopeName</code>  ResourceScope  <p>ScopeName is the ResourceScope to make a requirement for.</p> <code>operator</code>  ResourceScopeSelectorOperator  <p>Operator is the ResourceScopeSelectorOperator to check the ScopeName with in a resource.</p> <code>values</code>  []string  <p>Values are the values to compare the Operator with the ScopeName. May be optional.</p> <p> Generated with <code>gen-crd-api-reference-docs</code> </p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/ipam/","title":"IPAM","text":"<p>Packages:</p> <ul> <li> ipam.ironcore.dev/v1alpha1 </li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/ipam/#ipam.ironcore.dev/v1alpha1","title":"ipam.ironcore.dev/v1alpha1","text":"<p>Package v1alpha1 is the v1alpha1 version of the API.</p> <p>Resource Types:</p> <ul><li> Prefix </li><li> PrefixAllocation </li></ul>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/ipam/#ipam.ironcore.dev/v1alpha1.Prefix","title":"Prefix","text":"<p>Prefix is the Schema for the prefixes API</p> Field Description <code>apiVersion</code> string <code> ipam.ironcore.dev/v1alpha1 </code> <code>kind</code> string  <code>Prefix</code> <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>spec</code>  PrefixSpec  <code>ipFamily</code>  Kubernetes core/v1.IPFamily  <p>IPFamily is the IPFamily of the prefix. If unset but Prefix is set, this can be inferred.</p> <code>prefix</code>  github.com/ironcore-dev/ironcore/api/common/v1alpha1.IPPrefix  <p>Prefix is the prefix to allocate for this Prefix.</p> <code>prefixLength</code>  int32  <p>PrefixLength is the length of prefix to allocate for this Prefix.</p> <code>parentRef</code>  Kubernetes core/v1.LocalObjectReference  <p>ParentRef references the parent to allocate the Prefix from. If ParentRef and ParentSelector is empty, the Prefix is considered a root prefix and thus allocated by itself.</p> <code>parentSelector</code>  Kubernetes meta/v1.LabelSelector  <p>ParentSelector is the LabelSelector to use for determining the parent for this Prefix.</p> <code>status</code>  PrefixStatus"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/ipam/#ipam.ironcore.dev/v1alpha1.PrefixAllocation","title":"PrefixAllocation","text":"<p>PrefixAllocation is the Schema for the prefixallocations API</p> Field Description <code>apiVersion</code> string <code> ipam.ironcore.dev/v1alpha1 </code> <code>kind</code> string  <code>PrefixAllocation</code> <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>spec</code>  PrefixAllocationSpec  <code>ipFamily</code>  Kubernetes core/v1.IPFamily  <p>IPFamily is the IPFamily of the prefix. If unset but Prefix is set, this can be inferred.</p> <code>prefix</code>  github.com/ironcore-dev/ironcore/api/common/v1alpha1.IPPrefix  <p>Prefix is the prefix to allocate for this Prefix.</p> <code>prefixLength</code>  int32  <p>PrefixLength is the length of prefix to allocate for this Prefix.</p> <code>prefixRef</code>  Kubernetes core/v1.LocalObjectReference  <p>PrefixRef references the prefix to allocate from.</p> <code>prefixSelector</code>  Kubernetes meta/v1.LabelSelector  <p>PrefixSelector selects the prefix to allocate from.</p> <code>status</code>  PrefixAllocationStatus"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/ipam/#ipam.ironcore.dev/v1alpha1.PrefixAllocationPhase","title":"PrefixAllocationPhase (<code>string</code> alias)","text":"<p> (Appears on:PrefixAllocationStatus) </p> <p>PrefixAllocationPhase is a phase a PrefixAllocation can be in.</p> Value Description <p>\"Allocated\"</p> <p>PrefixAllocationPhaseAllocated marks a PrefixAllocation as allocated by a Prefix.</p> <p>\"Failed\"</p> <p>PrefixAllocationPhaseFailed marks a PrefixAllocation as failed.</p> <p>\"Pending\"</p> <p>PrefixAllocationPhasePending marks a PrefixAllocation as waiting for allocation.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/ipam/#ipam.ironcore.dev/v1alpha1.PrefixAllocationSpec","title":"PrefixAllocationSpec","text":"<p> (Appears on:PrefixAllocation) </p> <p>PrefixAllocationSpec defines the desired state of PrefixAllocation</p> Field Description <code>ipFamily</code>  Kubernetes core/v1.IPFamily  <p>IPFamily is the IPFamily of the prefix. If unset but Prefix is set, this can be inferred.</p> <code>prefix</code>  github.com/ironcore-dev/ironcore/api/common/v1alpha1.IPPrefix  <p>Prefix is the prefix to allocate for this Prefix.</p> <code>prefixLength</code>  int32  <p>PrefixLength is the length of prefix to allocate for this Prefix.</p> <code>prefixRef</code>  Kubernetes core/v1.LocalObjectReference  <p>PrefixRef references the prefix to allocate from.</p> <code>prefixSelector</code>  Kubernetes meta/v1.LabelSelector  <p>PrefixSelector selects the prefix to allocate from.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/ipam/#ipam.ironcore.dev/v1alpha1.PrefixAllocationStatus","title":"PrefixAllocationStatus","text":"<p> (Appears on:PrefixAllocation) </p> <p>PrefixAllocationStatus is the status of a PrefixAllocation.</p> Field Description <code>prefix</code>  github.com/ironcore-dev/ironcore/api/common/v1alpha1.IPPrefix  <p>Prefix is the allocated prefix, if any</p> <code>phase</code>  PrefixAllocationPhase  <p>Phase is the phase of the PrefixAllocation.</p> <code>lastPhaseTransitionTime</code>  Kubernetes meta/v1.Time  <p>LastPhaseTransitionTime is the last time the Phase changed values.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/ipam/#ipam.ironcore.dev/v1alpha1.PrefixPhase","title":"PrefixPhase (<code>string</code> alias)","text":"<p> (Appears on:PrefixStatus) </p> <p>PrefixPhase is a phase a Prefix can be in.</p> Value Description <p>\"Allocated\"</p> <p>PrefixPhaseAllocated marks a prefix as allocated.</p> <p>\"Pending\"</p> <p>PrefixPhasePending marks a prefix as waiting for allocation.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/ipam/#ipam.ironcore.dev/v1alpha1.PrefixSpec","title":"PrefixSpec","text":"<p> (Appears on:Prefix, PrefixTemplateSpec) </p> <p>PrefixSpec defines the desired state of Prefix</p> Field Description <code>ipFamily</code>  Kubernetes core/v1.IPFamily  <p>IPFamily is the IPFamily of the prefix. If unset but Prefix is set, this can be inferred.</p> <code>prefix</code>  github.com/ironcore-dev/ironcore/api/common/v1alpha1.IPPrefix  <p>Prefix is the prefix to allocate for this Prefix.</p> <code>prefixLength</code>  int32  <p>PrefixLength is the length of prefix to allocate for this Prefix.</p> <code>parentRef</code>  Kubernetes core/v1.LocalObjectReference  <p>ParentRef references the parent to allocate the Prefix from. If ParentRef and ParentSelector is empty, the Prefix is considered a root prefix and thus allocated by itself.</p> <code>parentSelector</code>  Kubernetes meta/v1.LabelSelector  <p>ParentSelector is the LabelSelector to use for determining the parent for this Prefix.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/ipam/#ipam.ironcore.dev/v1alpha1.PrefixStatus","title":"PrefixStatus","text":"<p> (Appears on:Prefix) </p> <p>PrefixStatus defines the observed state of Prefix</p> Field Description <code>phase</code>  PrefixPhase  <p>Phase is the PrefixPhase of the Prefix.</p> <code>lastPhaseTransitionTime</code>  Kubernetes meta/v1.Time  <p>LastPhaseTransitionTime is the last time the Phase changed values.</p> <code>used</code>  []github.com/ironcore-dev/ironcore/api/common/v1alpha1.IPPrefix  <p>Used is a list of used prefixes.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/ipam/#ipam.ironcore.dev/v1alpha1.PrefixTemplateSpec","title":"PrefixTemplateSpec","text":"Field Description <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>spec</code>  PrefixSpec  <code>ipFamily</code>  Kubernetes core/v1.IPFamily  <p>IPFamily is the IPFamily of the prefix. If unset but Prefix is set, this can be inferred.</p> <code>prefix</code>  github.com/ironcore-dev/ironcore/api/common/v1alpha1.IPPrefix  <p>Prefix is the prefix to allocate for this Prefix.</p> <code>prefixLength</code>  int32  <p>PrefixLength is the length of prefix to allocate for this Prefix.</p> <code>parentRef</code>  Kubernetes core/v1.LocalObjectReference  <p>ParentRef references the parent to allocate the Prefix from. If ParentRef and ParentSelector is empty, the Prefix is considered a root prefix and thus allocated by itself.</p> <code>parentSelector</code>  Kubernetes meta/v1.LabelSelector  <p>ParentSelector is the LabelSelector to use for determining the parent for this Prefix.</p> <p> Generated with <code>gen-crd-api-reference-docs</code> </p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/","title":"Networking","text":"<p>Packages:</p> <ul> <li> networking.ironcore.dev/v1alpha1 </li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/#networking.ironcore.dev/v1alpha1","title":"networking.ironcore.dev/v1alpha1","text":"<p>Package v1alpha1 is the v1alpha1 version of the API.</p> <p>Resource Types:</p> <ul><li> LoadBalancer </li><li> LoadBalancerRouting </li><li> NATGateway </li><li> Network </li><li> NetworkInterface </li><li> NetworkPolicy </li><li> VirtualIP </li></ul>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/#networking.ironcore.dev/v1alpha1.LoadBalancer","title":"LoadBalancer","text":"<p>LoadBalancer is the Schema for the LoadBalancer API</p> Field Description <code>apiVersion</code> string <code> networking.ironcore.dev/v1alpha1 </code> <code>kind</code> string  <code>LoadBalancer</code> <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>spec</code>  LoadBalancerSpec  <code>type</code>  LoadBalancerType  <p>Type is the type of LoadBalancer.</p> <code>ipFamilies</code>  []Kubernetes core/v1.IPFamily  <p>IPFamilies are the ip families the load balancer should have.</p> <code>ips</code>  []IPSource  <p>IPs are the ips to use. Can only be used when Type is LoadBalancerTypeInternal.</p> <code>networkRef</code>  Kubernetes core/v1.LocalObjectReference  <p>NetworkRef is the Network this LoadBalancer should belong to.</p> <code>networkInterfaceSelector</code>  Kubernetes meta/v1.LabelSelector  <p>NetworkInterfaceSelector defines the NetworkInterfaces for which this LoadBalancer should be applied</p> <code>ports</code>  []LoadBalancerPort  <p>Ports are the ports the load balancer should allow.</p> <code>status</code>  LoadBalancerStatus"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/#networking.ironcore.dev/v1alpha1.LoadBalancerRouting","title":"LoadBalancerRouting","text":"<p>LoadBalancerRouting is the Schema for the loadbalancerroutings API</p> Field Description <code>apiVersion</code> string <code> networking.ironcore.dev/v1alpha1 </code> <code>kind</code> string  <code>LoadBalancerRouting</code> <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>networkRef</code>  github.com/ironcore-dev/ironcore/api/common/v1alpha1.LocalUIDReference  <p>NetworkRef is the network the load balancer is assigned to.</p> <code>destinations</code>  []LoadBalancerDestination  <p>Destinations are the destinations for an LoadBalancer.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/#networking.ironcore.dev/v1alpha1.NATGateway","title":"NATGateway","text":"<p>NATGateway is the Schema for the NATGateway API</p> Field Description <code>apiVersion</code> string <code> networking.ironcore.dev/v1alpha1 </code> <code>kind</code> string  <code>NATGateway</code> <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>spec</code>  NATGatewaySpec  <code>type</code>  NATGatewayType  <p>Type is the type of NATGateway.</p> <code>ipFamily</code>  Kubernetes core/v1.IPFamily  <p>IPFamily is the ip family the NAT gateway should have.</p> <code>networkRef</code>  Kubernetes core/v1.LocalObjectReference  <p>NetworkRef is the Network this NATGateway should belong to.</p> <code>portsPerNetworkInterface</code>  int32  <p>PortsPerNetworkInterface defines the number of concurrent connections per target network interface. Has to be a power of 2. If empty, 2048 (DefaultPortsPerNetworkInterface) is the default.</p> <code>status</code>  NATGatewayStatus"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/#networking.ironcore.dev/v1alpha1.Network","title":"Network","text":"<p>Network is the Schema for the network API</p> Field Description <code>apiVersion</code> string <code> networking.ironcore.dev/v1alpha1 </code> <code>kind</code> string  <code>Network</code> <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>spec</code>  NetworkSpec  <code>providerID</code>  string  <p>ProviderID is the provider-internal ID of the network.</p> <code>peerings</code>  []NetworkPeering  (Optional) <p>Peerings are the network peerings with this network.</p> <code>incomingPeerings</code>  []NetworkPeeringClaimRef  (Optional) <p>PeeringClaimRefs are the peering claim references of other networks.</p> <code>status</code>  NetworkStatus"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/#networking.ironcore.dev/v1alpha1.NetworkInterface","title":"NetworkInterface","text":"<p>NetworkInterface is the Schema for the networkinterfaces API</p> Field Description <code>apiVersion</code> string <code> networking.ironcore.dev/v1alpha1 </code> <code>kind</code> string  <code>NetworkInterface</code> <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>spec</code>  NetworkInterfaceSpec  <code>providerID</code>  string  <p>ProviderID is the provider-internal ID of the network interface.</p> <code>networkRef</code>  Kubernetes core/v1.LocalObjectReference  <p>NetworkRef is the Network this NetworkInterface is connected to</p> <code>machineRef</code>  github.com/ironcore-dev/ironcore/api/common/v1alpha1.LocalUIDReference  <p>MachineRef is the Machine this NetworkInterface is used by</p> <code>ipFamilies</code>  []Kubernetes core/v1.IPFamily  <p>IPFamilies defines which IPFamilies this NetworkInterface is supporting</p> <code>ips</code>  []IPSource  <p>IPs is the list of provided IPs or ephemeral IPs which should be assigned to this NetworkInterface.</p> <code>prefixes</code>  []PrefixSource  <p>Prefixes is the list of provided prefixes or ephemeral prefixes which should be assigned to this NetworkInterface.</p> <code>virtualIP</code>  VirtualIPSource  <p>VirtualIP specifies the virtual ip that should be assigned to this NetworkInterface.</p> <code>attributes</code>  map[string]string  <p>Attributes are provider-specific attributes for the network interface.</p> <code>status</code>  NetworkInterfaceStatus"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/#networking.ironcore.dev/v1alpha1.NetworkPolicy","title":"NetworkPolicy","text":"<p>NetworkPolicy is the Schema for the networkpolicies API</p> Field Description <code>apiVersion</code> string <code> networking.ironcore.dev/v1alpha1 </code> <code>kind</code> string  <code>NetworkPolicy</code> <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>spec</code>  NetworkPolicySpec  <code>networkRef</code>  Kubernetes core/v1.LocalObjectReference  <p>NetworkRef is the network to regulate using this policy.</p> <code>networkInterfaceSelector</code>  Kubernetes meta/v1.LabelSelector  <p>NetworkInterfaceSelector selects the network interfaces that are subject to this policy.</p> <code>ingress</code>  []NetworkPolicyIngressRule  <p>Ingress specifies rules for ingress traffic.</p> <code>egress</code>  []NetworkPolicyEgressRule  <p>Egress specifies rules for egress traffic.</p> <code>policyTypes</code>  []PolicyType  <p>PolicyTypes specifies the types of policies this network policy contains.</p> <code>status</code>  NetworkPolicyStatus"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/#networking.ironcore.dev/v1alpha1.VirtualIP","title":"VirtualIP","text":"<p>VirtualIP is the Schema for the virtualips API</p> Field Description <code>apiVersion</code> string <code> networking.ironcore.dev/v1alpha1 </code> <code>kind</code> string  <code>VirtualIP</code> <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>spec</code>  VirtualIPSpec  <code>type</code>  VirtualIPType  <p>Type is the type of VirtualIP.</p> <code>ipFamily</code>  Kubernetes core/v1.IPFamily  <p>IPFamily is the ip family of the VirtualIP.</p> <code>targetRef</code>  github.com/ironcore-dev/ironcore/api/common/v1alpha1.LocalUIDReference  <p>TargetRef references the target for this VirtualIP (currently only NetworkInterface).</p> <code>status</code>  VirtualIPStatus"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/#networking.ironcore.dev/v1alpha1.EphemeralPrefixSource","title":"EphemeralPrefixSource","text":"<p> (Appears on:IPSource, PrefixSource) </p> <p>EphemeralPrefixSource contains the definition to create an ephemeral (i.e. coupled to the lifetime of the surrounding object) Prefix.</p> Field Description <code>prefixTemplate</code>  github.com/ironcore-dev/ironcore/api/ipam/v1alpha1.PrefixTemplateSpec  <p>PrefixTemplate is the template for the Prefix.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/#networking.ironcore.dev/v1alpha1.EphemeralVirtualIPSource","title":"EphemeralVirtualIPSource","text":"<p> (Appears on:VirtualIPSource) </p> <p>EphemeralVirtualIPSource contains the definition to create an ephemeral (i.e. coupled to the lifetime of the surrounding object) VirtualIP.</p> Field Description <code>virtualIPTemplate</code>  VirtualIPTemplateSpec  <p>VirtualIPTemplate is the template for the VirtualIP.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/#networking.ironcore.dev/v1alpha1.EphemeralVirtualIPSpec","title":"EphemeralVirtualIPSpec","text":"<p> (Appears on:VirtualIPTemplateSpec) </p> Field Description <code>VirtualIPSpec</code>  VirtualIPSpec  <p> (Members of <code>VirtualIPSpec</code> are embedded into this type.) </p> <p>VirtualIPSpec defines the desired state of a VirtualIP</p> <code>reclaimPolicy</code>  ReclaimPolicyType  <p>ReclaimPolicy is the ReclaimPolicyType of virtualIP</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/#networking.ironcore.dev/v1alpha1.IPBlock","title":"IPBlock","text":"<p> (Appears on:NetworkPolicyPeer) </p> <p>IPBlock specifies an ip block with optional exceptions.</p> Field Description <code>cidr</code>  github.com/ironcore-dev/ironcore/api/common/v1alpha1.IPPrefix  <p>CIDR is a string representing the ip block.</p> <code>except</code>  []github.com/ironcore-dev/ironcore/api/common/v1alpha1.IPPrefix  <p>Except is a slice of CIDRs that should not be included within the specified CIDR. Values will be rejected if they are outside CIDR.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/#networking.ironcore.dev/v1alpha1.IPSource","title":"IPSource","text":"<p> (Appears on:LoadBalancerSpec, NetworkInterfaceSpec) </p> <p>IPSource is the definition of how to obtain an IP.</p> Field Description <code>value</code>  github.com/ironcore-dev/ironcore/api/common/v1alpha1.IP  <p>Value specifies an IP by using an IP literal.</p> <code>ephemeral</code>  EphemeralPrefixSource  <p>Ephemeral specifies an IP by creating an ephemeral Prefix to allocate the IP with.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/#networking.ironcore.dev/v1alpha1.LoadBalancerDestination","title":"LoadBalancerDestination","text":"<p> (Appears on:LoadBalancerRouting) </p> <p>LoadBalancerDestination is the destination of the load balancer.</p> Field Description <code>ip</code>  github.com/ironcore-dev/ironcore/api/common/v1alpha1.IP  <p>IP is the target IP.</p> <code>targetRef</code>  LoadBalancerTargetRef  <p>TargetRef is the target providing the destination.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/#networking.ironcore.dev/v1alpha1.LoadBalancerPort","title":"LoadBalancerPort","text":"<p> (Appears on:LoadBalancerSpec) </p> Field Description <code>protocol</code>  Kubernetes core/v1.Protocol  <p>Protocol is the protocol the load balancer should allow. If not specified, defaults to TCP.</p> <code>port</code>  int32  <p>Port is the port to allow.</p> <code>endPort</code>  int32  <p>EndPort marks the end of the port range to allow. If unspecified, only a single port, Port, will be allowed.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/#networking.ironcore.dev/v1alpha1.LoadBalancerSpec","title":"LoadBalancerSpec","text":"<p> (Appears on:LoadBalancer) </p> <p>LoadBalancerSpec defines the desired state of LoadBalancer</p> Field Description <code>type</code>  LoadBalancerType  <p>Type is the type of LoadBalancer.</p> <code>ipFamilies</code>  []Kubernetes core/v1.IPFamily  <p>IPFamilies are the ip families the load balancer should have.</p> <code>ips</code>  []IPSource  <p>IPs are the ips to use. Can only be used when Type is LoadBalancerTypeInternal.</p> <code>networkRef</code>  Kubernetes core/v1.LocalObjectReference  <p>NetworkRef is the Network this LoadBalancer should belong to.</p> <code>networkInterfaceSelector</code>  Kubernetes meta/v1.LabelSelector  <p>NetworkInterfaceSelector defines the NetworkInterfaces for which this LoadBalancer should be applied</p> <code>ports</code>  []LoadBalancerPort  <p>Ports are the ports the load balancer should allow.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/#networking.ironcore.dev/v1alpha1.LoadBalancerStatus","title":"LoadBalancerStatus","text":"<p> (Appears on:LoadBalancer) </p> <p>LoadBalancerStatus defines the observed state of LoadBalancer</p> Field Description <code>ips</code>  []github.com/ironcore-dev/ironcore/api/common/v1alpha1.IP  <p>IPs are the IPs allocated for the load balancer.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/#networking.ironcore.dev/v1alpha1.LoadBalancerTargetRef","title":"LoadBalancerTargetRef","text":"<p> (Appears on:LoadBalancerDestination) </p> <p>LoadBalancerTargetRef is a load balancer target.</p> Field Description <code>uid</code>  k8s.io/apimachinery/pkg/types.UID  <p>UID is the UID of the target.</p> <code>name</code>  string  <p>Name is the name of the target.</p> <code>providerID</code>  string  <p>ProviderID is the provider internal id of the target.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/#networking.ironcore.dev/v1alpha1.LoadBalancerType","title":"LoadBalancerType (<code>string</code> alias)","text":"<p> (Appears on:LoadBalancerSpec) </p> <p>LoadBalancerType is a type of LoadBalancer.</p> Value Description <p>\"Internal\"</p> <p>LoadBalancerTypeInternal is a LoadBalancer that allocates and routes network-internal, stable IPs.</p> <p>\"Public\"</p> <p>LoadBalancerTypePublic is a LoadBalancer that allocates and routes a stable public IP.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/#networking.ironcore.dev/v1alpha1.NATGatewaySpec","title":"NATGatewaySpec","text":"<p> (Appears on:NATGateway) </p> <p>NATGatewaySpec defines the desired state of NATGateway</p> Field Description <code>type</code>  NATGatewayType  <p>Type is the type of NATGateway.</p> <code>ipFamily</code>  Kubernetes core/v1.IPFamily  <p>IPFamily is the ip family the NAT gateway should have.</p> <code>networkRef</code>  Kubernetes core/v1.LocalObjectReference  <p>NetworkRef is the Network this NATGateway should belong to.</p> <code>portsPerNetworkInterface</code>  int32  <p>PortsPerNetworkInterface defines the number of concurrent connections per target network interface. Has to be a power of 2. If empty, 2048 (DefaultPortsPerNetworkInterface) is the default.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/#networking.ironcore.dev/v1alpha1.NATGatewayStatus","title":"NATGatewayStatus","text":"<p> (Appears on:NATGateway) </p> <p>NATGatewayStatus defines the observed state of NATGateway</p> Field Description <code>ips</code>  []github.com/ironcore-dev/ironcore/api/common/v1alpha1.IP  <p>IPs are the IPs allocated for the NAT gateway.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/#networking.ironcore.dev/v1alpha1.NATGatewayType","title":"NATGatewayType (<code>string</code> alias)","text":"<p> (Appears on:NATGatewaySpec) </p> <p>NATGatewayType is a type of NATGateway.</p> Value Description <p>\"Public\"</p> <p>NATGatewayTypePublic is a NATGateway that allocates and routes a stable public IP.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/#networking.ironcore.dev/v1alpha1.NetworkInterfaceSpec","title":"NetworkInterfaceSpec","text":"<p> (Appears on:NetworkInterface, NetworkInterfaceTemplateSpec) </p> <p>NetworkInterfaceSpec defines the desired state of NetworkInterface</p> Field Description <code>providerID</code>  string  <p>ProviderID is the provider-internal ID of the network interface.</p> <code>networkRef</code>  Kubernetes core/v1.LocalObjectReference  <p>NetworkRef is the Network this NetworkInterface is connected to</p> <code>machineRef</code>  github.com/ironcore-dev/ironcore/api/common/v1alpha1.LocalUIDReference  <p>MachineRef is the Machine this NetworkInterface is used by</p> <code>ipFamilies</code>  []Kubernetes core/v1.IPFamily  <p>IPFamilies defines which IPFamilies this NetworkInterface is supporting</p> <code>ips</code>  []IPSource  <p>IPs is the list of provided IPs or ephemeral IPs which should be assigned to this NetworkInterface.</p> <code>prefixes</code>  []PrefixSource  <p>Prefixes is the list of provided prefixes or ephemeral prefixes which should be assigned to this NetworkInterface.</p> <code>virtualIP</code>  VirtualIPSource  <p>VirtualIP specifies the virtual ip that should be assigned to this NetworkInterface.</p> <code>attributes</code>  map[string]string  <p>Attributes are provider-specific attributes for the network interface.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/#networking.ironcore.dev/v1alpha1.NetworkInterfaceState","title":"NetworkInterfaceState (<code>string</code> alias)","text":"<p> (Appears on:NetworkInterfaceStatus) </p> <p>NetworkInterfaceState is the ironcore state of a NetworkInterface.</p> Value Description <p>\"Available\"</p> <p>NetworkInterfaceStateAvailable is used for any NetworkInterface where all properties are valid.</p> <p>\"Error\"</p> <p>NetworkInterfaceStateError is used for any NetworkInterface where any property has an error.</p> <p>\"Pending\"</p> <p>NetworkInterfaceStatePending is used for any NetworkInterface that is pending.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/#networking.ironcore.dev/v1alpha1.NetworkInterfaceStatus","title":"NetworkInterfaceStatus","text":"<p> (Appears on:NetworkInterface) </p> <p>NetworkInterfaceStatus defines the observed state of NetworkInterface</p> Field Description <code>state</code>  NetworkInterfaceState  <p>State is the NetworkInterfaceState of the NetworkInterface.</p> <code>lastStateTransitionTime</code>  Kubernetes meta/v1.Time  <p>LastStateTransitionTime is the last time the State transitioned from one value to another.</p> <code>ips</code>  []github.com/ironcore-dev/ironcore/api/common/v1alpha1.IP  <p>IPs represent the effective IP addresses of the NetworkInterface.</p> <code>prefixes</code>  []github.com/ironcore-dev/ironcore/api/common/v1alpha1.IPPrefix  <p>Prefixes represent the prefixes routed to the NetworkInterface.</p> <code>virtualIP</code>  github.com/ironcore-dev/ironcore/api/common/v1alpha1.IP  <p>VirtualIP is any virtual ip assigned to the NetworkInterface.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/#networking.ironcore.dev/v1alpha1.NetworkInterfaceTemplateSpec","title":"NetworkInterfaceTemplateSpec","text":"<p>NetworkInterfaceTemplateSpec is the specification of a NetworkInterface template.</p> Field Description <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>spec</code>  NetworkInterfaceSpec  <code>providerID</code>  string  <p>ProviderID is the provider-internal ID of the network interface.</p> <code>networkRef</code>  Kubernetes core/v1.LocalObjectReference  <p>NetworkRef is the Network this NetworkInterface is connected to</p> <code>machineRef</code>  github.com/ironcore-dev/ironcore/api/common/v1alpha1.LocalUIDReference  <p>MachineRef is the Machine this NetworkInterface is used by</p> <code>ipFamilies</code>  []Kubernetes core/v1.IPFamily  <p>IPFamilies defines which IPFamilies this NetworkInterface is supporting</p> <code>ips</code>  []IPSource  <p>IPs is the list of provided IPs or ephemeral IPs which should be assigned to this NetworkInterface.</p> <code>prefixes</code>  []PrefixSource  <p>Prefixes is the list of provided prefixes or ephemeral prefixes which should be assigned to this NetworkInterface.</p> <code>virtualIP</code>  VirtualIPSource  <p>VirtualIP specifies the virtual ip that should be assigned to this NetworkInterface.</p> <code>attributes</code>  map[string]string  <p>Attributes are provider-specific attributes for the network interface.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/#networking.ironcore.dev/v1alpha1.NetworkPeering","title":"NetworkPeering","text":"<p> (Appears on:NetworkSpec) </p> <p>NetworkPeering defines a network peering with another network.</p> Field Description <code>name</code>  string  <p>Name is the semantical name of the network peering.</p> <code>networkRef</code>  NetworkPeeringNetworkRef  <p>NetworkRef is the reference to the network to peer with. An empty namespace indicates that the target network resides in the same namespace as the source network.</p> <code>prefixes</code>  []PeeringPrefix  <p>Prefixes is a list of prefixes that we want only to be exposed to the peered network, if no prefixes are specified no filtering will be done.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/#networking.ironcore.dev/v1alpha1.NetworkPeeringClaimRef","title":"NetworkPeeringClaimRef","text":"<p> (Appears on:NetworkSpec) </p> Field Description <code>namespace</code>  string  <p>Namespace is the namespace of the referenced entity. If empty, the same namespace as the referring resource is implied.</p> <code>name</code>  string  <p>Name is the name of the referenced entity.</p> <code>uid</code>  k8s.io/apimachinery/pkg/types.UID  <p>UID is the UID of the referenced entity.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/#networking.ironcore.dev/v1alpha1.NetworkPeeringNetworkRef","title":"NetworkPeeringNetworkRef","text":"<p> (Appears on:NetworkPeering) </p> <p>NetworkPeeringNetworkRef is a reference to a network to peer with.</p> Field Description <code>namespace</code>  string  <p>Namespace is the namespace of the referenced entity. If empty, the same namespace as the referring resource is implied.</p> <code>name</code>  string  <p>Name is the name of the referenced entity.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/#networking.ironcore.dev/v1alpha1.NetworkPeeringState","title":"NetworkPeeringState (<code>string</code> alias)","text":"<p> (Appears on:NetworkPeeringStatus) </p> <p>NetworkPeeringState is the state a NetworkPeering can be in</p> Value Description <p>\"Error\"</p> <p>NetworkPeeringStateError signals that the network peering is in error state.</p> <p>\"Pending\"</p> <p>NetworkPeeringStatePending signals that the network peering is not applied.</p> <p>\"Ready\"</p> <p>NetworkPeeringStateReady signals that the network peering is ready.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/#networking.ironcore.dev/v1alpha1.NetworkPeeringStatus","title":"NetworkPeeringStatus","text":"<p> (Appears on:NetworkStatus) </p> <p>NetworkPeeringStatus is the status of a network peering.</p> Field Description <code>name</code>  string  <p>Name is the name of the network peering.</p> <code>state</code>  NetworkPeeringState  <p>State represents the network peering state</p> <code>prefixes</code>  []PeeringPrefixStatus  <p>Prefixes contains the prefixes exposed to the peered network</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/#networking.ironcore.dev/v1alpha1.NetworkPolicyCondition","title":"NetworkPolicyCondition","text":"<p> (Appears on:NetworkPolicyStatus) </p> <p>NetworkPolicyCondition is one of the conditions of a network policy.</p> Field Description <code>type</code>  NetworkPolicyConditionType  <p>Type is the type of the condition.</p> <code>status</code>  Kubernetes core/v1.ConditionStatus  <p>Status is the status of the condition.</p> <code>reason</code>  string  <p>Reason is a machine-readable indication of why the condition is in a certain state.</p> <code>message</code>  string  <p>Message is a human-readable explanation of why the condition has a certain reason / state.</p> <code>observedGeneration</code>  int64  <p>ObservedGeneration represents the .metadata.generation that the condition was set based upon.</p> <code>lastTransitionTime</code>  Kubernetes meta/v1.Time  <p>LastTransitionTime is the last time the status of a condition has transitioned from one state to another.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/#networking.ironcore.dev/v1alpha1.NetworkPolicyConditionType","title":"NetworkPolicyConditionType (<code>string</code> alias)","text":"<p> (Appears on:NetworkPolicyCondition) </p> <p>NetworkPolicyConditionType is a type a NetworkPolicyCondition can have.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/#networking.ironcore.dev/v1alpha1.NetworkPolicyEgressRule","title":"NetworkPolicyEgressRule","text":"<p> (Appears on:NetworkPolicySpec) </p> <p>NetworkPolicyEgressRule describes a rule to regulate egress traffic with.</p> Field Description <code>ports</code>  []NetworkPolicyPort  <p>Ports specifies the list of destination ports that can be called with this rule. Each item in this list is combined using a logical OR. Empty matches all ports. As soon as a single item is present, only these ports are allowed.</p> <code>to</code>  []NetworkPolicyPeer  <p>To specifies the list of destinations which the selected network interfaces should be able to send traffic to. Fields are combined using a logical OR. Empty matches all destinations. As soon as a single item is present, only these peers are allowed.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/#networking.ironcore.dev/v1alpha1.NetworkPolicyIngressRule","title":"NetworkPolicyIngressRule","text":"<p> (Appears on:NetworkPolicySpec) </p> <p>NetworkPolicyIngressRule describes a rule to regulate ingress traffic with.</p> Field Description <code>ports</code>  []NetworkPolicyPort  <p>Ports specifies the list of ports which should be made accessible for this rule. Each item in this list is combined using a logical OR. Empty matches all ports. As soon as a single item is present, only these ports are allowed.</p> <code>from</code>  []NetworkPolicyPeer  <p>From specifies the list of sources which should be able to send traffic to the selected network interfaces. Fields are combined using a logical OR. Empty matches all sources. As soon as a single item is present, only these peers are allowed.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/#networking.ironcore.dev/v1alpha1.NetworkPolicyPeer","title":"NetworkPolicyPeer","text":"<p> (Appears on:NetworkPolicyEgressRule, NetworkPolicyIngressRule) </p> <p>NetworkPolicyPeer describes a peer to allow traffic to / from.</p> Field Description <code>objectSelector</code>  github.com/ironcore-dev/ironcore/api/core/v1alpha1.ObjectSelector  <p>ObjectSelector selects peers with the given kind matching the label selector. Exclusive with other peer specifiers.</p> <code>ipBlock</code>  IPBlock  <p>IPBlock specifies the ip block from or to which network traffic may come.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/#networking.ironcore.dev/v1alpha1.NetworkPolicyPort","title":"NetworkPolicyPort","text":"<p> (Appears on:NetworkPolicyEgressRule, NetworkPolicyIngressRule) </p> <p>NetworkPolicyPort describes a port to allow traffic on</p> Field Description <code>protocol</code>  Kubernetes core/v1.Protocol  <p>Protocol (TCP, UDP, or SCTP) which traffic must match. If not specified, this field defaults to TCP.</p> <code>port</code>  int32  <p>The port on the given protocol. If this field is not provided, this matches all port names and numbers. If present, only traffic on the specified protocol AND port will be matched.</p> <code>endPort</code>  int32  <p>EndPort indicates that the range of ports from Port to EndPort, inclusive, should be allowed by the policy. This field cannot be defined if the port field is not defined. The endPort must be equal or greater than port.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/#networking.ironcore.dev/v1alpha1.NetworkPolicySpec","title":"NetworkPolicySpec","text":"<p> (Appears on:NetworkPolicy) </p> <p>NetworkPolicySpec defines the desired state of NetworkPolicy.</p> Field Description <code>networkRef</code>  Kubernetes core/v1.LocalObjectReference  <p>NetworkRef is the network to regulate using this policy.</p> <code>networkInterfaceSelector</code>  Kubernetes meta/v1.LabelSelector  <p>NetworkInterfaceSelector selects the network interfaces that are subject to this policy.</p> <code>ingress</code>  []NetworkPolicyIngressRule  <p>Ingress specifies rules for ingress traffic.</p> <code>egress</code>  []NetworkPolicyEgressRule  <p>Egress specifies rules for egress traffic.</p> <code>policyTypes</code>  []PolicyType  <p>PolicyTypes specifies the types of policies this network policy contains.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/#networking.ironcore.dev/v1alpha1.NetworkPolicyStatus","title":"NetworkPolicyStatus","text":"<p> (Appears on:NetworkPolicy) </p> <p>NetworkPolicyStatus defines the observed state of NetworkPolicy.</p> Field Description <code>conditions</code>  []NetworkPolicyCondition  <p>Conditions are various conditions of the NetworkPolicy.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/#networking.ironcore.dev/v1alpha1.NetworkSpec","title":"NetworkSpec","text":"<p> (Appears on:Network) </p> <p>NetworkSpec defines the desired state of Network</p> Field Description <code>providerID</code>  string  <p>ProviderID is the provider-internal ID of the network.</p> <code>peerings</code>  []NetworkPeering  (Optional) <p>Peerings are the network peerings with this network.</p> <code>incomingPeerings</code>  []NetworkPeeringClaimRef  (Optional) <p>PeeringClaimRefs are the peering claim references of other networks.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/#networking.ironcore.dev/v1alpha1.NetworkState","title":"NetworkState (<code>string</code> alias)","text":"<p> (Appears on:NetworkStatus) </p> <p>NetworkState is the state of a network.</p> Value Description <p>\"Available\"</p> <p>NetworkStateAvailable means the network is ready to use.</p> <p>\"Error\"</p> <p>NetworkStateError means the network is in an error state.</p> <p>\"Pending\"</p> <p>NetworkStatePending means the network is being provisioned.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/#networking.ironcore.dev/v1alpha1.NetworkStatus","title":"NetworkStatus","text":"<p> (Appears on:Network) </p> <p>NetworkStatus defines the observed state of Network</p> Field Description <code>state</code>  NetworkState  <p>State is the state of the machine.</p> <code>peerings</code>  []NetworkPeeringStatus  (Optional) <p>Peerings contains the states of the network peerings for the network.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/#networking.ironcore.dev/v1alpha1.PeeringPrefix","title":"PeeringPrefix","text":"<p> (Appears on:NetworkPeering) </p> <p>PeeringPrefixes defines prefixes to be exposed to the peered network</p> Field Description <code>name</code>  string  <p>Name is the semantical name of the peering prefixes</p> <code>prefix</code>  github.com/ironcore-dev/ironcore/api/common/v1alpha1.IPPrefix  <p>CIDR to be exposed to the peered network</p> <code>prefixRef</code>  Kubernetes core/v1.LocalObjectReference  <p>PrefixRef is the reference to the prefix to be exposed to peered network An empty namespace indicates that the prefix resides in the same namespace as the source network.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/#networking.ironcore.dev/v1alpha1.PeeringPrefixStatus","title":"PeeringPrefixStatus","text":"<p> (Appears on:NetworkPeeringStatus) </p> <p>PeeringPrefixStatus lists prefixes exposed to peered network</p> Field Description <code>name</code>  string  <p>Name is the name of the peering prefix</p> <code>prefix</code>  github.com/ironcore-dev/ironcore/api/common/v1alpha1.IPPrefix  <p>CIDR exposed to the peered network</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/#networking.ironcore.dev/v1alpha1.PolicyType","title":"PolicyType (<code>string</code> alias)","text":"<p> (Appears on:NetworkPolicySpec) </p> <p>PolicyType is a type of policy.</p> Value Description <p>\"Egress\"</p> <p>PolicyTypeEgress is a policy that describes egress traffic.</p> <p>\"Ingress\"</p> <p>PolicyTypeIngress is a policy that describes ingress traffic.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/#networking.ironcore.dev/v1alpha1.PrefixSource","title":"PrefixSource","text":"<p> (Appears on:NetworkInterfaceSpec) </p> Field Description <code>value</code>  github.com/ironcore-dev/ironcore/api/common/v1alpha1.IPPrefix  <p>Value specifies a static prefix to use.</p> <code>ephemeral</code>  EphemeralPrefixSource  <p>Ephemeral specifies a prefix by creating an ephemeral ipam.Prefix to allocate the prefix with.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/#networking.ironcore.dev/v1alpha1.ReclaimPolicyType","title":"ReclaimPolicyType (<code>string</code> alias)","text":"<p> (Appears on:EphemeralVirtualIPSpec) </p> <p>ReclaimPolicyType is the ironcore ReclaimPolicy of a VirtualIP.</p> Value Description <p>\"Delete\"</p> <p>ReclaimPolicyTypeDelete is used for any VirtualIP that is deleted when the claim of VirtualIP is released.</p> <p>\"Retain\"</p> <p>ReclaimPolicyTypeRetain is used for any VirtualIP that is retained when the claim of VirtualIP is released.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/#networking.ironcore.dev/v1alpha1.VirtualIPSource","title":"VirtualIPSource","text":"<p> (Appears on:NetworkInterfaceSpec) </p> <p>VirtualIPSource is the definition of how to obtain a VirtualIP.</p> Field Description <code>virtualIPRef</code>  Kubernetes core/v1.LocalObjectReference  <p>VirtualIPRef references a VirtualIP to use.</p> <code>ephemeral</code>  EphemeralVirtualIPSource  <p>Ephemeral instructs to create an ephemeral (i.e. coupled to the lifetime of the surrounding object) VirtualIP.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/#networking.ironcore.dev/v1alpha1.VirtualIPSpec","title":"VirtualIPSpec","text":"<p> (Appears on:VirtualIP, EphemeralVirtualIPSpec) </p> <p>VirtualIPSpec defines the desired state of a VirtualIP</p> Field Description <code>type</code>  VirtualIPType  <p>Type is the type of VirtualIP.</p> <code>ipFamily</code>  Kubernetes core/v1.IPFamily  <p>IPFamily is the ip family of the VirtualIP.</p> <code>targetRef</code>  github.com/ironcore-dev/ironcore/api/common/v1alpha1.LocalUIDReference  <p>TargetRef references the target for this VirtualIP (currently only NetworkInterface).</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/#networking.ironcore.dev/v1alpha1.VirtualIPStatus","title":"VirtualIPStatus","text":"<p> (Appears on:VirtualIP) </p> <p>VirtualIPStatus defines the observed state of VirtualIP</p> Field Description <code>ip</code>  github.com/ironcore-dev/ironcore/api/common/v1alpha1.IP  <p>IP is the allocated IP, if any.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/#networking.ironcore.dev/v1alpha1.VirtualIPTemplateSpec","title":"VirtualIPTemplateSpec","text":"<p> (Appears on:EphemeralVirtualIPSource) </p> <p>VirtualIPTemplateSpec is the specification of a VirtualIP template.</p> Field Description <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>spec</code>  EphemeralVirtualIPSpec  <code>VirtualIPSpec</code>  VirtualIPSpec  <p> (Members of <code>VirtualIPSpec</code> are embedded into this type.) </p> <p>VirtualIPSpec defines the desired state of a VirtualIP</p> <code>reclaimPolicy</code>  ReclaimPolicyType  <p>ReclaimPolicy is the ReclaimPolicyType of virtualIP</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/networking/#networking.ironcore.dev/v1alpha1.VirtualIPType","title":"VirtualIPType (<code>string</code> alias)","text":"<p> (Appears on:VirtualIPSpec) </p> <p>VirtualIPType is a type of VirtualIP.</p> Value Description <p>\"Public\"</p> <p>VirtualIPTypePublic is a VirtualIP that allocates and routes a stable public IP.</p> <p> Generated with <code>gen-crd-api-reference-docs</code> </p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/overview/","title":"API Reference Documentation","text":"<p>This is the home of the API reference documentation grouped by the various API groups. The content in each subgroup is automatically generated from the Go types in the <code>apis</code> folder. For more information on how the documentation is built and how it can be updated please refer to the Updating API Reference Documentation in the documentation development guide.</p> <ul> <li>Core</li> <li>IPAM</li> <li>Compute</li> <li>Networking</li> <li>Storage</li> <li>Common</li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/storage/","title":"Storage","text":"<p>Packages:</p> <ul> <li> storage.ironcore.dev/v1alpha1 </li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/storage/#storage.ironcore.dev/v1alpha1","title":"storage.ironcore.dev/v1alpha1","text":"<p>Package v1alpha1 is the v1alpha1 version of the API.</p> <p>Resource Types:</p> <ul><li> Bucket </li><li> BucketClass </li><li> BucketPool </li><li> Volume </li><li> VolumeClass </li><li> VolumePool </li></ul>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/storage/#storage.ironcore.dev/v1alpha1.Bucket","title":"Bucket","text":"<p>Bucket is the Schema for the buckets API</p> Field Description <code>apiVersion</code> string <code> storage.ironcore.dev/v1alpha1 </code> <code>kind</code> string  <code>Bucket</code> <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>spec</code>  BucketSpec  <code>bucketClassRef</code>  Kubernetes core/v1.LocalObjectReference  <p>BucketClassRef is the BucketClass of a bucket If empty, an external controller has to provision the bucket.</p> <code>bucketPoolSelector</code>  map[string]string  <p>BucketPoolSelector selects a suitable BucketPoolRef by the given labels.</p> <code>bucketPoolRef</code>  Kubernetes core/v1.LocalObjectReference  <p>BucketPoolRef indicates which BucketPool to use for a bucket. If unset, the scheduler will figure out a suitable BucketPoolRef.</p> <code>tolerations</code>  []github.com/ironcore-dev/ironcore/api/common/v1alpha1.Toleration  <p>Tolerations define tolerations the Bucket has. Only any BucketPool whose taints covered by Tolerations will be considered to host the Bucket.</p> <code>status</code>  BucketStatus"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/storage/#storage.ironcore.dev/v1alpha1.BucketClass","title":"BucketClass","text":"<p>BucketClass is the Schema for the bucketclasses API</p> Field Description <code>apiVersion</code> string <code> storage.ironcore.dev/v1alpha1 </code> <code>kind</code> string  <code>BucketClass</code> <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>capabilities</code>  github.com/ironcore-dev/ironcore/api/core/v1alpha1.ResourceList  <p>Capabilities describes the capabilities of a BucketClass.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/storage/#storage.ironcore.dev/v1alpha1.BucketPool","title":"BucketPool","text":"<p>BucketPool is the Schema for the bucketpools API</p> Field Description <code>apiVersion</code> string <code> storage.ironcore.dev/v1alpha1 </code> <code>kind</code> string  <code>BucketPool</code> <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>spec</code>  BucketPoolSpec  <code>providerID</code>  string  <p>ProviderID identifies the BucketPool on provider side.</p> <code>taints</code>  []github.com/ironcore-dev/ironcore/api/common/v1alpha1.Taint  <p>Taints of the BucketPool. Only Buckets who tolerate all the taints will land in the BucketPool.</p> <code>status</code>  BucketPoolStatus"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/storage/#storage.ironcore.dev/v1alpha1.Volume","title":"Volume","text":"<p>Volume is the Schema for the volumes API</p> Field Description <code>apiVersion</code> string <code> storage.ironcore.dev/v1alpha1 </code> <code>kind</code> string  <code>Volume</code> <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>spec</code>  VolumeSpec  <code>volumeClassRef</code>  Kubernetes core/v1.LocalObjectReference  <p>VolumeClassRef is the VolumeClass of a volume If empty, an external controller has to provision the volume.</p> <code>volumePoolSelector</code>  map[string]string  <p>VolumePoolSelector selects a suitable VolumePoolRef by the given labels.</p> <code>volumePoolRef</code>  Kubernetes core/v1.LocalObjectReference  <p>VolumePoolRef indicates which VolumePool to use for a volume. If unset, the scheduler will figure out a suitable VolumePoolRef.</p> <code>claimRef</code>  github.com/ironcore-dev/ironcore/api/common/v1alpha1.LocalUIDReference  <p>ClaimRef is the reference to the claiming entity of the Volume.</p> <code>resources</code>  github.com/ironcore-dev/ironcore/api/core/v1alpha1.ResourceList  <p>Resources is a description of the volume\u2019s resources and capacity.</p> <code>image</code>  string  <p>Image is an optional image to bootstrap the volume with.</p> <code>imagePullSecretRef</code>  Kubernetes core/v1.LocalObjectReference  <p>ImagePullSecretRef is an optional secret for pulling the image of a volume.</p> <code>unclaimable</code>  bool  <p>Unclaimable marks the volume as unclaimable.</p> <code>tolerations</code>  []github.com/ironcore-dev/ironcore/api/common/v1alpha1.Toleration  <p>Tolerations define tolerations the Volume has. Only any VolumePool whose taints covered by Tolerations will be considered to host the Volume.</p> <code>encryption</code>  VolumeEncryption  <p>Encryption is an optional field which provides attributes to encrypt Volume.</p> <code>status</code>  VolumeStatus"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/storage/#storage.ironcore.dev/v1alpha1.VolumeClass","title":"VolumeClass","text":"<p>VolumeClass is the Schema for the volumeclasses API</p> Field Description <code>apiVersion</code> string <code> storage.ironcore.dev/v1alpha1 </code> <code>kind</code> string  <code>VolumeClass</code> <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>capabilities</code>  github.com/ironcore-dev/ironcore/api/core/v1alpha1.ResourceList  <p>Capabilities describes the capabilities of a VolumeClass.</p> <code>resizePolicy</code>  ResizePolicy  <p>ResizePolicy describes the supported expansion policy of a VolumeClass. If not set default to Static expansion policy.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/storage/#storage.ironcore.dev/v1alpha1.VolumePool","title":"VolumePool","text":"<p>VolumePool is the Schema for the volumepools API</p> Field Description <code>apiVersion</code> string <code> storage.ironcore.dev/v1alpha1 </code> <code>kind</code> string  <code>VolumePool</code> <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>spec</code>  VolumePoolSpec  <code>providerID</code>  string  <p>ProviderID identifies the VolumePool on provider side.</p> <code>taints</code>  []github.com/ironcore-dev/ironcore/api/common/v1alpha1.Taint  <p>Taints of the VolumePool. Only Volumes who tolerate all the taints will land in the VolumePool.</p> <code>status</code>  VolumePoolStatus"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/storage/#storage.ironcore.dev/v1alpha1.BucketAccess","title":"BucketAccess","text":"<p> (Appears on:BucketStatus) </p> <p>BucketAccess represents information on how to access a bucket.</p> Field Description <code>secretRef</code>  Kubernetes core/v1.LocalObjectReference  <p>SecretRef references the Secret containing the access credentials to consume a Bucket.</p> <code>endpoint</code>  string  <p>Endpoint defines address of the Bucket REST-API.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/storage/#storage.ironcore.dev/v1alpha1.BucketCondition","title":"BucketCondition","text":"<p> (Appears on:BucketStatus) </p> <p>BucketCondition is one of the conditions of a bucket.</p> Field Description <code>type</code>  BucketConditionType  <p>Type is the type of the condition.</p> <code>status</code>  Kubernetes core/v1.ConditionStatus  <p>Status is the status of the condition.</p> <code>reason</code>  string  <p>Reason is a machine-readable indication of why the condition is in a certain state.</p> <code>message</code>  string  <p>Message is a human-readable explanation of why the condition has a certain reason / state.</p> <code>observedGeneration</code>  int64  <p>ObservedGeneration represents the .metadata.generation that the condition was set based upon.</p> <code>lastTransitionTime</code>  Kubernetes meta/v1.Time  <p>LastTransitionTime is the last time the status of a condition has transitioned from one state to another.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/storage/#storage.ironcore.dev/v1alpha1.BucketConditionType","title":"BucketConditionType (<code>string</code> alias)","text":"<p> (Appears on:BucketCondition) </p> <p>BucketConditionType is a type a BucketCondition can have.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/storage/#storage.ironcore.dev/v1alpha1.BucketPoolSpec","title":"BucketPoolSpec","text":"<p> (Appears on:BucketPool) </p> <p>BucketPoolSpec defines the desired state of BucketPool</p> Field Description <code>providerID</code>  string  <p>ProviderID identifies the BucketPool on provider side.</p> <code>taints</code>  []github.com/ironcore-dev/ironcore/api/common/v1alpha1.Taint  <p>Taints of the BucketPool. Only Buckets who tolerate all the taints will land in the BucketPool.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/storage/#storage.ironcore.dev/v1alpha1.BucketPoolState","title":"BucketPoolState (<code>string</code> alias)","text":"<p> (Appears on:BucketPoolStatus) </p> Value Description <p>\"Available\"</p> <p>\"Pending\"</p> <p>\"Unavailable\"</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/storage/#storage.ironcore.dev/v1alpha1.BucketPoolStatus","title":"BucketPoolStatus","text":"<p> (Appears on:BucketPool) </p> <p>BucketPoolStatus defines the observed state of BucketPool</p> Field Description <code>state</code>  BucketPoolState  <p>State represents the infrastructure state of a BucketPool.</p> <code>availableBucketClasses</code>  []Kubernetes core/v1.LocalObjectReference  <p>AvailableBucketClasses list the references of any supported BucketClass of this pool</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/storage/#storage.ironcore.dev/v1alpha1.BucketSpec","title":"BucketSpec","text":"<p> (Appears on:Bucket, BucketTemplateSpec) </p> <p>BucketSpec defines the desired state of Bucket</p> Field Description <code>bucketClassRef</code>  Kubernetes core/v1.LocalObjectReference  <p>BucketClassRef is the BucketClass of a bucket If empty, an external controller has to provision the bucket.</p> <code>bucketPoolSelector</code>  map[string]string  <p>BucketPoolSelector selects a suitable BucketPoolRef by the given labels.</p> <code>bucketPoolRef</code>  Kubernetes core/v1.LocalObjectReference  <p>BucketPoolRef indicates which BucketPool to use for a bucket. If unset, the scheduler will figure out a suitable BucketPoolRef.</p> <code>tolerations</code>  []github.com/ironcore-dev/ironcore/api/common/v1alpha1.Toleration  <p>Tolerations define tolerations the Bucket has. Only any BucketPool whose taints covered by Tolerations will be considered to host the Bucket.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/storage/#storage.ironcore.dev/v1alpha1.BucketState","title":"BucketState (<code>string</code> alias)","text":"<p> (Appears on:BucketStatus) </p> <p>BucketState represents the infrastructure state of a Bucket.</p> Value Description <p>\"Available\"</p> <p>BucketStateAvailable reports whether a Bucket is available to be used.</p> <p>\"Error\"</p> <p>BucketStateError reports that a Bucket is in an error state.</p> <p>\"Pending\"</p> <p>BucketStatePending reports whether a Bucket is about to be ready.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/storage/#storage.ironcore.dev/v1alpha1.BucketStatus","title":"BucketStatus","text":"<p> (Appears on:Bucket) </p> <p>BucketStatus defines the observed state of Bucket</p> Field Description <code>state</code>  BucketState  <p>State represents the infrastructure state of a Bucket.</p> <code>lastStateTransitionTime</code>  Kubernetes meta/v1.Time  <p>LastStateTransitionTime is the last time the State transitioned between values.</p> <code>access</code>  BucketAccess  <p>Access specifies how to access a Bucket. This is set by the bucket provider when the bucket is provisioned.</p> <code>conditions</code>  []BucketCondition  <p>Conditions are the conditions of a bucket.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/storage/#storage.ironcore.dev/v1alpha1.BucketTemplateSpec","title":"BucketTemplateSpec","text":"<p>BucketTemplateSpec is the specification of a Bucket template.</p> Field Description <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>spec</code>  BucketSpec  <code>bucketClassRef</code>  Kubernetes core/v1.LocalObjectReference  <p>BucketClassRef is the BucketClass of a bucket If empty, an external controller has to provision the bucket.</p> <code>bucketPoolSelector</code>  map[string]string  <p>BucketPoolSelector selects a suitable BucketPoolRef by the given labels.</p> <code>bucketPoolRef</code>  Kubernetes core/v1.LocalObjectReference  <p>BucketPoolRef indicates which BucketPool to use for a bucket. If unset, the scheduler will figure out a suitable BucketPoolRef.</p> <code>tolerations</code>  []github.com/ironcore-dev/ironcore/api/common/v1alpha1.Toleration  <p>Tolerations define tolerations the Bucket has. Only any BucketPool whose taints covered by Tolerations will be considered to host the Bucket.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/storage/#storage.ironcore.dev/v1alpha1.ResizePolicy","title":"ResizePolicy (<code>string</code> alias)","text":"<p> (Appears on:VolumeClass) </p> <p>ResizePolicy is a type of policy.</p> Value Description <p>\"ExpandOnly\"</p> <p>ResizePolicyExpandOnly is a policy that only allows the expansion of a Volume.</p> <p>\"Static\"</p> <p>ResizePolicyStatic is a policy that does not allow the expansion of a Volume.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/storage/#storage.ironcore.dev/v1alpha1.VolumeAccess","title":"VolumeAccess","text":"<p> (Appears on:VolumeStatus) </p> <p>VolumeAccess represents information on how to access a volume.</p> Field Description <code>secretRef</code>  Kubernetes core/v1.LocalObjectReference  <p>SecretRef references the Secret containing the access credentials to consume a Volume.</p> <code>driver</code>  string  <p>Driver is the name of the drive to use for this volume. Required.</p> <code>handle</code>  string  <p>Handle is the unique handle of the volume.</p> <code>volumeAttributes</code>  map[string]string  <p>VolumeAttributes are attributes of the volume to use.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/storage/#storage.ironcore.dev/v1alpha1.VolumeCondition","title":"VolumeCondition","text":"<p> (Appears on:VolumeStatus) </p> <p>VolumeCondition is one of the conditions of a volume.</p> Field Description <code>type</code>  VolumeConditionType  <p>Type is the type of the condition.</p> <code>status</code>  Kubernetes core/v1.ConditionStatus  <p>Status is the status of the condition.</p> <code>reason</code>  string  <p>Reason is a machine-readable indication of why the condition is in a certain state.</p> <code>message</code>  string  <p>Message is a human-readable explanation of why the condition has a certain reason / state.</p> <code>observedGeneration</code>  int64  <p>ObservedGeneration represents the .metadata.generation that the condition was set based upon.</p> <code>lastTransitionTime</code>  Kubernetes meta/v1.Time  <p>LastTransitionTime is the last time the status of a condition has transitioned from one state to another.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/storage/#storage.ironcore.dev/v1alpha1.VolumeConditionType","title":"VolumeConditionType (<code>string</code> alias)","text":"<p> (Appears on:VolumeCondition) </p> <p>VolumeConditionType is a type a VolumeCondition can have.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/storage/#storage.ironcore.dev/v1alpha1.VolumeEncryption","title":"VolumeEncryption","text":"<p> (Appears on:VolumeSpec) </p> <p>VolumeEncryption represents information to encrypt a volume.</p> Field Description <code>secretRef</code>  Kubernetes core/v1.LocalObjectReference  <p>SecretRef references the Secret containing the encryption key to encrypt a Volume. This secret is created by user with encryptionKey as Key and base64 encoded 256-bit encryption key as Value.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/storage/#storage.ironcore.dev/v1alpha1.VolumePoolCondition","title":"VolumePoolCondition","text":"<p> (Appears on:VolumePoolStatus) </p> <p>VolumePoolCondition is one of the conditions of a volume.</p> Field Description <code>type</code>  VolumePoolConditionType  <p>Type is the type of the condition.</p> <code>status</code>  Kubernetes core/v1.ConditionStatus  <p>Status is the status of the condition.</p> <code>reason</code>  string  <p>Reason is a machine-readable indication of why the condition is in a certain state.</p> <code>message</code>  string  <p>Message is a human-readable explanation of why the condition has a certain reason / state.</p> <code>observedGeneration</code>  int64  <p>ObservedGeneration represents the .metadata.generation that the condition was set based upon.</p> <code>lastTransitionTime</code>  Kubernetes meta/v1.Time  <p>LastTransitionTime is the last time the status of a condition has transitioned from one state to another.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/storage/#storage.ironcore.dev/v1alpha1.VolumePoolConditionType","title":"VolumePoolConditionType (<code>string</code> alias)","text":"<p> (Appears on:VolumePoolCondition) </p> <p>VolumePoolConditionType is a type a VolumePoolCondition can have.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/storage/#storage.ironcore.dev/v1alpha1.VolumePoolSpec","title":"VolumePoolSpec","text":"<p> (Appears on:VolumePool) </p> <p>VolumePoolSpec defines the desired state of VolumePool</p> Field Description <code>providerID</code>  string  <p>ProviderID identifies the VolumePool on provider side.</p> <code>taints</code>  []github.com/ironcore-dev/ironcore/api/common/v1alpha1.Taint  <p>Taints of the VolumePool. Only Volumes who tolerate all the taints will land in the VolumePool.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/storage/#storage.ironcore.dev/v1alpha1.VolumePoolState","title":"VolumePoolState (<code>string</code> alias)","text":"<p> (Appears on:VolumePoolStatus) </p> Value Description <p>\"Available\"</p> <p>\"Pending\"</p> <p>\"Unavailable\"</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/storage/#storage.ironcore.dev/v1alpha1.VolumePoolStatus","title":"VolumePoolStatus","text":"<p> (Appears on:VolumePool) </p> <p>VolumePoolStatus defines the observed state of VolumePool</p> Field Description <code>state</code>  VolumePoolState  <code>conditions</code>  []VolumePoolCondition  <code>availableVolumeClasses</code>  []Kubernetes core/v1.LocalObjectReference  <p>AvailableVolumeClasses list the references of any supported VolumeClass of this pool</p> <code>capacity</code>  github.com/ironcore-dev/ironcore/api/core/v1alpha1.ResourceList  <p>Capacity represents the total resources of a machine pool.</p> <code>allocatable</code>  github.com/ironcore-dev/ironcore/api/core/v1alpha1.ResourceList  <p>Allocatable represents the resources of a machine pool that are available for scheduling.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/storage/#storage.ironcore.dev/v1alpha1.VolumeSpec","title":"VolumeSpec","text":"<p> (Appears on:Volume, VolumeTemplateSpec) </p> <p>VolumeSpec defines the desired state of Volume</p> Field Description <code>volumeClassRef</code>  Kubernetes core/v1.LocalObjectReference  <p>VolumeClassRef is the VolumeClass of a volume If empty, an external controller has to provision the volume.</p> <code>volumePoolSelector</code>  map[string]string  <p>VolumePoolSelector selects a suitable VolumePoolRef by the given labels.</p> <code>volumePoolRef</code>  Kubernetes core/v1.LocalObjectReference  <p>VolumePoolRef indicates which VolumePool to use for a volume. If unset, the scheduler will figure out a suitable VolumePoolRef.</p> <code>claimRef</code>  github.com/ironcore-dev/ironcore/api/common/v1alpha1.LocalUIDReference  <p>ClaimRef is the reference to the claiming entity of the Volume.</p> <code>resources</code>  github.com/ironcore-dev/ironcore/api/core/v1alpha1.ResourceList  <p>Resources is a description of the volume\u2019s resources and capacity.</p> <code>image</code>  string  <p>Image is an optional image to bootstrap the volume with.</p> <code>imagePullSecretRef</code>  Kubernetes core/v1.LocalObjectReference  <p>ImagePullSecretRef is an optional secret for pulling the image of a volume.</p> <code>unclaimable</code>  bool  <p>Unclaimable marks the volume as unclaimable.</p> <code>tolerations</code>  []github.com/ironcore-dev/ironcore/api/common/v1alpha1.Toleration  <p>Tolerations define tolerations the Volume has. Only any VolumePool whose taints covered by Tolerations will be considered to host the Volume.</p> <code>encryption</code>  VolumeEncryption  <p>Encryption is an optional field which provides attributes to encrypt Volume.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/storage/#storage.ironcore.dev/v1alpha1.VolumeState","title":"VolumeState (<code>string</code> alias)","text":"<p> (Appears on:VolumeStatus) </p> <p>VolumeState represents the infrastructure state of a Volume.</p> Value Description <p>\"Available\"</p> <p>VolumeStateAvailable reports whether a Volume is available to be used.</p> <p>\"Error\"</p> <p>VolumeStateError reports that a Volume is in an error state.</p> <p>\"Pending\"</p> <p>VolumeStatePending reports whether a Volume is about to be ready.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/storage/#storage.ironcore.dev/v1alpha1.VolumeStatus","title":"VolumeStatus","text":"<p> (Appears on:Volume) </p> <p>VolumeStatus defines the observed state of Volume</p> Field Description <code>state</code>  VolumeState  <p>State represents the infrastructure state of a Volume.</p> <code>lastStateTransitionTime</code>  Kubernetes meta/v1.Time  <p>LastStateTransitionTime is the last time the State transitioned between values.</p> <code>access</code>  VolumeAccess  <p>Access specifies how to access a Volume. This is set by the volume provider when the volume is provisioned.</p> <code>conditions</code>  []VolumeCondition  <p>Conditions are the conditions of a volume.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/api-reference/storage/#storage.ironcore.dev/v1alpha1.VolumeTemplateSpec","title":"VolumeTemplateSpec","text":"<p>VolumeTemplateSpec is the specification of a Volume template.</p> Field Description <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>spec</code>  VolumeSpec  <code>volumeClassRef</code>  Kubernetes core/v1.LocalObjectReference  <p>VolumeClassRef is the VolumeClass of a volume If empty, an external controller has to provision the volume.</p> <code>volumePoolSelector</code>  map[string]string  <p>VolumePoolSelector selects a suitable VolumePoolRef by the given labels.</p> <code>volumePoolRef</code>  Kubernetes core/v1.LocalObjectReference  <p>VolumePoolRef indicates which VolumePool to use for a volume. If unset, the scheduler will figure out a suitable VolumePoolRef.</p> <code>claimRef</code>  github.com/ironcore-dev/ironcore/api/common/v1alpha1.LocalUIDReference  <p>ClaimRef is the reference to the claiming entity of the Volume.</p> <code>resources</code>  github.com/ironcore-dev/ironcore/api/core/v1alpha1.ResourceList  <p>Resources is a description of the volume\u2019s resources and capacity.</p> <code>image</code>  string  <p>Image is an optional image to bootstrap the volume with.</p> <code>imagePullSecretRef</code>  Kubernetes core/v1.LocalObjectReference  <p>ImagePullSecretRef is an optional secret for pulling the image of a volume.</p> <code>unclaimable</code>  bool  <p>Unclaimable marks the volume as unclaimable.</p> <code>tolerations</code>  []github.com/ironcore-dev/ironcore/api/common/v1alpha1.Toleration  <p>Tolerations define tolerations the Volume has. Only any VolumePool whose taints covered by Tolerations will be considered to host the Volume.</p> <code>encryption</code>  VolumeEncryption  <p>Encryption is an optional field which provides attributes to encrypt Volume.</p> <p> Generated with <code>gen-crd-api-reference-docs</code> </p>"},{"location":"infrastructure-as-a-service/components/ironcore/architecture/iri/","title":"IRI - IronCore Runtime Interface","text":""},{"location":"infrastructure-as-a-service/components/ironcore/architecture/iri/#introduction","title":"Introduction","text":"<p>The IronCore Runtime Interface (IRI) is a GRPC-based abstraction layer introduced to ease the implementation of a <code>poollet</code> and <code>pool provider</code>. </p> <p>A <code>poollet</code> does not have any knowledge how the resources are materialized and where the <code>pool provider</code> runs. The responsibility of the <code>poollet</code> is to collect and resolve the needed dependencies to materialize a resource.</p> <p>A <code>pool provider</code> implements the IRI, where the IRI defines the correct creation and management of resources  handled by a <code>pool provider</code>. A <code>pool provider</code> of the IRI should follow the interface defined in the IRI APIs. </p> <pre><code>graph LR\n    P[poollet] --&gt; IRI\n    IRI{IRI} --&gt; B\n    B[pool provider]</code></pre>"},{"location":"infrastructure-as-a-service/components/ironcore/architecture/iri/#pool-provider","title":"<code>pool provider</code>","text":"<p>A <code>pool provider</code> represents a specific implementation of resources managed by a Pool. The implementation details of the <code>pool provider</code> depend on the type of resource it handles, such as Compute or Storage resources.</p> <p>Based on the implementation of a <code>pool provider</code> it can serve multiple use-cases:  - to broker resources between different clusters e.g. volume-broker - to materialize resources e.g. block devices created in a Ceph cluster via the cephlet</p>"},{"location":"infrastructure-as-a-service/components/ironcore/architecture/iri/#interface-methods","title":"Interface Methods","text":"<p>The IRI defines several interface methods categIRIzed into Compute, Storage, and Bucket.</p> <ul> <li>Compute Methods</li> <li>Storage Methods</li> <li>Bucket Methods</li> </ul> <p>The IRI definition can be extended in the future with new resource groups.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/architecture/iri/#diagram","title":"Diagram","text":"<p>Below is a diagram illustrating the relationship between <code>poollets</code>, IRI, and <code>pool providers</code> in the <code>ironcore</code> project.</p> <pre><code>graph TB\n    A[Machine] -- scheduled on --&gt; B[MachinePool]\n    C[Volume] -- scheduled on --&gt; D[VolumePool]\n    B -- announced by --&gt; E[machinepoollet]\n    D -- announced by --&gt; F[volumepoollet]\n    E -- GRPC calls --&gt; G[IRI compute provider]\n    F -- GRPC calls --&gt; H[IRI storage provider]\n    G -.sidecar to.- E\n    H -.sidecar to.- F</code></pre> <p>This diagram illustrates:</p> <ul> <li><code>Machine</code> resources are scheduled on a <code>MachinePool</code> which is announced by the <code>machinepoollet</code>.</li> <li>Similarly, <code>Volume</code> resources are scheduled on a <code>VolumePool</code> which is announced by the <code>volumepoollet</code>.</li> <li>The <code>machinepoollet</code> and <code>volumepoollet</code> each have an IRI <code>provider</code> sidecar, which provides a GRPC interface for  making calls to create, update, or delete resources.</li> <li>The IRI <code>provider</code> (Compute) is a sidecar to the <code>machinepoollet</code> and the IRI <code>provider</code> (Storage) is a sidecar to the  <code>volumepoollet</code>. They handle GRPC calls from their respective <code>poollets</code> and interact with the actual resources.</li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/architecture/overview/","title":"IronCore Architecture","text":""},{"location":"infrastructure-as-a-service/components/ironcore/concepts/machine-exec-flow/","title":"Machine Exec","text":"<p>The <code>exec</code> feature allows accessing the serial console of a <code>compute.Machine</code> via the <code>ironcore-apiserver</code>. The following parties are involved in implementing <code>exec</code>:</p> <ul> <li><code>ironcore-apiserver</code></li> <li><code>machinepollet</code></li> <li><code>iri-machine</code> implementor</li> </ul> <p>The connection flow between those components looks like the following:</p> <pre><code>sequenceDiagram\n    participant User as user\n    participant OA as ironcore-apiserver\n    participant MP as machinepoollet\n    participant OM as iri-machine implementor\n\n    User-&gt;&gt;OA: exec request with machine name\n    Note over OA: Get machine by name\n    Note over OA: Get machine pool\n    Note over OA: Find suitable address &amp; port\n    Note over OA: Create URL for exec request\n    OA-&gt;&gt;MP: HTTP request to exec URL\n    Note over MP: Check authentication &amp; authorization\n    MP-&gt;&gt;OM: Call Exec method\n    Note over OM: Provide functioning Exec implementation\n    Note over OM: iri-machine implementor generates unique token\n    Note over OM: Token-associated URL is called\n    Note over OM: Calls exec on its target\n    Note over OM: Proxies response from the ironcore-apiserver to the requester\n    OM--&gt;&gt;MP: Returns URL for exec session\n    MP--&gt;&gt;OA: Proxy response\n    OA--&gt;&gt;User: Proxy response</code></pre>"},{"location":"infrastructure-as-a-service/components/ironcore/concepts/machine-exec-flow/#ironcore-apiserver","title":"<code>ironcore-apiserver</code>","text":"<p>The <code>ironcore-apiserver</code> implements <code>exec</code> as a custom subresource on the <code>Machine</code> resource. In the <code>ironcore</code> REST registry, it is registered as <code>machines/exec</code>.</p> <p>The subresource itself is implemented by implementing the <code>k8s.io/apiserver/pkg/registry/rest.Connecter</code> interface, which allows custom logic for handling <code>CONNECT</code> and their follow-up <code>GET</code> / <code>POST</code> requests.</p> <p>For <code>exec</code>, the <code>ironcore-apiserver</code> knows the name of the machine the user wants to access. It first gets the machine by its name (returning an error if it doesn't exist) and then the machine pool it's assigned to (also returning an error if the machine is not assigned to any pool or the machine pool does not exist).</p> <p>On the machine pool, it looks for a suitable address via the reported <code>MachinePool.Status.Addresses</code>, depending on the configurable preferred address types of the <code>ironcore-apiserver</code>. Once found, it uses the address together with the <code>MachinePool.Status.DaemonEndpoints.MachinepoolletEndpoint.Port</code> to create a URL to make the target <code>exec</code> request to. The URL is of the form</p> <pre><code>https://&lt;host&gt;:&lt;port&gt;/apis/compute.ironcore.dev/namespaces/&lt;namespace&gt;/machines/&lt;machine/exec\n</code></pre> <p>It then makes an http request to that location and proxies the resulting response to the original requester.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/concepts/machine-exec-flow/#machinepoollet","title":"<code>machinepoollet</code>","text":"<p>The <code>machinepoollet</code> provides the HTTP server wrapping the <code>iri-machine</code> implementor. This HTTP server also provides the aforementioned route to serve <code>exec</code> for a machine.</p> <p>When the <code>machinepoollet</code> gets a request to that URL it first checks whether the requesting entity is authenticated &amp; authorized to do an <code>exec</code> request for that machine. It does so by using a delegated authenticator / authorizer against the <code>kube-apiserver</code> the <code>ironcore-apiserver</code> is connected to.</p> <p>Once successfully authenticated &amp; authorized, the <code>machinepoollet</code> calls the <code>Exec</code> method of the <code>iri-machine</code> implementor. This <code>Exec</code> method returns a URL where the <code>exec</code> session for the target machine will be hosted at.</p> <p>It then makes an HTTP request to that URL and proxies the resulting response to the <code>ironcore-apiserver</code>.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/concepts/machine-exec-flow/#iri-machine-implementor","title":"<code>iri-machine</code> Implementor","text":"<p>The <code>iri-machine</code> implementor has to provide a functioning <code>Exec</code> implementation that returns the URL where the actual <code>exec</code> session of the machine is hosted at.</p> <p>For the <code>machinebroker</code>, this is implemented by having an HTTP server that associates the request together with a unique randomly generated token and returns a URL containing that token.</p> <p>Once the URL containing that token is called, the <code>machinebroker</code> looks up the corresponding request and calls <code>exec</code> on its target (different from the original) <code>ironcore-apiserver</code> with the machine namespace and name from the stored request. It then proxies the response from the <code>ironcore-apiserver</code> to the requester.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/development/contribution/","title":"Contributors Guide","text":""},{"location":"infrastructure-as-a-service/components/ironcore/development/contribution/#contributing","title":"Contributing","text":"<p>The IronCore project uses Github to manage reviews of pull requests.</p> <ul> <li> <p>If you are looking to make your first contribution, follow Steps to Contribute</p> </li> <li> <p>If you have a trivial fix or improvement, go ahead and create a pull request and address (with @...) a suitable maintainer of this repository  (see CODEOWNERS  of this repository) in the description of the pull request.</p> </li> <li> <p>If you plan to do something more involved, first discuss your ideas by creating an  issue for this repository. This will avoid unnecessary work and surely give you  and us a good deal of inspiration.</p> </li> </ul> <p>Note</p> <p>Please follow these style guidelines to have your contribution considered by the maintainers: Coding style guidelines Go Code Review Comments, Formatting and style section of Peter Bourgon\u2019s Go: Best Practices for Production Environments.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/development/contribution/#steps-to-contribute","title":"Steps to Contribute","text":"<p>Do you want to work on an issue?  You are welcome to claim an existing one by commenting on it in GitHub. </p> <p>Note</p> <p>Perform a cursory search to see if the issue has already been taken by someone else.  This will prevent misunderstanding and duplication of  effort from contributors on the same issue.</p> <p>If you have questions about one of the issues please comment on them and one of the  maintainers will clarify it.</p> <p>We kindly ask you to follow the Pull Request Checklist to ensure reviews can happen accordingly.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/development/contribution/#contributing-code","title":"Contributing Code","text":"<p>You are welcome to contribute code to the IronCore project in order to fix a bug or to implement a new feature.</p> <p>The following rules govern code contributions:</p> <ul> <li>Contributions must be licensed under the Apache 2.0 License</li> <li>You need to sign the Developer Certificate of Origin.</li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/development/contribution/#contributing-documentation","title":"Contributing Documentation","text":"<p>You are welcome to contribute documentation to the IronCore project.</p> <p>The following rules govern documentation contributions:</p> <ul> <li>Contributions must be licensed under the Creative Commons Attribution 4.0 International License</li> <li>You need to sign the Developer Certificate of Origin.</li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/development/contribution/#developer-certificate-of-origin","title":"Developer Certificate of Origin","text":"<p>Due to legal reasons, contributors will be asked to accept a Developer Certificate of Origin (DCO) before they submit  the first pull request to the IronCore project, this happens in an automated fashion during the submission  process. We use the standard DCO text of the Linux Foundation.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/development/contribution/#pull-request-checklist","title":"Pull Request Checklist","text":"<ul> <li>Fork and clone the repository to you local machine.</li> </ul> <pre><code>git clone git@github.com:YOUR_GITHUB_USER/ironcore.git\ncd ironcore\n</code></pre> <ul> <li>Create a branch from the <code>main</code>  using 'git checkout' command. </li> </ul> <p>Note</p> <p>If needed, rebase to the current <code>main</code> branch before submitting  your pull request. If it doesn't merge properly with <code>main</code> you may be asked to rebase your changes.</p> <pre><code>git checkout -b my_feature\n# rebase if necessary\ngit fetch upstream main\ngit rebase upstream/main\n</code></pre> <ul> <li> <p>Commits should be as small as possible, while ensuring that each commit is correct independently  (i.e. each commit should compile and pass tests).</p> </li> <li> <p>Create your patch and test your changes  before you commit them. Automated test by unit / integration tests are preferred.  If tested manually, provide information about the test scope in the PR description. Now you can commit your changes to your feature branch and push it to your fork.</p> </li> </ul> <pre><code>git add .\ngit commit -m \"Something meaningful\"\ngit push origin my_feature\n</code></pre> <p>Note</p> <p>Alternatively you can amend your commit before pushing if you forgot something by using <code>git commit --amend</code></p> <ul> <li> <p>Create Work In Progress [WIP] pull requests only if you need a clarification or an explicit review before you can  continue your work item.</p> </li> <li> <p>If your patch is not getting reviewed, or you need a specific person to review it, you can @-reply a reviewer asking  for a review in the pull request or a comment.</p> </li> <li> <p>Post review:</p> <ul> <li>If a reviewer requires you to change your commit(s), please test the changes again.</li> <li>Amend the affected commit(s) and force push onto your branch.</li> <li>Set respective comments in your GitHub review as resolved.</li> <li>Create a general PR comment to notify the reviewers that your amendments are ready for another round of review.</li> </ul> </li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/development/contribution/#issues-and-planning","title":"Issues and Planning","text":"<p>We use GitHub issues to track bugs and enhancement requests. Please provide as much context as possible when you open  an issue. The information you provide must be comprehensive enough to understand, reproduce the behavior and find related reports of  that issue for the assignee.  Therefore, contributors may use but aren't restricted to the issue template provided by the IronCore maintainers.</p> <p>Issues and pull requests are tracked in the backlog for this project.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/development/documentation/","title":"Documentation Setup","text":"<p>The documentation of the ironcore project is written primarily using Markdown. All documentation related content can be found in the <code>/docs</code> folder. New content also should be added there. MkDocs and MkDocs Material are then used to render the contents of the <code>/docs</code> folder to have a more user-friendly experience when browsing the projects' documentation.</p> <p>Note</p> <p>One exception to the common contribution process builds the <code>docs/api-reference</code> folder. The folder contains auto-generated CRD reference documentation of the project, no manual contributions should be applied as they will be overwritten in the next generation step. To read more: Updating API Reference Documentation  section.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/development/documentation/#requirements","title":"Requirements:","text":"<p>Following tools are required to work on that package.</p> <ul> <li>Kubernetes cluster access to deploy and test the result (via minikube, kind or docker desktop locally)</li> <li>make - to execute build goals</li> <li>docker - to run the local mkdocs environment</li> <li>git - to be able to commit any changes to repository</li> <li>kubectl (&gt;= v1.23.4) - to be able to talk to the kubernetes cluster</li> </ul> <p>Note</p> <p>If you don't have Docker installed on your machine please follow one of those guides:</p> <ul> <li>Docker Desktop for Mac</li> <li>Docker Desktop for Windows</li> <li>Docker Engine for Linux</li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/development/documentation/#local-development-setup","title":"Local Development Setup","text":"<p>This project contains a local Docker based runtime environment for the documentation part. If you have an access to the docker registry and k8s installation that you can use for development purposes, just run following command and access the output in your browser under http://localhost:8000/:</p> <p><pre><code>make start-docs\n</code></pre> The environment will hot-rebuild your documentation, so there is no need to restart it while you make your changes. If you want to add a new chapter (basically a new file/folder to <code>docs</code> directory) you should add it to the <code>nav</code> section in the <code>mkdocs.yml</code> file in the projects root folder. Use helper Makefile directive to clean up old and stopped container instances.</p> <pre><code>make clean-docs\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ironcore/development/documentation/#writing-content","title":"Writing Content","text":""},{"location":"infrastructure-as-a-service/components/ironcore/development/documentation/#api-reference-documentation","title":"API Reference Documentation","text":"<p>The API reference documentation contains auto-generated description from the CRD definition of the ironcore project. We are using the gen-crd-api-reference-docs project to generate the content. Under the hood we are using <code>go generate</code> instructions defined in each version type <code>doc.go</code>. The needed instructions to generate documentation for the <code>core/v1alpha1</code> types are in the example below:</p> <p><pre><code>//go:generate gen-crd-api-reference-docs -api-dir . -config ../../../hack/api-reference/core-config.json -template-dir ../../../hack/api-reference/template -out-file ../../../docs/api-reference/core.md\n</code></pre> Together with the comments in the corresponding type files <code>go generate</code> will call the <code>gen-crd-api-reference-doc</code> command to generate the output in the <code>/docs/api-reference</code> folder. The project contains a <code>Makefile</code> routine to generate the reference documentation for all types. In case you change any of the types in the <code>apis</code> folder just run:</p> <pre><code>make docs\n</code></pre> <p>Note</p> <p>The generated output should be part of your pull request.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/development/setup/","title":"Local Development Setup","text":""},{"location":"infrastructure-as-a-service/components/ironcore/development/setup/#requirements","title":"Requirements","text":"<ul> <li><code>go</code> &gt;= 1.20</li> <li><code>git</code>, <code>make</code> and <code>kubectl</code></li> <li>Kustomize</li> <li>Access to a Kubernetes cluster (Minikube, kind or a   real cluster)</li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/development/setup/#clone-the-repository","title":"Clone the Repository","text":"<p>To bring up and start locally the <code>ironcore</code> project for development purposes you first need to clone the repository.</p> <pre><code>git clone git@github.com:ironcore-dev/ironcore.git\ncd ironcore\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ironcore/development/setup/#install-cert-manager","title":"Install cert-manager","text":"<p>If there is no cert-manager present in the cluster it needs to be installed.</p> <pre><code>kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.8.0/cert-manager.yaml\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ironcore/development/setup/#install-apis-into-the-cluster","title":"Install APIs into the Cluster","text":"<p>Your Kubernetes API server needs to know about the APIs which come with the <code>ironcore</code> project. To install the APIs your cluster, run</p> <pre><code>make install\n</code></pre> <p>Note: This requires the <code>APISERVER_IMG</code> (Makefile default set to <code>apiserver</code>) to be pullable from your kubernetes cluster. For local development with <code>kind</code>, a make target that builds and loads the api server image and then applies the manifests is available via</p> <pre><code>make kind-install\n</code></pre> <p>Note: In case that there are multiple environments running, ensure that <code>kind get clusters</code> is pointing to the default kind cluster.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/development/setup/#start-the-controller-manager","title":"Start the Controller Manager","text":"<p>The controller manager can be started via the following command</p> <pre><code>make run\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ironcore/development/setup/#apply-sample-manifests","title":"Apply Sample Manifests","text":"<p>The <code>config/samples</code> folder contains samples for all APIs supported by this project. You can apply any of the samples by running</p> <pre><code>kubectl apply -f config/samples/SOME_RESOURCE.yaml\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ironcore/development/setup/#rebuilding-api-type-and-manifests","title":"Rebuilding API Type and Manifests","text":"<p>Everytime a change has been done to any of the types definitions, the corresponding manifests and generated code pieces have to be rebuilt.</p> <pre><code>make generate\nmake manifests\n</code></pre> <p>Note: Make sure your APIs are up-to-date by running <code>make install</code> / <code>make kind-install</code> after your code / manifests have been regenerated.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/development/setup/#setup-formatting-tools","title":"Setup formatting tools","text":"<p>The project uses <code>gofmt</code> and <code>goimports</code> for formatting. <code>gofmt</code> is used with default settings. While <code>goimports</code> should be used with <code>--local github.com/ironcore-dev</code> flag, so that <code>goimports</code> would sort <code>ironcore</code> pkgs separately.</p> <p>You can automate running formatting tools in your IDE.</p> <ul> <li>VSCode -- add following to the <code>settings.json</code>:</li> </ul> <pre><code>    \"go.formatTool\": \"goimports\",\n    \"gopls\": {\n        \"formatting.local\": \"github.com/ironcore-dev\",\n    },\n</code></pre> <ul> <li>Goland -- go to <code>File -&gt; Settings -&gt; Tools -&gt; File Watchers</code> and replace contents of <code>Arguments</code>   with <code>--local github.com/ironcore -w $FilePath$</code></li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/development/setup/#cleanup","title":"Cleanup","text":"<p>To remove the APIs from your cluster, simply run</p> <pre><code>make uninstall\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ironcore/development/testing/","title":"Testing","text":"<p>This project is using Ginkgo as it's primary testing framework in conjunction with Gomega matcher/assertion library.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/development/testing/#unit-tests","title":"Unit Tests","text":"<p>Each package should consist of its own <code>suite_test</code> setup and the corresponding test cases for each component.</p> <p>Example of test suite setup is below:</p> <pre><code>package mypackage\n\nimport (\n    . \"github.com/onsi/ginkgo/v2\"\n    . \"github.com/onsi/gomega\"\n    \"testing\"\n)\n\nfunc Test(t *testing.T) {\n    RegisterFailHandler(ginkgo.Fail)\n    ginkgo.RunSpecs(t, \"MyComponent\")\n}\n</code></pre> <p>The testing code should meet the requirements of be common Ginkgo format</p> <pre><code>package mypackage\n\nimport\n...\n\nvar _ = Describe(\"MyComponent\", func() {\n\n    BeforeEach(func() {\n        // Code to run before each Context\n    })\n\n    Context(\"When doing x\", func() {\n        It(\"Should result in y\", func() {\n            By(\"Creating something in x\")\n            Expect(x.DoSomething()).To(Equal(\"expected result\"))\n        })\n    })\n})\n</code></pre> <p>Note</p> <p>here: Ginkgo documentation. Assertion examples can be found here: Gomega documentation.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/development/testing/#controller-tests","title":"Controller Tests","text":"<p>Setup a local Kubernetes control plane in order to write controller tests. Use <code>envtest</code> as a part of the controller-runtime project.</p> <p>Example of <code>suite_test.go</code> inside a controller package is below:</p> <pre><code>package my_controller_package\n\nimport\n...\n\n// Those global vars are needed later.\nvar cfg *rest.Config\nvar k8sClient client.Client\nvar testEnv *envtest.Environment\n\nfunc TestAPIs(t *testing.T) {\n    RegisterFailHandler(Fail)\n\n    RunSpecsWithDefaultAndCustomReporters(t,\n        \"Controller Suite\",\n        []Reporter{printer.NewlineReporter{}})\n}\n\nvar _ = BeforeSuite(func() {\n    ...\n    // Here is the actual envtest setup. Make sure that the path\n    // to your generated CRDs is correct, as it will be injected\n    // directly into the API server once the envtest environment comes up.\n    testEnv = &amp;envtest.Environment{\n        CRDDirectoryPaths:     []string{filepath.Join(\"..\", \"..\", \"..\", \"config\", \"crd\", \"bases\")},\n        ErrorIfCRDPathMissing: true,\n    }\n    ...\n    // Define scheme\n    err = api.AddToScheme(scheme.Scheme)\n    ...\n    // Create a corresponding Kubernetes client.\n    k8sClient, err = client.New(cfg, client.Options{Scheme: scheme.Scheme})\n    ...\n    k8sManager, err := manager.NewManager(cfg, ctrl.Options{\n        Scheme: scheme.Scheme,\n        // On MacOS it might happen, that the firewall warnings will\n        // popup if you open a port on your machine. It typically\n        // happens due to the metrics endpoint of the controller-manager.\n        // To prevent it, disable it in the local setup\n        // and set the Host parameter to localhost.\n        Host:               \"127.0.0.1\",\n        MetricsBindAddress: \"0\",\n    })\n    ...\n    // Register our reconciler with the manager. In case if you want to test\n    // multiple reconcilers at once you have to register them one by\n    // one in the same fashion as is shown below.\n    err = (&amp;MyObjectReconciler{\n        Client: k8sManager.GetClient(),\n        Scheme: k8sManager.GetScheme(),\n        Log:    ctrl.Log.WithName(\"controllers\").WithName(\"MyObject\"),\n    }).SetupWithManager(k8sManager)\n    ...\n\n    // Start the manager\n    go func() {\n        err = k8sManager.Manager.Start(ctrl.SetupSignalHandler())\n        Expect(err).ToNot(HaveOccurred())\n    }()\n\n}, 60)\n\nvar _ = AfterSuite(func() {\n    By(\"tearing down the test environment\")\n    err := testEnv.Stop()\n    Expect(err).NotTo(HaveOccurred())\n})\n</code></pre> <p>The Ginkgo style tests can be now written in the same manner as described in the Unit Test section. The only difference now is, that you have a working controller manager in the background which is reacting on changes in the Kubernetes API which you can access via the <code>k8sClient</code> to create or modify your resources.</p> <p>More information on the envtest setup you can find in the CRD testing section here: Kubebuilder</p>"},{"location":"infrastructure-as-a-service/components/ironcore/development/testing/#running-tests","title":"Running Tests","text":"<p>Test run can be executed via:</p> <pre><code>make test\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ironcore/development/testing/#goland-integration","title":"Goland Integration","text":"<p>Running static Ginkgo/Gomega tests in Golang should work out of the box. However, in order to make the controller test run from within your IDE you need to expose the following environment variable inside your 'Test Run Configuration'</p> <pre><code>KUBEBUILDER_ASSETS=/PATH_TO_MY_WORKSPACE/ironcore-dev/ironcore/testbin/bin\n</code></pre> <p>This is typically the location of the Kubernetes control plane binaries on your machine.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/","title":"Proposals","text":"<p>This is the home of the <code>ironcore</code> enhancement/extension proposals. You can find the list of accepted proposals  in the poposal folder of our Github repository.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/#submitting-a-new-proposal","title":"Submitting a new proposal","text":"<p>Please use our proposal template to write and submit your proposal via a pull request. </p>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/00-template/","title":"IEP-NNNN: Your short, descriptive title","text":""},{"location":"infrastructure-as-a-service/components/ironcore/proposals/00-template/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Summary</li> <li>Motivation<ul> <li>Goals</li> <li>Non-Goals</li> </ul> </li> <li>Proposal</li> <li>Alternatives</li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/00-template/#summary","title":"Summary","text":""},{"location":"infrastructure-as-a-service/components/ironcore/proposals/00-template/#motivation","title":"Motivation","text":""},{"location":"infrastructure-as-a-service/components/ironcore/proposals/00-template/#goals","title":"Goals","text":""},{"location":"infrastructure-as-a-service/components/ironcore/proposals/00-template/#non-goals","title":"Non-Goals","text":""},{"location":"infrastructure-as-a-service/components/ironcore/proposals/00-template/#proposal","title":"Proposal","text":""},{"location":"infrastructure-as-a-service/components/ironcore/proposals/00-template/#alternatives","title":"Alternatives","text":""},{"location":"infrastructure-as-a-service/components/ironcore/proposals/01-networking-integration/","title":"01 networking integration","text":"<p>title: Networking Integration</p> <p>iep-number: 1</p> <p>creation-date: 2022-17-03</p> <p>status: implementable</p> <p>authors:</p> <ul> <li>\"@adracus\"</li> <li>\"@afritzler\"</li> </ul> <p>reviewers:</p> <ul> <li>\"@adracus\"</li> <li>\"@afritzler\"</li> <li>\"@MalteJ\"</li> <li>\"@guvenc\"</li> <li>\"@gehoern\"</li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/01-networking-integration/#iep-1-networking-integration","title":"IEP-1: Networking Integration","text":""},{"location":"infrastructure-as-a-service/components/ironcore/proposals/01-networking-integration/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Summary</li> <li>Motivation<ul> <li>Goals</li> <li>Non-Goals</li> </ul> </li> <li>Proposal</li> <li>Alternatives</li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/01-networking-integration/#summary","title":"Summary","text":"<p>Networking is a crucial part in a modern cloud system: It enables systems to communicate within themselves and to the outside world. Orchestrating traffic, auditing it and gaining visibility of what is the desired state is key to a modern network architecture.</p> <p>Key of this IEP is to define the user-facing network API as well as its implications on any other type and the overall structure of <code>ironcore</code>.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/01-networking-integration/#motivation","title":"Motivation","text":"<p>Without networking, any machine / process running inside a datacenter cannot interact / affect the outside world. Networking is a crucial component that has to be implemented for ironcore to have business value. In a full-fledged state, networking also enables security to the outside world and within a datacenter itself.</p> <p>The basic use case we want to implement with ironcore is a machine that can access the internet and can be reached from the internet.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/01-networking-integration/#goals","title":"Goals","text":"<ul> <li>Define APIs for managing isolated networks. It should be possible to do conflict-free peering of networks in the   future.</li> <li>Define APIs for assigning / routing public IPs / prefixes to members of a network / subnet.</li> <li>Adapt the <code>compute.Machine</code> type to integrate with the network API.</li> <li>Have fully integrated IP address management for all resources (IPAM).</li> <li>It should be possible to extend the API in the future to achieve the following (listed by decreasing priority):<ul> <li>Regulate Communication within a subnet (plus security concepts)</li> <li>Subnet-to-subnet communication (plus security concepts)</li> <li>Isolated network-to-network communication (plus security concepts)</li> <li>Cross-region isolated network-to-network communication (plus security concepts)</li> </ul> </li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/01-networking-integration/#non-goals","title":"Non-Goals","text":"<ul> <li>Define Load Balancer APIs (L4 sooner in the future, L7 later)</li> <li>Implement any of the future API extensions listed above</li> <li>Allow a user to bring own public IP prefixes</li> <li>Feature-creep beyond a simplistic MVP</li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/01-networking-integration/#proposal","title":"Proposal","text":""},{"location":"infrastructure-as-a-service/components/ironcore/proposals/01-networking-integration/#preface","title":"Preface","text":"<p>As ironcore is Kubernetes-API, it should integrate nicely within the existing ecosystem. Some API design choices are made in that regard. For further information about Kubernetes, see the Kubernetes reference .</p> <ul> <li>Kubernetes specifies multiple ip types using <code>IPFamily</code>. This means, that instead of e.g. an object having   <pre><code>ipv4: 10.0.0.1\nipv6: ffff::\n</code></pre>   Kubernetes specifies it as   <pre><code>ipFamilies: [IPv4, IPv6]\nips:\n- 10.0.0.1\n- ffff::\n</code></pre>   The proposal should integrate into Kubernetes by using the same notation.</li> <li>Resources that are created, managed, and deleted in scope of another resource are called <code>ephemeral</code>. An example in   Kubernetes is the <code>Pod.spec.volumes.ephemeralVolume</code> that creates a volume just before a   <code>Pod</code> is created and deletes it alongside the <code>Pod</code> after usage.</li> <li><code>1:1</code> binding between two resources is achieved by both resources referencing each other. This can be seen in   Kubernetes'   <code>PersistentVolumeClaim.Spec.volumeName</code> - <code>PersistentVolume.spec.claimRef</code>.</li> <li><code>1:n</code> binding between two resources is achieved by the resource on <code>n</code> side having a reference to the resource on   the <code>1</code> side. This can be seen in <code>n</code> <code>Pod.spec.nodeName</code> referencing a <code>Node</code>.</li> <li><code>m:n</code> binding between two resources is achieved by using <code>selector</code>s and a 'binding' resource that usually gets   created on-the-fly, though this also usually can be modified. An example can be seen in the relation between   <code>Service</code>s and <code>Pod</code>s. A <code>Service</code> selects multiple <code>Pod</code>s via its <code>.spec.selector</code>. The resulting manifested binding   resource is realized via the <code>Endpoints</code> kind that contains the current target list.</li> </ul> <p>The proposal is divided into two parts: The first part purely focuses on IP address management. The second part defines the actual networking types while allowing the user to use the IP address management features of the first part.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/01-networking-integration/#prefix-type","title":"<code>Prefix</code> type","text":"<p>The <code>Prefix</code> simplifies management of IP prefixes (v4 and v6 are both supported).</p> <p>An <code>Prefix</code> may be a root prefix by specifying no parent / parent selector and a prefix it manages. If an <code>Prefix</code> specifies a parent / parent selector, the requested prefix / prefix length is allocated from the parent (that matches, if selector is used). This means, prefixes can both be allocated dynamically by specifying only a desired prefix length or 'statically' by specifying the desired prefix.</p> <p>Example manifests:</p> <pre><code>apiVersion: ipam.ironcore.dev/v1alpha1\nkind: Prefix\nmetadata:\n  namespace: default\n  name: my-root-prefix\nspec:\n  prefix: 10.0.0.0/8\nstatus:\n  phase: Allocated\n---\napiVersion: ipam.ironcore.dev/v1alpha1\nkind: Prefix\nmetadata:\n  namespace: default\n  name: my-sub-prefix\nspec:\n  parentRef:\n    name: my-root-prefix\n#  parentSelector: # A metav1.LabelSelector can be used to select the parent.\n#    matchLabels:\n#      foo: bar\n  prefixLength: 16\n  # prefix: 10.0.0.0/16 # Once successfully allocated, the spec is patched.\nstatus:\n  phase: Pending # This will become `Allocated` once the controller approves it.\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/01-networking-integration/#network-type","title":"<code>Network</code> type","text":"<p>The namespaced <code>Network</code> type defines a <code>Network</code> bracket. Traffic from, to and within the <code>Network</code> can be managed. A <code>Network</code> has to specify the ip families it wants to allow (same is design as in the Kubernetes <code>Service</code> type).</p> <p>IP address space in a <code>Network</code> is not dictated in any way. A <code>Network</code> however has to accept any claimed IP address space within it. For initial design, a <code>Network</code> will only accept non-overlapping space. In a later version, this may be regulated with a field / policy of some kind.</p> <p>Example manifest:</p> <pre><code>apiVersion: networking.ironcore.dev/v1alpha1\nkind: Network\nmetadata:\n  namespace: default\n  name: my-network\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/01-networking-integration/#the-networkinterface-type","title":"The <code>NetworkInterface</code> type","text":"<p>A <code>NetworkInterface</code> is the binding piece between a <code>Machine</code> and a <code>Network</code>. A <code>NetworkInterface</code> references the <code>Network</code> it wants to join as well as the IPs it should use in that <code>Network</code>.</p> <p>The IPs (v4 / v6) can be specified in multiple ways:</p> <ul> <li>Without IPAM by specifying an IP literal</li> <li>As <code>ephemeral</code>, creating an <code>ipam.Prefix</code> with the prefix length of the specified ip family (32 / 128) that will be   owned and also deleted alongside the surrounding <code>NetworkInterface</code>. The name of the   created <code>ipam.Prefix</code> will be <code>&lt;nic-name&gt;-&lt;index&gt;</code>, where <code>&lt;index&gt;</code> is the index of the <code>ephemeral</code> in the <code>ips</code>   list. An existing <code>Prefix</code> with that name will not be used for the <code>NetworkInterface</code> to avoid using an unrelated   <code>Prefix</code> by mistake.</li> </ul> <p>When specifying IPs, a user should also specify <code>ipFamilies</code>. <code>ipFamilies</code> validates that there can be either a single <code>IPv4</code> / <code>IPv6</code>, or an ordered list of an <code>IPv4</code> / <code>IPv6</code> address. If left empty and it can be deducted deterministically from the <code>ips</code>, it will be defaulted. Same applies vice versa.</p> <p>The binding between a <code>NetworkInterface</code> and a <code>Machine</code> is bidirectional via <code>NetworkInterface.spec.machineRef.name</code> / <code>Machine.spec.networkInterfaces[*].name</code>. For the mvp, we will only allow exactly 1 <code>NetworkInterface</code> per <code>Machine</code> .</p> <p>Example usage:</p> <pre><code>apiVersion: networking.ironcore.dev/v1alpha1\nkind: NetworkInterface\nmetadata:\n  namespace: default\n  name: my-machine-interface\nspec:\n  networkRef:\n    name: my-network\n  ipFamilies: [IPv4, IPv6]\n  ips:\n#    - value: 10.0.0.1 # It is also possible to directly specify IPs without IPAM \n#    - value: 2607:f0d0:1002:51::4 # Same applies for v6 addresses\n    - ephemeral:\n        prefixTemplate:\n          spec:\n            prefixRef:\n              name: my-node-prefix-v4\n    - ephemeral:\n        prefixTemplate:\n          spec:\n            prefixRef:\n              name: my-node-prefix-v6\n  machineRef:\n    name: my-machine\nstatus:\n  ips: # This will be updated with the allocated addresses.\n    - 10.0.0.1\n    - 2607:f0d0:1002:51::4\n---\napiVersion: compute.ironcore.dev/v1alpha1\nkind: Machine\nmetadata:\n  namespace: default\n  name: my-machine\n  labels:\n    app: web\nspec:\n  networkInterfaces:\n    - name: my-interface\n      networkInterfaceRef:\n        name: my-machine-interface\n  ...\nstatus:\n  networkInterfaces:\n    - name: my-interface\n      ips: # The machine reports all ips available via its interfaces\n        - 10.0.0.1\n        - 2607:f0d0:1002:51::4\n  ...\n</code></pre> <p>To simplify managing the creation of a <code>NetworkInterface</code> per <code>Machine</code>, a <code>Machine</code> can specify a <code>NetworkInterface</code> as <code>ephemeral</code>, creating and owning it before the <code>Machine</code> becomes available. The name of the <code>NetworkInterface</code> will be <code>&lt;machine-name&gt;-&lt;name&gt;</code> where <code>&lt;name&gt;</code> is the <code>name:</code> value in the <code>networkInterfaces</code> list. Existing <code>NetworkInterface</code>s will not be adopted by the <code>Machine</code>.</p> <p>Sample manifest:</p> <pre><code>apiVersion: compute.ironcore.dev/v1alpha1\nkind: Machine\nspec:\n  interfaces:\n    - name: my-interface\n      ephemeral:\n        networkInterfaceTemplate:\n          spec:\n            ipFamilies: [IPv4, IPv6]\n            networkRef:\n              name: my-network\n            ips:\n              - ephemeral:\n                  prefixTemplate:\n                    spec:\n                      prefixRef:\n                        name: my-node-prefix-v4\n              - ephemeral:\n                  prefixTemplate:\n                    spec:\n                      prefixRef:\n                        name: my-node-prefix-v6\n  ...\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/01-networking-integration/#the-aliasprefix-type","title":"The <code>AliasPrefix</code> type.","text":"<p>An <code>AliasPrefix</code> allows routing a sub-prefix of a network to multiple targets (in our case, <code>NetworkInterface</code>s). It references its target <code>Network</code> and selects the <code>NetworkInterfaces</code> via its <code>selector</code> to apply the alias to.</p> <p>The <code>AliasPrefix</code> creates an <code>AliasPrefixRouting</code> object with the same name as itself where it maintains a list of the <code>NetworkInterface</code>s matching its <code>selector</code>. If the <code>selector</code> is empty it is assumed that an external process manages the <code>AliasPrefixRouting</code> belonging to that <code>AliasPrefix</code>.</p> <p>Example manifest:</p> <pre><code>apiVersion: networking.ironcore.dev/v1alpha1\nkind: AliasPrefix\nmetadata:\n  namespace: default\n  name: my-pod-prefix-1\nspec:\n  ipFamily: IPv4\n  networkRef:\n    name: my-network\n  networkInterfaceSelector:\n    matchLabels:\n      foo: bar\n  prefix:\n#    value: 10.0.0.0/24 # It's possible to directly specify the AliasPrefix value\n    ephemeral:\n      prefixTemplate:\n        spec:\n          prefixRef:\n            name: my-pod-prefix\n          prefixLength: 24\nstatus:\n  prefix: 10.0.0.0/24\n</code></pre> <p>This could manifest in the following <code>AliasPrefixRouting</code>:</p> <pre><code>apiVersion: networking.ironcore.dev/v1alpha1\nkind: AliasPrefixRouting\nmetadata:\n  namespace: default\n  name: my-pod-prefix-1\nnetworkRef:\n  name: my-network\ndestinations:\n  - name: my-machine-interface-1\n    uid: 2020dcf9-e030-427e-b0fc-4fec2016e73a\n  - name: my-machine-interface-2\n    uid: 2020dcf9-e030-427e-b0fc-4fec2016e73d\n</code></pre> <p>To simplify the creation and use of an <code>AliasPrefix</code> per <code>NetworkInterface</code>, a <code>NetworkInterface</code> allows the creation via <code>ephemeralAliasPrefixes</code>. The resulting <code>AliasPrefix</code> name will be <code>&lt;nic-name&gt;-&lt;name&gt;</code> where <code>&lt;name&gt;</code> is the name in the <code>ephemeralAliasPrefixes</code> list.</p> <p>It will also automatically be set in the same network and only target the hosting <code>NetworkInterface</code>. <code>selector</code> and <code>networkRef</code> in <code>spec</code> thus cannot be specified.</p> <pre><code>apiVersion: networking.ironcore.dev/v1alpha1\nkind: NetworkInterface\nmetadata:\n  namespace: default\n  name: my-machine-interface\nspec:\n  ephemeralAliasPrefixes:\n    - name: podrange-v4\n      spec:\n        prefix:\n#          value: 10.0.0.0/24 # It's possible to directly specify the AliasPrefix value\n          ephemeralPrefix:\n            spec:\n              prefixRef:\n                name: my-pod-prefix\n              prefixLength: 24\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/01-networking-integration/#the-virtualip-type","title":"The <code>VirtualIP</code> type","text":"<p>A <code>VirtualIP</code> requests a stable public IP for a single targets (<code>NetworkInterface</code>s). There is a <code>type</code> field that currently only can be <code>type: Public</code> in order to support other future <code>VirtualIP</code> types (for instance, <code>VirtualIP</code>s in other networks).</p> <p>As the public prefixes are provider-managed and custom public IP pools are not in scope of this draft, the IP allocation cannot be influenced and thus no construct like <code>prefixRef</code> is possible for <code>VirtualIP</code>s.</p> <p>To disambiguate between IPv4 and IPv6, the <code>VirtualIP</code> requires an <code>ipFamily</code> (same enum type as in Kubernetes' <code>Service.spec.ipFamilies</code>).</p> <p>The <code>VirtualIP</code> references the claiming <code>NetworkInterface</code> using <code>targetRef</code>.</p> <p>Example manifest:</p> <pre><code>apiVersion: networking.ironcore.dev\nkind: VirtualIP\nmetadata:\n  namespace: default\n  name: my-virtual-ip\nspec:\n  type: Public\n  ipFamily: IPv4\n  targetRef:\n    name: my-nic\n    uid: 2020dcf9-e030-427e-b0fc-4fec2016e73d\nstatus:\n  ip: 45.86.152.88\n  phase: Bound\n</code></pre> <p>To simplify the creation and use of a <code>VirtualIP</code> per <code>NetworkInterface</code>, a <code>NetworkInterface</code> allows the creation via <code>virtualIP.ephemeral</code>. The resulting <code>VirtualPrefix</code> name will be <code>&lt;nic-name&gt;</code> It will also automatically be set up to reference the creating <code>NetworkInterface</code>. A <code>networkInterfaceRef</code> in the <code>spec</code> thus cannot be specified.</p> <pre><code>apiVersion: networking.ironcore.dev/v1alpha1\nkind: NetworkInterface\nmetadata:\n  namespace: default\n  name: my-machine-interface\nspec:\n  virtualIP:\n    ephemeral:\n      virtualIPTemplate:\n        spec:\n          type: Public\n          ipFamily: IPv4\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/01-networking-integration/#scenarios","title":"Scenarios","text":""},{"location":"infrastructure-as-a-service/components/ironcore/proposals/01-networking-integration/#kubernetes-gardener-integration-on-top-of-ironcore","title":"Kubernetes (Gardener) integration on top of ironcore","text":"<p>For a Kubernetes integration, multiple worker nodes should be created in the same network. For each worker node, a separate pod prefix should be allocated. For internet-facing requests, each node should get a distinct public <code>VirtualIP</code> (in the future, outgoing requests will be solved via <code>SNAT</code>, but for the initial version of the MVP a <code>VirtualIP</code> is chosen).</p> <p>Additionally, to show it's possible, an <code>AliasPrefix</code> that is shared across different nodes is created.</p> <p>These are the required manifests:</p> <pre><code># IPAM Setup:\n# Create a root prefix and a pod / node sub-prefix.\napiVersion: ipam.ironcore.dev/v1alpha1\nkind: Prefix\nmetadata:\n  namespace: default\n  name: root\nspec:\n  prefix: 10.0.0.0/8\n---\napiVersion: ipam.ironcore.dev/v1alpha1\nkind: Prefix\nmetadata:\n  namespace: default\n  name: pods\nspec:\n  prefixLength: 11\n  parentRef:\n    name: root\n---\napiVersion: ipam.ironcore.dev/v1alpha1\nkind: Prefix\nmetadata:\n  namespace: default\n  name: nodes\nspec:\n  prefixLength: 16\n  parentRef:\n    name: root\n---\n# Once IPAM is done, the concrete networking is defined\n# The Network is the bracket around all resources\napiVersion: networking.ironcore.dev/v1alpha1\nkind: Network\nmetadata:\n  namespace: default\n  name: k8s\n---\n# Create one prefix that should be shared across all machines\napiVersion: networking.ironcore.dev/v1alpha1\nkind: AliasPrefix\nmetadata:\n  namespace: default\n  name: shared\nspec:\n  networkRef:\n    name: k8s\n  networkInterfaceSelector:\n    matchLabels:\n      type: k8s-worker\n  prefix:\n    ephemeral:\n      prefixTemplate:\n        spec:\n          prefixRef:\n            name: k8s\n          prefixLength: 16\n---\n# Create the actual machine\napiVersion: compute.ironcore.dev/v1alpha1\nkind: Machine\nmetadata:\n  namespace: default\n  name: worker-1\n  labels:\n    type: k8s-worker\nspec:\n  image: gardenlinux-k8s-worker:v0.23.5\n  networkInterfaces:\n    - name: primary\n      ephemeral:\n        networkInterfaceTemplate:\n          spec:\n            # Let the nic join the network\n            networkRef:\n              name: k8s\n            # The IP should be allocated from the node range\n            ips:\n              - ephemeral:\n                  prefixTemplate:\n                    spec:\n                      ipFamily: IPv4\n                      prefixRef:\n                        name: nodes\n            # Create a pod alias range exclusively for this machine\n            ephemeralAliasPrefixes:\n              - name: pods\n                spec:\n                  prefix:\n                    ephemeral:\n                      prefixTemplate:\n                        ipFamily: IPv4\n                        spec:\n                          prefixRef:\n                            name: pods\n                          prefixLength: 24\n            # Create a virtual IP for this machine\n            virtualIP:\n              - ephemeral:\n                  virtualIPTemplate:\n                    spec:\n                      type: Public\n                      ipFamily: IPv4\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/01-networking-integration/#alternatives","title":"Alternatives","text":"<p>None discussed so far.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/02-machine-console-access/","title":"IEP-02: Machine Console Access","text":""},{"location":"infrastructure-as-a-service/components/ironcore/proposals/02-machine-console-access/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Summary</li> <li>Motivation<ul> <li>Goals</li> <li>Non-Goals</li> </ul> </li> <li>Proposal</li> <li>Alternatives</li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/02-machine-console-access/#summary","title":"Summary","text":"<p>A user of the ironcoreshould be able to access the serial console of their machine to access / debug / run imperative commands on it. For this, an endpoint + client-side tooling has to be created as well as the server-side machinery.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/02-machine-console-access/#motivation","title":"Motivation","text":"<p>Users should be able to access / debug / run imperative commands on their machines. This gives immediate feedback on the state of the machine and is a required feature for our minimum viable product.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/02-machine-console-access/#goals","title":"Goals","text":"<ul> <li>Define an endpoint + client side tooling for machine console access</li> <li>Define a server-side interface machine pool providers have to implement in order to   support console access to their machines.</li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/02-machine-console-access/#non-goals","title":"Non-Goals","text":"<ul> <li>Due to the imperative nature of consoles, no declarative interface to consoles should be defined.</li> <li>Have consoles as a building piece of other parts of the ironcore.</li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/02-machine-console-access/#proposal","title":"Proposal","text":""},{"location":"infrastructure-as-a-service/components/ironcore/proposals/02-machine-console-access/#user-facing-api","title":"User-facing API","text":"<p>The <code>compute.ironcore.dev/Machine</code> resource is extended with an <code>exec</code> subresource. When connecting to that subresource, a websocket connection to the backing machine console should be opened. Supported HTTP methods for the <code>exec</code> call are <code>POST</code> and <code>GET</code> (in order to be able to do this from a browser as well).</p> <p>Example call to the Kubernetes API server hosting the aggregated API:</p> <p>```http request GET https:///apis/compute.ironcore.dev/v1alpha1/namespaces//machines//exec <pre><code>### Server-Side API\n\nOnce the server receives such a request, it gets the `Machine` and looks up the `MachinePool` the `Machine`\nis running on. If the `Machine` does not exist or is not scheduled onto a `MachinePool`, an error is returned.\n\nAfter identifying the responsible `MachinePool`, it is retrieved and its `.status.addresses` field is inspected\nfor an address to call. The `.status.addresses` field does not exist yet and has to be updated in the ironcore.\nIt is the responsibility of the `MachinePool` implementor to report its endpoints in the `status`.\n\nFor reference on the address type, see\n[the Kubernetes node address type](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.23/#nodeaddress-v1-core)\nwhich will be used as reference for designing the address type.\n\nExample manifest:\n\n```yaml\napiVersion: compute.ironcore.dev/v1alpha1\nkind: MachinePool\nmetadata:\n  name: my-machine-pool\nspec:\n  providerID: my://machine-pool\nstatus:\n  addresses:\n    - address: 10.250.0.38\n      type: InternalIP\n    - address: my-machine-pool-host\n      type: ExternalDNS\n</code></pre> <p>Once an address has been identified, the ironcore API server calls the endpoint of the <code>MachinePool</code> provider with an <code>exec</code> request for the <code>Machine</code>. The resulting websocket connection is proxied through the ironcore API server to the user.</p> <p><code>http request GET https://&lt;machine-pool-adddress&gt;/apis/compute.ironcore.dev/namespaces/&lt;namespace&gt;/machines/&lt;machine&gt;/exec</code></p> <p>Caution: This proposal does not include anything on authentication mechanisms yet. Implementors can already implement the endpoint but authentication will be added in the future.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/02-machine-console-access/#alternatives","title":"Alternatives","text":""},{"location":"infrastructure-as-a-service/components/ironcore/proposals/03-loadbalancer/","title":"IEP-3: Network Loadbalancer","text":""},{"location":"infrastructure-as-a-service/components/ironcore/proposals/03-loadbalancer/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Summary</li> <li>Motivation<ul> <li>Goals</li> <li>Non-Goals</li> <li>Details</li> </ul> </li> <li>Proposal</li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/03-loadbalancer/#summary","title":"Summary","text":"<p>Load Balancing is an essential requirement in any modern network architecture. It makes backend services scalable, fault-tolerant and provides easy-to-consume access to external consumers.</p> <p>There are multiple types and strategies for load balancing: IP-based load balancing (L3 in the OSI model), Port-based load balancing (L4) and application-based load balancing (L7). This proposal focuses on IP-based load balancers, since they can be used as a foundation for the higher level load balancer types.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/03-loadbalancer/#motivation","title":"Motivation","text":"<p>A <code>VirtualIP</code> (IEP-1) allows to expose a <code>NetworkInterface</code> with a stable public IP. Services running on a <code>Machine</code> using that <code>NetworkInterface</code> can be consumed this way. However, if the <code>Machine</code> or the service running on that <code>Machine</code> crashes, the service will have an outage. To be more resilient and to scale beyond single <code>NetworkInterface</code>s, a <code>LoadBalancer</code> allows targeting multiple <code>NetworkInterface</code>s and distributes traffic between them.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/03-loadbalancer/#goals","title":"Goals","text":"<ul> <li>Define an API for managing L3 load balancers with publicly available addresses</li> <li>Load balancers should allow specifying their IP stack (<code>IPv4</code> / <code>IPv6</code> / dual stack). Public IP addresses   should be allocated according to the specified IP stack.</li> <li>Load balancers should support multiple target <code>NetworkInterface</code>s (   see (IEP-1)</li> <li>The load balancer should dynamically watch for target <code>NetworkInterface</code>s.</li> <li>All target <code>NetworkInterface</code>s must be in the same <code>Network</code>.</li> <li>The load balancer should be able to filter unwanted traffic. The filtering must not alter the packages.   The following filters should be implemented:<ul> <li>Filter depending on ports &amp; protocols (UDP/TCP/SCTP).</li> <li>ICMP requests should be filtered out by default.</li> </ul> </li> <li>Load balancing must be transparent for both target and source.</li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/03-loadbalancer/#non-goals","title":"Non-Goals","text":"<ul> <li>No address or port translation / rewriting (no SNAT / DNAT) (L4 Loadbalancer) support</li> <li>No injection of additional information (e.g. x-forwarded-for) (L7 Loadbalancer) support</li> <li>No protocol offloading like ssl (L7 Loadbalancer) support</li> <li>If more load balancer IPs are required than a single load balancer serves, more load balancers have to be requested.</li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/03-loadbalancer/#details","title":"Details","text":"<ul> <li>Load balancing is used to deliver a packet addressed to the load balancer to one of its targets via the ironcore   network routing</li> <li>The target needs to be aware of the load balancer's IP and needs to answer with it (and to receive traffic with it)</li> <li>Answers to the request will be directly delivered since all details are known by the target</li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/03-loadbalancer/#proposal","title":"Proposal","text":"<p>Introduce a <code>LoadBalancer</code> resource that dynamically selects multiple target <code>NetworkInterface</code>s via a <code>networkInterfaceSelector</code> <code>metav1.LabelSelector</code> (as e.g. in <code>AliasPrefix</code>es). The <code>LoadBalancer</code> of <code>type: Public</code> should allocate public IPs for its <code>ipFamilies</code> and announce them in its <code>status.ips</code>. <code>ports</code> defines an allow list of which traffic should be handled by a <code>LoadBalancer</code>. A <code>port</code> consists of a <code>protocol</code>, <code>port</code> and an optional <code>portEnd</code> to support port range filtering. <code>networkRef</code> defines the target <code>Network</code> a <code>NetworkInterface</code> has to be in in order to be an eligible target for traffic forwarding (see IEP-1).</p> <pre><code>apiVersion: networking.ironcore.dev/v1alpha1\nkind: LoadBalancer\nmetadata:\n  namespace: default\n  name: my-load-balancer\nspec:\n  # type denotes which kind of load balancer to create. For now, only `Public` is supported.\n  type: Public\n  # ip families specifies the supported IP stack of a load balancer. May be `IPv4`, `IPv6` or both (dual stack).\n  ipFamilies: [ IPv4, IPv6 ]\n  # ports is an allow list of traffic to load balance via port(range) and protocol.\n  ports:\n    - # protocols supported UDP, TCP, SCTP\n      protocol: tcp\n      # single port\n      port: 80\n    - protocol: udp\n      # port range\n      port: 1024\n      portEnd: 2048\n  # networkRef specifies the target network any target network interface should be in.\n  networkRef:\n    name: my-network\n  # network interface selector specifies the network interfaces to select for load balancing.\n  networkInterfaceSelector:\n    matchLabels:\n      key: db\n      foo: bar\nstatus:\n  # ips are the ips allocated for the load balancer.\n  ips:\n    - 45.86.152.88\n    - 2001::\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/03-loadbalancer/#routing-state-object","title":"Routing State Object","text":"<p>The load balancer needs details computable at the ironcore API level to describe the explicit targets in a pool traffic is routed to. <code>LoadBalancerRouting</code> describes <code>NetworkInterface</code>s load balanced traffic is routed to. This object describes a state of the <code>LoadBalancer</code> and results of the <code>LoadBalancer</code> definition specifically <code>networkInterfaceSelector</code> and <code>networkRef</code>. <code>LoadBalancerRouting</code> is reconciled by the <code>ironcore</code> load balancer controller.</p> <pre><code>apiVersion: networking.ironcore.dev/v1alpha1\nkind: LoadBalancerRouting\nmetadata:\n  namespace: default\n  name: my-load-balancer # Same name as the load balancer it originates from.\n# networkRef references the exact network object the routing belongs to.\nnetworkRef:\n  name: my-network\n# destinations lists the target network interface instances (including UID) for load balancing.\ndestinations:\n  - name: my-machine-interface-1\n    uid: 2020dcf9-e030-427e-b0fc-4fec2016e73a\n  - name: my-machine-interface-2\n    uid: 2020dcf9-e030-427e-b0fc-4fec2016e73d\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/04-nat-gateway/","title":"04 nat gateway","text":"<p>title: NAT Gateway</p> <p>iep-number: 4</p> <p>creation-date: 2022-18-10</p> <p>status: implementable</p> <p>authors:</p> <ul> <li>\"@gehoern\"</li> <li>\"@adracus\"</li> </ul> <p>reviewers:</p> <ul> <li>\"@MalteJ\"</li> <li>\"@adracus\"</li> <li>\"@afritzler\"</li> <li>\"@guvenc\"</li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/04-nat-gateway/#iep-4-cloud-nate-gateway","title":"IEP-4: Cloud Nate Gateway","text":""},{"location":"infrastructure-as-a-service/components/ironcore/proposals/04-nat-gateway/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Summary</li> <li>Motivation<ul> <li>Goals</li> <li>Non-Goals</li> </ul> </li> <li>Proposal</li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/04-nat-gateway/#summary","title":"Summary","text":"<p>NAT gateways are essential for safe and resource-efficient internet access. Any machine (even those with no public / virtual IP) using a NAT gateway can access the internet without being directly exposed. IPs belonging to the NAT gateway are shared between multiple clients. Communication initiated by a member can get answers from outside (connection tracking) but the member cannot be contacted (no remote initiated traffic) from outside.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/04-nat-gateway/#motivation","title":"Motivation","text":"<p>A <code>NetworkInterface</code>s may have no dedicated public IP addresses (no <code>VirtualIP</code> via <code>spec.virtualIP</code>) but still may need public internet access. A NAT gateway provides this functionality by defining a default gateway to the network interface and a NAT for incoming and outgoing traffic (e.g. downloading container images). The <code>NetworkInterface</code> thus can reach the public internet but is not exposed as it would be when using a <code>VirtualIP</code>.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/04-nat-gateway/#goals","title":"Goals","text":"<ul> <li>A public NAT gateway should only target a single <code>Network</code>.</li> <li>Define an API for managing NAT gateways with publicly available addresses.</li> <li>Define the maximum ports of a NAT gateway to be used by a target <code>NetworkInterface</code>.</li> <li>Define the name of the <code>Network</code> and the <code>NetworkInterface</code> the NAT gateway is operating on.</li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/04-nat-gateway/#non-goals","title":"Non-Goals","text":"<ul> <li>The NAT gateway is not transparent since it manipulates the source port for outgoing traffic towards the remote   target.</li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/04-nat-gateway/#proposal","title":"Proposal","text":"<p>Introduce a <code>NATGateway</code> resource that targets <code>NetworkInterface</code>s in a <code>Network</code>. The <code>Network</code> is specified via a <code>networkRef</code>, the <code>NetworkInterface</code>s are targeted via a <code>LabelSelector</code>. During reconciliation, only <code>NetworkInterface</code>s that are not yet exposed via <code>VirtualIP</code> are selected and will be NATed and get masqueraded internet access. To denote a <code>NATGateway</code> as publicly facing, <code>type: Public</code> must be specified. For now, this is the only supported type. A <code>NATGateway</code> must specify the IP stack it operates on via <code>ipFamilies</code>. This can be <code>IPv4</code>, <code>IPv6</code> or both ( dual-stack). The <code>ips</code> field names the ips allocated for a <code>NATGateway</code>. If <code>ipFamilies</code> is dual-stack, both an <code>IPv4</code> and <code>IPv6</code> ip address will be allocated for each item in the <code>ips</code> field. The field <code>portsPerNetworkInterface</code> defines the maximum number of concurrent connections from a single <code>NetworkInterface</code> to a remote IP. The current usage of ports is reported in <code>status.portsUsed</code>.</p> <pre><code>apiVersion: networking.ironcore.dev/v1alpha1\nkind: NATGateway\nmetadata:\n  namespace: default\n  name: my-nat\nspec:\n  # Type denotes the type of nat gateway. For now, only 'Public' is supported.k:w\n  type: Public\n  # ip families specifies the supported IP stack of a load balancer. May be `IPv4`, `IPv6` or both (dual stack).\n  ipFamilies: [ IPv4, IPv6 ]\n  # the network the nat gateway targets.\n  networkRef:\n    name: sample-network\n  # ips are the ips to allocate for the nat gateway.\n  # If dual-stack is active, at least two ips will be allocated.\n  ips:\n    - name: ip1\n  # defines the concurrent connections per NetworkInterface and target. Must be a power of 2.\n  portsPerNetworkInterface: 64\n  # networkInterfaceSelector selects the target network interfaces that should be NATed.\n  networkInterfaceSelector:\n    matchLabels:\n      key: db\n      foo: bar\nstatus:\n  # ips lists the ips allocated for each requested ip.\n  ips:\n    - name: ip1\n      ips:\n      - 48.86.152.12\n  # portsUsed reports the current port usage of the nat gateway.\n  portsUsed: 128 # Equal to portsPerNetworkInterface * entries in routing destinations\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/05-object-storage/","title":"IEP-5: Object Storage","text":""},{"location":"infrastructure-as-a-service/components/ironcore/proposals/05-object-storage/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Summary</li> <li>Motivation<ul> <li>Goals</li> <li>Non-Goals</li> </ul> </li> <li>Proposal</li> <li>Alternatives</li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/05-object-storage/#summary","title":"Summary","text":"<p>Object storage builds the basis for many cloud applications. An Object Storage provides a simplified object  model for files, but has a reduced set of security and access features (non-posix). This functionality is built on top  of the HTTP protocol. The current market standard is S3.  This document describes how to integrate simplified S3 buckets into the IronCore API without taking too many details of  the S3 feature completeness itself.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/05-object-storage/#motivation","title":"Motivation","text":"<p>Object Storage is demanded by cloud native applications, therefore, IronCore needs to provide it for a complete solution. The Object Storage service should be integrated into IronCore and is not designed  to be just a service on top of IronCore. The used protocol is called S3 which introduces a storage entity called bucket. For the beginning only the bucket creation and removal is covered.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/05-object-storage/#goals","title":"Goals","text":"<ul> <li>S3-compatible object storage implementation</li> <li>Automatic assigned public storage endpoint </li> <li>Providing a REST-API endpoint to address the bucket</li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/05-object-storage/#non-goals","title":"Non-Goals","text":"<ul> <li>Support other object storage protocols than S3</li> <li>Internal buckets (reachable only from inside the cluster)</li> <li>Quota handling (size or object number limitation)</li> <li>External Object level access control (beyond what the S3 implementation provides)</li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/05-object-storage/#proposal","title":"Proposal","text":"<p>The proposal to provide an Object Storage consists of three API resources: <code>Bucket</code>, <code>BucketClass</code> and <code>BucketPool</code>.  A <code>Bucket</code> is the S3 enabled storage endpoint. IOPS/Bandwidth limitations are controlled via a <code>BucketClass</code> and the  capabilities of the underlying storage provider are expressed via a <code>BucketPool</code>. A <code>Bucket</code> can be requested  from a <code>BucketPool</code> as long as it can provide the performance characteristics described in the <code>BucketClass</code>.  The proposed API resources are similar to <code>Volume</code>, <code>VolumeClass</code> and <code>Volumepool</code> except that a volume is a  block device with a specific driver.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/05-object-storage/#bucket","title":"Bucket","text":"<p>A <code>Bucket</code> is a namespaced resource to request S3-compatible object storage. The desired <code>BucketClass</code> is referenced by the <code>bucketClassRef</code>. If no pool is pre-defined,  the <code>bucketPoolSelector</code> will be used to find a suitable <code>BucketPool</code>.  The desired pool, either pre-defined or  set by another controller, is stated in the <code>bucketPoolRef</code>.</p> <p>The information to access the requested <code>Bucket</code> is in the <code>access</code> field of the status.  The <code>endpoint</code> defines the address of the <code>Bucket</code> Rest-API. Access credentials are placed in a secret with is referenced  through the <code>secretRef</code>. The <code>state</code> indicates if the <code>Bucket</code> is <code>Available</code>, <code>Pending</code> or in an <code>Error</code> state.</p> <pre><code>apiVersion: storage.ironcore.dev/v1alpha1\nkind: Bucket\nmetadata:\n  name: bucket-1\nspec:\n  bucketClassRef:\n    name: slow\n  bucketPoolSelector:\n    matchLabels:\n      key: db\n      foo: bar\n  bucketPoolRef:\n    name: fra-shared\nstatus:\n  access:\n    endpoint: foo.bar.example.org \n    secretRef:\n      name: 000225194345f27a40257c5777c96a03ce219f96731f22afc45b7dfda7d077d\n  state: Available\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/05-object-storage/#bucketclass","title":"BucketClass","text":"<p>A <code>BucketClass</code> is a non-namespaced resource which describes the characteristics of a <code>Bucket</code>. The maximal  performance the <code>Bucket</code> will offer (like I/O operations or throughput) is defined in the <code>capabilities</code> field.</p> <pre><code>apiVersion: storage.ironcore.dev/v1alpha1\nkind: BucketClass\nmetadata:\n  name: slow\ncapabilities:\n  iops: 10\n  tps: 20Mi\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/05-object-storage/#bucketpool","title":"BucketPool","text":"<p>A <code>BucketPool</code> is a non-namespaced logical unit and accommodates a collection of <code>Bucket</code>s.  The <code>provider</code>'s id (the implementor's id) of the <code>BucketPool</code> is stated in the <code>providerID</code> field.  Only <code>Bucket</code>s who tolerate all the taints, will land in the <code>BucketPool</code>. <code>BucketClasses</code> which can be fulfilled by  the provider of the <code>BucketPool</code>, are listed in the status field <code>availableBucketClasses</code>. The <code>state</code> in the status  indicates if the pool is <code>Available</code>, <code>Pending</code> or <code>Unavailable</code>.</p> <pre><code>apiVersion: storage.ironcore.dev/v1alpha1\nkind: BucketPool\nmetadata:\n  name: ceph-object-store\nspec:\n  providerID: cephlet://pool\n  taints: []\nstatus:\n  availableBucketClasses:\n    - name: fast\n    - name: slow\n  state: Available\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/05-object-storage/#alternatives","title":"Alternatives","text":""},{"location":"infrastructure-as-a-service/components/ironcore/proposals/06-storage-encryption/","title":"IEP-6: Storage Encryption","text":""},{"location":"infrastructure-as-a-service/components/ironcore/proposals/06-storage-encryption/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Summary</li> <li>Motivation<ul> <li>Goals</li> <li>Non-Goals</li> </ul> </li> <li>Proposal</li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/06-storage-encryption/#summary","title":"Summary","text":"<p>One of the important feature of Cloud Native IaaS is to provide secure storage. This proposal focuses on providing option to enable encryption for individual ironcore Volume.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/06-storage-encryption/#motivation","title":"Motivation","text":"<p>As part of Storage encryption feature the IronCore API supports option to enable encryption of Volumes. Volume level encryption helps protect users from data theft or accidental loss, by rendering data stored on hard drives unreadable when an unauthorized user tries to gain access. The loss of encryption keys is a major concern, as it can render any encrypted data useless. </p>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/06-storage-encryption/#goals","title":"Goals","text":"<ul> <li>Allow user to enable volume encryption by providing encryption key via secret reference</li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/06-storage-encryption/#non-goals","title":"Non-Goals","text":"<ul> <li>Add a new attribute to provide source of encryption key like None/UserProvidedKey/DefaultMasterKey</li> <li>Add KMS support to manage user provided encryption keys</li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/06-storage-encryption/#proposal","title":"Proposal","text":"<ul> <li>The proposal introduces a new field <code>encryption</code> with currently the single attribute <code>secretRef</code>, referencing a secret to use for encryption, in existing <code>Volume</code> type. </li> <li><code>encryption</code> is an optional field.</li> <li>If <code>encryption</code> field is not provided by user, then ironcore <code>Volume</code> remains unencrypted</li> <li>To encrypt ironcore <code>Volume</code>, user has to first create kubernetes secret of Opaque type with key-value pair as below:<ul> <li>key = <code>encryptionKey</code> </li> <li>value = base64-encoded 256 bit encryption key</li> </ul> </li> <li>Then provide this secret name to <code>encryption.secretRef</code> attribute of <code>Volume</code> type.</li> </ul> <p>Secret for encryption key</p> <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: encryption-key-secret\n  namespace: default\ntype: Opaque\ndata:\n  encryptionKey: QW9zejI4Y0xIR3pjR3M2UGltdHZVSnVSSGt6aWZiVTU4V3NIZElIL09idz0=\n</code></pre> <p>Volume with encryption key secret reference:</p> <pre><code>apiVersion: storage.ironcore.dev/v1alpha1\nkind: Volume\nmetadata:\n  name: sample-volume\n  namespace: default\nspec:\n  volumeClassRef:\n    name: fast\n  volumePoolRef:\n    name: ceph\n  resources:\n    storage: 1Gi\n  encryption:\n    secretRef: encryption-key-secret\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/07-quota/","title":"IEP-7: Quota","text":""},{"location":"infrastructure-as-a-service/components/ironcore/proposals/07-quota/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Summary</li> <li>Motivation<ul> <li>Goals</li> <li>Non-Goals</li> </ul> </li> <li>Proposal</li> <li>Alternatives</li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/07-quota/#summary","title":"Summary","text":"<p>Quota is a mechanism to manage and limit the usage of resources across multiple requesting entities. By introducing quotas, a system can be protected from usage spikes and services can be kept responsive. Quotas also can ensure that each requesting entity can exercise its right to a fair share of the resources.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/07-quota/#motivation","title":"Motivation","text":"<p>Kubernetes Resource Quotas are a great way to limit resource consumption for core Kubernetes types (allowing to manage things like overall CPU consumption) and resource count for all types. However, when it comes to limiting resource usage for custom types (in this special case, the <code>ironcore</code> types), the Kubernetes Quota system falls short of providing means to do so.</p> <p>For <code>ironcore</code> it should be possible to limit the actual requested resources like the total number of used CPUs, storage and memory as well as limit the count of resources by a given dimension (e.g. number of <code>Machine</code>s for a given <code>MachineClass</code>).</p>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/07-quota/#goals","title":"Goals","text":"<ul> <li>Limit resource count in a <code>Namespace</code> (by dimension)</li> <li>Limit accumulated resource usage in a <code>Namespace</code> (by dimension)</li> <li>Integrate nicely into the existing Kubernetes <code>ResourceQuota</code> concepts</li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/07-quota/#non-goals","title":"Non-Goals","text":"<ul> <li>Limit resource count / accumulated resource usage cross-<code>Namespace</code></li> <li>Define a system to request quota increases</li> <li>Define a user management system</li> <li>Couple resource quota to any user system</li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/07-quota/#proposal","title":"Proposal","text":"<p>Introduce a new namespaced type <code>ResourceQuota</code> in the new <code>core</code> group. A <code>ResourceQuota</code> allows defining hard resource limits that cannot be exceeded. The limits are defined via <code>spec.hard</code> as a <code>corev1alpha1.ResourceList</code>. The currently enforced limits are shown in <code>status.hard</code> and the currently used limits in <code>status.used</code>. Requests to create / update resources that would exceed the quota will fail with the HTTP status code <code>403 Forbidden</code>.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/07-quota/#compute-resource-quota","title":"Compute Resource Quota","text":"<p>For the <code>ironcore</code> <code>compute</code> group, the following resources can be limited:</p> Resource Name Description requests.cpu Across all machines in non terminal state, the sum of cpus cannot exceed this value requests.memory Across all machines in non terminal state, the sum of memory cannot exceed this value"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/07-quota/#storage-resource-quota","title":"Storage Resource Quota","text":"<p>For the <code>ironcore</code> <code>storage</code> group, the following</p> Resource Name Description requests.storage Across all volumes in non terminal state, the sum of storage cannot exceed this value"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/07-quota/#object-count-quota","title":"Object Count Quota","text":"<p>Similar to Kubernetes' object count quota, it is possible to limit the number of resources per types using the following syntax: <code>count/&lt;resource&gt;.&lt;group&gt;</code>. For example, <code>count/machines.compute.ironcore.dev</code> would limit the number of machines from the <code>ironcore</code> <code>compute.ironcore.dev</code> group.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/07-quota/#quota-scopes","title":"Quota Scopes","text":"<p>To measure / limit usage only for a subset of all resources, a <code>ResourceQuota</code> may specify a <code>scopeSelector</code>. A <code>scopeSelector</code> may contain multiple expressions and only matches a resource if it matches the intersection of enumerated scopes.</p> Scope Description MachineClass Match machines that reference the specified machine class VolumeClass Match volumes that reference the specified volume class <p>By using certain <code>scopeSelector</code>s, the quota can only track a specific set of resources. E.g. for the <code>MachineClass</code> <code>scopeSelector</code>, only <code>Machine</code>s can be tracked.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/07-quota/#example-manifests","title":"Example Manifests","text":"<p>Limit the accumulated amount of <code>cpu</code>, <code>memory</code> and <code>storage</code> across all <code>Machine</code>s and <code>Volume</code>s:</p> <pre><code>apiVersion: core.ironcore.dev/v1alpha1\nkind: ResourceQuota\nmetadata:\n  name: limit-accumulated-usage\nspec:\n  hard:\n    requests.cpu: \"1000\"\n    requests.memory: 200Gi\n    requests.storage: 10Ti\n</code></pre> <p>Limit the number of machines for a given machine class:</p> <pre><code>apiVersion: core.ironcore.dev/v1alpha1\nkind: ResourceQuota\nmetadata:\n  name: limit-large-machines\nspec:\n  hard:\n    count/machines.compute.ironcore.dev: 10\n  scopeSelector:\n    matchExpressions:\n    - scopeName: MachineClass\n      operator: In\n      values:\n        - large\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/08-internal-load-balancer/","title":"IEP-8: Internal Load Balancers","text":""},{"location":"infrastructure-as-a-service/components/ironcore/proposals/08-internal-load-balancer/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Summary</li> <li>Motivation</li> <li>Goals</li> <li>Non-Goals</li> <li>Proposal</li> <li>Alternatives</li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/08-internal-load-balancer/#summary","title":"Summary","text":"<p>When developing services in the cloud, not all services should be available to the public internet. Nevertheless they need to be highly available within a certain network boundary.</p> <p>To solve this issue, other public cloud vendors allow defining internal load balancers.</p> <p>Internal load balancers behave much like their external / public counterparts with the important difference of not exposing the selected service to the public internet.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/08-internal-load-balancer/#motivation","title":"Motivation","text":"<p>In <code>ironcore</code>, we need to be able to make services highly available internally. Currently, we can only allocate IP addresses for <code>NetworkInterface</code>s and target them, however, as soon as the backing <code>Machine</code> fails, the service would become unavailable.</p> <p>To prevent this, we have to extend our current <code>LoadBalancer</code> type to also function internally. This should be done with a similar API as for the public use case but allow for the same flexibility with internal IPs as we have already with the <code>NetworkInterface</code> type.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/08-internal-load-balancer/#goals","title":"Goals","text":"<ul> <li> <p>Make a service running on multiple <code>Machine</code>s / <code>NetworkInterface</code>s in a single <code>Namespace</code>   available behind a load-balanced IP without exposing it outside their <code>Network</code></p> </li> <li> <p>Manage the used internal IPs either via literals or by using <code>ipam.Prefix</code>es.</p> </li> <li> <p>Extend the current <code>LoadBalancer</code> type with <code>type: Internal</code> indicating its use as an internal   load balancer.</p> </li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/08-internal-load-balancer/#non-goals","title":"Non-Goals","text":"<ul> <li> <p>Cross-Namespace consumption of the <code>LoadBalancer</code> - An internal <code>LoadBalancer</code> is only   available within one <code>Network</code></p> </li> <li> <p>Cross-Namespace IP allocation - IPs and prefixes are created and deleted in a single namespace.</p> </li> <li> <p>Use <code>VirtualIP</code>s in a <code>LoadBalancer</code> of <code>type: Internal</code>:   <code>VirtualIP</code>s are always public (compare to AWS' <code>ElasticIP</code>) and their IP allocation differs   from allocating internal IPs (that don't have to be publicly routable / announced via ASN).   If a user always wants the same internal IP, this use case is already covered by specifying a   literal IP value or by referencing an <code>ipam.Prefix</code>.</p> </li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/08-internal-load-balancer/#proposal","title":"Proposal","text":"<p>Example manifest:</p> <pre><code>apiVersion: networking.ironcore.dev/v1alpha1\nkind: LoadBalancer\nmetadata:\n  name: my-loadbalancer\nspec:\n  type: Internal\n  networkRef:\n    name: my-network\n  ipFamilies: [IPv4, IPv6]\n  ips:\n  - ip: 10.0.0.1 # It is possible to specify a literal IP\n  - ephemeral: # Or to allocate using an existing ipam.Prefix\n      prefixTemplate:\n        spec:\n          prefixRef: # The prefix length will always = IPFamily.Bits\n            name: my-lb-prefix-v6\n  networkInterfaceSelector:\n    matchLabels:\n      app: web\n  ports: # The port filtering is the same as for public load balancers\n  - protocol: TCP\n    port: 8080\nstatus:\n  ips:\n  - ip: \"10.0.0.1\"\n  - ip: \"2607:f0d0:1002:51::4\"\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/08-internal-load-balancer/#alternatives","title":"Alternatives","text":"<ul> <li> <p>Target multiple <code>NetworkInterface</code>s + IPs and track (e.g. via discovery / concensus protocol)   which of these are available to solve the high-availability aspect. This has the drawback of   high implementation effort + having to choose from multiple IPs / putting the burden of choosing   the correct IP on a potential consumer.</p> </li> <li> <p>Create <code>Machine</code>(s) that e.g. run <code>HAProxy</code> to target your services with. This comes with the   drawback of having to manage the <code>Machine</code>s / having multiple IPs for the load balancing machines   to choose from (see alternative 1).</p> </li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/09-network-peering/","title":"IEP-9: Network Peering","text":""},{"location":"infrastructure-as-a-service/components/ironcore/proposals/09-network-peering/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Summary</li> <li>Motivation<ul> <li>Goals</li> <li>Non-Goals</li> </ul> </li> <li>Proposal</li> <li>Alternatives</li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/09-network-peering/#summary","title":"Summary","text":"<p>Network peering is a technique used to interleave two isolated networks, allowing members of both networks to communicate with each other as if they were in the same networking domain. This proposal describes how to introduce network peering to <code>ironcore</code>, building upon the existing concepts that were proposed in the Networking Integration IEP.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/09-network-peering/#motivation","title":"Motivation","text":"<p>Network peering allows members of two networks to communicate with each other without exposing them publicly and without a single point of failure. The networking fabric underneath is used to enable the actual routing. <code>ironcore</code>'s <code>networking</code> API should offer a way to define such a peering.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/09-network-peering/#goals","title":"Goals","text":"<ul> <li>Allow two <code>Network</code>s to communicate with each other without exposing their   routes / addresses publicly and by only using network routing to do so   (i.e. no load-balancing).</li> <li>Be less resource-intensive than comparable solutions like load-balancing /   VPN overlays.</li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/09-network-peering/#non-goals","title":"Non-Goals","text":"<ul> <li>Map / transform IP addresses: The peered networks will be interleaved with   each other without any transformation. The owners of the networks are   responsible for keeping the addresses conflict-free. If there are conflicts,   it is up to the networking implementation how to resolve them (e.g. use   a 'local-first' approach for which address / route to use).</li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/09-network-peering/#proposal","title":"Proposal","text":"<p>Extend the <code>networking.ironcore.dev.Network</code> resource with a <code>spec.peerings</code> field that specifies the desired network peerings and a <code>status.peerings</code> that reflects the status of these peerings.</p> <p>A peering has a <code>name</code> as handle &amp; primary key (used in <code>StrategicMergePatch</code> and <code>Apply</code>). It references the network to peer with via a <code>networkRef</code> field. This <code>networkRef</code> contains the <code>name</code> and the <code>uid</code> of the target network. If the <code>uid</code> is unset, the <code>Network</code> controller sets this to the <code>uid</code> of the corresponding network upon first reconciliation. This ensures that the same object instances are peered together by verifying the object identity.</p> <p>Both <code>Network</code>s have to specify a matching peering item (i.e. reference each other via <code>networkRef</code>) to mutually accept the peering.</p> <p>The (binding) <code>phase</code> of a <code>spec.peerings</code> item is reflected in a corresponding <code>status.peerings</code> item with the same <code>name</code>. The <code>phase</code> can either be <code>Pending</code>, meaning there is no active peering, or <code>Bound</code>, meaning the peering as described in the <code>spec.peerings</code> item is in place. The <code>lastTransitionTime</code> field is updated every time there is a change in the <code>phase</code>, allowing users and external controllers to determine whether a binding is hanging and to manually delete it if necessary.</p> <p>Example Manifests:</p> <pre><code>apiVersion: networking.ironcore.dev/v1alpha1\nkind: Network\nmetadata:\n  name: my-network-1\n  uid: 2020dcf9-e030-427e-b0fc-4fec2016e73a\nspec:\n  peerings:\n  # name is the name of the peering configuration\n  - name: my-network-peering\n    networkRef:\n      name: my-network-2\n      # If unset, uid will be filled in by the Network controller\n      # uid: 3030dcf9-f031-801b-f0f0-4fec2016e73a\nstatus:\n  peerings:\n  - name: my-network-peering\n    # The phase shows the binding progress between two networks.\n    # The initial state is 'Pending' until both peers accept.\n    phase: Bound\n    lastPhaseTransitionTime: \"2023-02-16T15:06:58Z\"\n---\napiVersion: networking.ironcore.dev/v1alpha1\nkind: Network\nmetadata:\n  name: my-network-2\n  uid: 3030dcf9-f031-801b-f0f0-4fec2016e73a\nspec:\n  # Both networks have to have the semantically same peering configuration.\n  peerings:\n  - name: my-network-peering\n    networkRef:\n      name: my-network-1\n      # If unset, uid will be filled in by the Network controller\n      # uid: 2020dcf9-e030-427e-b0fc-4fec2016e73a\nstatus:\n  peerings:\n  - name: my-network-peering\n    phase: Bound\n    lastPhaseTransitionTime: \"2023-02-16T15:06:58Z\"\n</code></pre> <p>Network peering can also specify <code>Network</code>s from different namespaces. For this, the <code>networkRef</code> field includes a <code>namespace</code> field (default empty if in the same namespace). Both <code>Network</code>s need to reference the other network and namespace correctly, otherwise the peering will stay in <code>phase: Pending</code> indefinitely.</p> <p>Example Manifests:</p> <pre><code>apiVersion: networking.ironcore.dev/v1alpha1\nkind: Network\nmetadata:\n  namespace: ns-1\n  name: my-network-1\nspec:\n  peerings:\n  - name: my-network-peering\n    networkRef:\n      namespace: ns-2\n      name: my-network-2\n---\napiVersion: networking.ironcore.dev/v1alpha1\nkind: Network\nmetadata:\n  namespace: ns-2\n  name: my-network-2\nspec:\n  peerings:\n  - name: my-network-peering\n    networkRef:\n      namespace: ns-1\n      name: my-network-1\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/09-network-peering/#alternatives","title":"Alternatives","text":"<ul> <li>Create a VPN overlay between two networks. However, this requires a (potentially   public endpoint and introduces points of failure in form of the VPN server(s)   and client(s). Additionally, the VPN components have to be maintained manually.</li> <li>Use hole-punching to create a bidirectional tunnel. This cannot always be done,   as it depends on the network fabric, requires a publicly available   rendezvous-point, introduces potential points of failure and requires   maintenance for its components as for the VPN-based solution.</li> <li>Depending on the use-case, services can be exposed behind an internal   load-balancer, providing failure-safe and scalable communication channels.</li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/10-network-policies/","title":"IEP-10: Network Policies","text":""},{"location":"infrastructure-as-a-service/components/ironcore/proposals/10-network-policies/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Summary</li> <li>Motivation<ul> <li>Goals</li> <li>Non-Goals</li> </ul> </li> <li>Proposal</li> <li>Alternatives</li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/10-network-policies/#summary","title":"Summary","text":"<p>In an unregulated network, it is impossible to properly enforce the rules of least-privilege. Each member of a network could potentially communicate to each other, receive traffic from the public internet (if connected) and communicate with the public internet (if connected). This imposes a big security risk which has to be properly addressed in each modern infrastructure. This proposal describes how to introduce network policies as a means to regulate traffic inside a network building upon the existing concepts that were proposed in the Networking Integration IEP.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/10-network-policies/#motivation","title":"Motivation","text":"<p>Currently, there is no way to describe which members of a network should be able to communicate with each other. Same applies to traffic coming from the public internet / going to the public internet. The <code>ironcore</code> should be extended with traffic control mechanisms, allowing to limit / deny traffic on a per-instance basis. Of course, the mechanisms should align well with existing proposals / concepts in the Kubernetes world.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/10-network-policies/#goals","title":"Goals","text":"<ul> <li>Be able to deny ingress and egress traffic between members of a <code>Network</code>.</li> <li>Be able to deny ingress and egress traffic between members of a <code>Network</code> and   the public internet.</li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/10-network-policies/#non-goals","title":"Non-Goals","text":"<ul> <li>Define policies that apply to multiple <code>Network</code>s simultaneously.</li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/10-network-policies/#proposal","title":"Proposal","text":"<p>Introduce a new type <code>NetworkPolicy</code> that regulates traffic within a certain network. By default, traffic to members in a <code>Network</code> is not regulated. However, as soon as a <code>NetworkPolicy</code> selects members of a <code>Network</code>, all ingress and egress traffic concerning the members is denied unless a <code>NetworkPolicy</code> explicitly allows it. This makes it so multiple <code>NetworkPolicy</code> instances can never be in conflict and instead just allow more ingress / egress traffic to be received / sent.</p> <p>Members are selected using a Kubernetes <code>metav1.LabelSelector</code> to allow specifying multiple target network interfaces.</p> <p>A <code>NetworkPolicy</code> specifies rules to treat <code>ingress</code> and <code>egress</code> traffic. To be able to express whether e.g. no <code>ingress</code> or <code>egress</code> traffic is allowed without specifying any rule, <code>NetworkPolicy</code>s always have to specify the <code>policyTypes</code> (either <code>Ingress</code> / <code>Egress</code>) they want to enforce.</p> <p>Example manifest:</p> <pre><code>apiVersion: networking.ironcore.dev/v1alpha1\nkind: NetworkPolicy\nmetadata:\n  namespace: default\n  name: my-network-policy\nspec:\n  # This specifies the target network to limit the traffic in.\n  networkRef:\n    name: my-network\n  # Only network interfaces in the specified network will be selected.\n  networkInterfaceSelector:\n    matchLabels:\n      app: db\n  # If the policy types are not specified, they are inferred on whether\n  # any ingress / egress rule exists. If no ingress / egress rule exists,\n  # the network policy is denied on admission.\n  policyTypes:\n  - Ingress\n  - Egress\n  # Multiple ingress / egress rules are possible.\n  ingress:\n  - from:\n    # Traffic can be limited from a source IP block.\n    - ipBlock:\n        cidr: 172.17.0.0/16\n    # Traffic can also be limited to objects of the networking api.\n    # For instance, to limit traffic from network interfaces, one could\n    # specify the following:\n    - objectSelector:\n        kind: NetworkInterface\n        matchLabels:\n          app: web\n    # Analogous to network interfaces, it is also possible to limit\n    # traffic coming from load balancers:\n    - objectSelector:\n        kind: LoadBalancer\n        matchLabels:\n          app: web\n    # Ports always have to be specified. Only traffic matching the ports\n    # will be allowed.\n    ports:\n    - protocol: TCP\n      port: 5432\n  egress:\n  - to:\n    - ipBlock:\n        cidr: 10.0.0.0/24\n    ports:\n    - protocol: TCP\n      port: 8080\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ironcore/proposals/10-network-policies/#alternatives","title":"Alternatives","text":"<ul> <li>Provide an own networking overlay that enforces the rules. However, this   involves significant effort and maintenance.</li> <li>Have hypervisors / management processes monitor traffic sent by application   processes. However, monitoring of the hypervisors / management processes still   is not addressed with this.</li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/installation/","title":"Installing Ironcore","text":""},{"location":"infrastructure-as-a-service/components/ironcore/usage/installation/#requirements","title":"Requirements","text":"<ul> <li><code>go</code> &gt;= 1.20</li> <li><code>git</code>, <code>make</code>, and <code>kubectl</code></li> <li>Kustomize</li> <li>Access to a Kubernetes cluster (Minikube, kind or a real cluster)</li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/installation/#clone-the-repository","title":"Clone the Repository","text":"<p>To bring up and install the <code>Ironcore</code> project, you first need to clone the repository.</p> <pre><code>git clone git@github.com:ironcore-dev/ironcore.git\ncd ironcore\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/installation/#install-cert-manager","title":"Install cert-manager","text":"<p>If there is no cert-manager present in the cluster it needs to be installed.</p> <pre><code>kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.16.2/cert-manager.yaml\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/installation/#install-apis-into-the-cluster","title":"Install APIs into the Cluster","text":"<p>Your Kubernetes API server needs to know about the APIs that come with the <code>Ironcore</code> project. To install the APIs into your cluster, run</p> <pre><code>make install\n</code></pre> <p>Note: This requires the <code>APISERVER_IMG</code> (Makefile default set to <code>apiserver</code>) to be pullable from your Kubernetes cluster. For local development with <code>kind</code>, a make target that builds and loads the API server image and then applies the manifests is available via</p> <pre><code>make kind-install\n</code></pre> <p>Note: In case multiple environments running, ensure that <code>kind get clusters</code> is pointing to the default kind cluster.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/installation/#deploy-the-controller-manager","title":"Deploy the Controller Manager","text":"<p>The controller manager can be started via the following command.</p> <pre><code>make kind-deploy\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/installation/#validate","title":"Validate","text":"<p>Make sure you have all the below pods running.</p> <pre><code>$ kubectl get po -n ironcore-system\nNAME                                           READY   STATUS    RESTARTS       AGE\nironcore-apiserver-85995846f9-47247            1/1     Running   0              136m\nironcore-controller-manager-84bf4cc6d5-l224c   2/2     Running   0              136m\nironcore-etcd-0                                1/1     Running   0              143m\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/installation/#apply-sample-manifests","title":"Apply Sample Manifests","text":"<p>The <code>config/samples</code> folder contains samples for all APIs supported by this project. You can apply any of the samples by running</p> <pre><code>kubectl apply -f config/samples/SOME_RESOURCE.yaml\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/installation/#cleanup","title":"Cleanup","text":"<p>To remove the APIs from your cluster, simply run.</p> <pre><code>make uninstall\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/compute/machine/","title":"Machine","text":"<p>A <code>Machine</code> resource in <code>Ironcore</code> is used to represent a compute resource or a virtual machine.  It serves as a means to configure network, storage, type of machine and other information needed to create a VM. The <code>MachineController</code> reconciler leverages this information to determine where the machine needs to be created and the type of machine that needs to be created along with the required <code>Network</code> and <code>Storage</code> configuration which will be further passed to respective <code>NetworkController</code> and <code>StorageController</code>.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/compute/machine/#example-machine-resource","title":"Example Machine Resource","text":"<p>An example of how to define a Machine resource:</p> <p><pre><code>apiVersion: compute.ironcore.dev/v1alpha1\nkind: Machine\nmetadata:\n  name: machine-sample\nspec:\n  machineClassRef:\n    name: machineclass-sample\n  image: my-image\n  volumes:\n    - name: rootdisk # first disk is the root disk\n      volumeRef:\n        name: my-volume\n  networkInterfaces:\n    - name: primary\n      networkInterfaceRef:\n        name: networkinterface-sample\n  ignitionRef:\n    name: my-ignition-secret\n</code></pre> (<code>Note</code>: Refer to E2E Examples for more detailed examples.)</p> <p>Key Fields:</p> <ul> <li>machineClassRef (<code>string</code>): machineClassRef is a reference to the machine class/flavor of the machine.</li> <li>machinePoolRef (<code>string</code>): machinePoolRef defines the machine pool to run the machine in. If empty, a scheduler will figure out an appropriate pool to run the machine in.</li> <li>image (<code>string</code>): image is the optional URL providing the operating system image of the machine.</li> <li>volumes (<code>list</code>): volumes are list volumes(storage) attached to this machine.</li> <li>networkInterfaces (<code>list</code>): networkInterfaces define a list of network interfaces present on the machine</li> <li>ignitionRef (<code>string</code>): ignitionRef is a reference to a <code>secret</code> containing the ignition YAML for the machine to boot up. If a key is empty, <code>DefaultIgnitionKey</code> will be used as a fallback. (<code>Note</code>: Refer to Sample Ignition for creating ignition secret)</li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/compute/machine/#reconciliation-process","title":"Reconciliation Process","text":"<ol> <li>Machine Scheduling:  The <code>MachineScheduler</code> controller continuously watches for <code>Machines</code> without an assigned <code>MachinePool</code> and tries to schedule it on available and matching MachinePool.</li> <li>Monitor Unassigned Machines: The scheduler continuously watches for machines without an assigned <code>machinePoolRef</code>.</li> <li>Retrieve Available Machine Pools: The scheduler fetches the list of available machine pools from the cache.</li> <li>Make Scheduling Decisions: The scheduler selects the most suitable machine pool based on resource availability and other policies.</li> <li>Update Cache: The scheduler updates the cache with recalculated allocatable <code>machineClass</code> quantities.</li> <li> <p>Assign MachinePoolRef: The scheduler assigns the selected <code>machinePoolRef</code> to the machine object.</p> </li> <li> <p>IRI Machine Creation and Brokering: </p> </li> <li>The Machine is allocated to a particular pool via the scheduler. </li> <li>The <code>machinepoollet</code> responsible for this pool picks up the <code>Machine</code> resource and extracts the <code>ignitionData</code>, <code>networkInterfaces</code> and <code>volumes</code> information from the <code>spec</code> and prepares the IRI machine object. </li> <li>Once the IRIMachine object is prepared the machine create/update request is sent to a broker via the IRI interface(via GRPC call) either against a broker (to copy the resource into another cluster) OR a provider implementation e.g. libvirt-provider which creates a corresponding machine against libvirt/QEMU. </li> <li> <p>Once the response is received from IRI call Machine status is updated with the status received.</p> </li> <li> <p>Network Interface handling: <code>MachineControllerNetworkinterface</code> takes care of attaching/detaching Network interfaces defined for the machine. Once the attachment is successful status is updated from <code>Pending</code> to <code>Attached</code>.</p> </li> <li> <p>Volume handling: <code>MachineControllerVolume</code> takes care of attach/detach of Volumes(Storage) defined for machine. Once the attachment is successful status is updated from <code>Pending</code> to <code>Attached</code>.</p> </li> <li> <p>Ephemeral resource handling: </p> </li> <li>The <code>Volume</code> and <code>NetworkIntreface</code> can be bound with the lifecycle of the Machine by creating them as ephemeral resources. (<code>Note</code>: For more details on how to create ephemeral resources refer to Machine with ephemeral resources)</li> <li>If <code>NetworkIntreface</code> or <code>Volume</code> is defined as ephemeral <code>MachineEphemeralControllers</code> takes care of creating and destroying respective objects on creation/deletion of the machine. </li> </ol>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/compute/machine/#lifecycle-and-states","title":"Lifecycle and States","text":"<p>A Machine can be in the following states: 1. Pending:  A Machine is in a Pending state when the Machine has been accepted by the system, but not yet completely started. This includes time before being bound to a MachinePool, as well as time spent setting up the Machine on that MachinePool.  2. Running: A Machine in Running state when the machine is running on a MachinePool. 2. Shutdown: A Machine is in a Shutdown state. 3. Terminating: A Machine is Terminating. 2. Terminated: A Machine is in the Terminated state when the machine has been permanently stopped and cannot be started.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/compute/machineclass/","title":"MachineClass","text":"<p>A <code>MachineClass</code> is an <code>Ironcore</code> resource used to represent a class/flavor of a Machine. It serves as a means to define the number of resources a <code>Machine</code> object can have as capabilities(For eg, CPU, memory) associated with a particular class. The <code>MachineClassController</code> reconciler leverages this information to create <code>MachineClass</code>.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/compute/machineclass/#example-machine-resource","title":"Example Machine Resource","text":"<p>An example of how to define a MachineClass resource:</p> <pre><code>apiVersion: compute.ironcore.dev/v1alpha1\nkind: MachineClass\nmetadata:\n  name: machineclass-sample\ncapabilities:\n  cpu: 4\n  memory: 16Gi\n</code></pre> <p>Key Fields:</p> <ul> <li>capabilities (<code>ResourceList</code>): capabilities are used to define a list of resources a Machine can have along with its capacity.</li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/compute/machineclass/#reconciliation-process","title":"Reconciliation Process","text":"<ul> <li>MachineClass Creation: The <code>MachineClassController</code> uses the <code>capabilities</code> field in the MachineClass resource to create a flavor of MachineClass resource.</li> <li>MachineClass Deletion: Before deleting any MachineClass it's been ensured that it is not in use by any <code>Machine</code> and then only deleted.</li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/compute/machinepool/","title":"MachinePool","text":"<p>A <code>MachinePool</code> is a resource in <code>Ironcore</code> that represents a pool of compute resources managed collectively. It defines the infrastructure's compute configuration used to provision and manage <code>Machines</code>, ensuring resource availability and compatibility with associated <code>MachineClasses</code>. (<code>Note</code>: One <code>machinepoollet</code> is responsible for one <code>MachinePool</code>)</p>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/compute/machinepool/#example-machinepool-resource","title":"Example MachinePool Resource","text":"<p>An example of how to define a MachinePool resource:</p> <pre><code>apiVersion: compute.ironcore.dev/v1alpha1\nkind: MachinePool\nmetadata:\n  name: machinepool-sample\n  labels:\n    ironcore.dev/az: az1\nspec:\n  providerID: ironcore://shared\n</code></pre> <p>Key Fields:</p> <ul> <li><code>ProviderID</code>(<code>string</code>):  The <code>providerId</code> helps the controller identify and communicate with the correct compute system within the specific backend compute provider. For example <code>ironcore://shared</code></li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/compute/machinepool/#reconciliation-process","title":"Reconciliation Process","text":"<ul> <li>Machine Type Discovery: It constantly checks what kinds of <code>MachineClasses</code> are available in the <code>Ironcore</code> Infrastructure</li> <li>Compatibility Check: Evaluating whether the <code>MachinePool</code> can manage available machine classes based on its capabilities. </li> <li>Status Update: Updating the MachinePool's status to indicate the supported <code>MachineClasses</code> with available capacity and allocatable.</li> <li>Event Handling: Watches for changes in MachineClass resources and ensures the associated MachinePool is reconciled when relevant changes occur.</li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/core/resourcequota/","title":"ResourceQuota","text":"<p>A <code>ResourceQuota</code> in <code>Ironcore</code> provides a mechanism to manage and limit the usage of resources across multiple requesting entities. This allows to protect a system from usage spikes and services can be kept responsive. With the help of <code>ResourceQuota</code> user can define a hard limit with list of resources along with <code>ScopeSelector</code>. The <code>ResourcequotaController</code> reconciler leverages this information to create a ResourceQuota in Ironcore infrastructure. (<code>Note</code>: ResourceQuota is a namespaced resource and it can only limit resource count/accumulated resource usage within deifned namespace)</p>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/core/resourcequota/#example-resourcequota-resource","title":"Example ResourceQuota Resource","text":"<p>An example of how to define a <code>ResourceQuota</code> in <code>Ironcore</code> <pre><code>apiVersion: core.ironcore.dev/v1alpha1\nkind: ResourceQuota\nmetadata:\n  name: resource-quota-sample\nspec:\n  hard: # Hard is the mapping of strictly enforced resource limits.\n    requests.cpu: \"10\"\n    requests.memory: 100Gi\n    requests.storage: 10Ti\n</code></pre></p>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/core/resourcequota/#key-fields","title":"Key Fields:","text":"<ul> <li><code>hard</code>(<code>ResourceList</code>): hard is a <code>ResourceList</code> of the strictly enforced number of resources. <code>ResourceList</code> is a list of ResourceName alongside their resource quantity.</li> <li><code>scopeSelector</code>(<code>ResourceScopeSelector</code>): scopeSelector selects the resources that are subject to this quota. (<code>Note</code>: By using scopeSelectors, only certain resources may be tracked.)</li> </ul> <p>(<code>Note</code>: Refer to API Reference for more detailed description of <code>ResourceList</code> and <code>ResourceScopeSelector</code>.)</p>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/core/resourcequota/#reconciliation-process","title":"Reconciliation Process:","text":"<ul> <li>Gathering matching evaluators: ResourcequotaController retrieves all the matching evaluators from the registry for the specified resources in hard spec. Each resource evaluator implements set of Evaluator interface methods which helps in retrieving the current usage of that perticular resource type.</li> <li>Calculating resource usage: Resource usage is calculated by iterating over each evaluator and listing the namespace resource of that particular type. Listed resources are then filtred out by matching specified scope selector and accumulated usage is calculated. </li> <li>Status update: Once usage data is available resource quota status is updated with the enforced hard resource limits and currently used resources.</li> <li>Resource quota handling: On request of create/update resources whether to allow create/update based on resource quota usage is handled via admission controller. Resources that would exceed the quota will fail with the HTTP status code 403 Forbidden.</li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/ipam/prefix/","title":"Prefix","text":"<p>A <code>Prefix</code> resource provides a fully integrated IP address management(IPAM) solution for <code>Ironcore</code>. It serves as a means to define IP prefixes along with prefix length to a reserved range of IP addresses. It is also possible to define child prefixes with the specified prefix length referring to the parent prefix.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/ipam/prefix/#example-volume-resource","title":"Example Volume Resource","text":"<p>An example of how to define a root <code>Prefix</code> resource in <code>Ironcore</code></p> <p><pre><code>apiVersion: ipam.ironcore.dev/v1alpha1\nkind: Prefix\nmetadata:\n  name: root\n  labels:\n    root-prefix: customer-1\nspec:\n  prefix: 10.0.0.0/24\n</code></pre> An example of how to define a child <code>Prefix</code> resource in <code>Ironcore</code></p> <p><pre><code>apiVersion: ipam.ironcore.dev/v1alpha1\nkind: Prefix\nmetadata:\n  name: child-prefix\nspec:\n  ipFamily: IPv4\n  prefixLength: 9\n  parentSelector:\n    matchLabels:\n      root-prefix: customer-1\n</code></pre> (<code>Note</code>: Refer to E2E Examples for more detailed example on IPAM to understant e2e flow)</p>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/ipam/prefix/#key-fields","title":"Key Fields:","text":"<ul> <li> <p><code>ipFamily</code>(<code>string</code>): <code>ipFamily</code> is the IPFamily of the prefix. If unset but <code>prefix</code> is set, this can be inferred.</p> </li> <li> <p><code>prefix</code> (<code>string</code>):  <code>prefix</code> is the IP prefix to allocate for this Prefix.</p> </li> <li> <p><code>prefixLength</code> (<code>int</code>): <code>prefixLength</code> is the length of prefix to allocate for this Prefix.</p> </li> <li> <p><code>parentRef</code> (<code>string</code>): <code>parentRef</code> references the parent to allocate the Prefix from. If <code>parentRef</code> and <code>parentSelector</code> is empty, the Prefix is considered a root prefix and thus allocated by itself.</p> </li> <li> <p><code>parentSelector</code> (<code>LabelSelector</code>): <code>parentSelector</code> is the LabelSelector to use for determining the parent for this Prefix.</p> </li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/ipam/prefix/#reconciliation-process","title":"Reconciliation Process:","text":"<ul> <li> <p>Allocate root prefix: If <code>parentRef</code> and <code>parentSelector</code> is empty, the PrefixController reconciler considers it as a root prefix and allocates by itself and the status is updated as <code>Allocated</code>.</p> </li> <li> <p>Allocating sub-prefix: If <code>parentRef</code> or <code>parentSelector</code> is set PrefixController lists all the previously allocated prefix allocations by parent prefix. Finds all the active allocations and prunes outdated ones. If no existing PrefixAllocation object is found new <code>PrefixAllocation</code> object is created for the new prefix to allocate. If prefix allocation is successful status is updated to <code>Allocated</code> otherwise to <code>Failed</code>.</p> </li> <li> <p>Prefix allocation scheduler: <code>PrefixAllocationScheduler</code> continuously watches for Prefix resource and tries to schedule all PrefixAllocation objects for which prefix is not yet allocated. PrefixAllocationScheduler determines suitable prefix for allocation by listing available prefixes based on label filter, namespace and desired IP family. Once a suitable prefix is found PrefixAllocation spec.parentRef is updated with the selected prefix reference.</p> </li> <li> <p>Status update: Once prefix allocation is successful status is updated to <code>Allocated</code>. In the case of sub-prefixes once the prefix is allocated <code>PrefixController</code> updates the parent Prefix's status with the used prefix IPs list.</p> </li> </ul> <p>Below is the sample <code>Prefix.status</code> :</p> <pre><code>status:\n  lastPhaseTransitionTime: \"2024-10-21T20:56:24Z\"\n  phase: Allocated\n  used:\n  - 10.0.0.1/32\n  - 10.0.0.2/32\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/networking/loadbalancer/","title":"LoadBalancer","text":"<p>A <code>LoadBalancer</code> resource is an L3(IP-based) load balancer service implementation provided by Ironcore. It provides an externally accessible IP address that sends traffic to the correct port on your cluster nodes. Ironcore LoadBalancer allows targeting multiple <code>NetworkInterfaces</code> and distributes traffic between them. This LoadBalancer supports dual stack IP addresses (IPv4/IPv6). </p>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/networking/loadbalancer/#example-network-resource","title":"Example Network Resource","text":"<p>An example of how to define a <code>LoadBalancer</code> resource in <code>Ironcore</code> <pre><code>apiVersion: networking.ironcore.dev/v1alpha1\nkind: LoadBalancer\nmetadata:\n  namespace: default\n  name: loadbalancer-sample\nspec:\n  type: Public\n  ipFamilies: [IPv4]\n  networkRef:\n    name: network-sample\n  networkInterfaceSelector:\n    matchLabels:\n      app: web\n  ports:\n  - port: 80\n</code></pre> (<code>Note</code>: Refer to E2E Examples for more detailed examples.)</p>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/networking/loadbalancer/#key-fields","title":"Key Fields:","text":"<ul> <li><code>type</code>(<code>string</code>): The type of <code>LoadBalancer</code>. Currently two types of <code>Loadbalancer</code> are supported: <ul> <li><code>Public</code>: LoadBalancer that allocates public IP and routes a stable public IP.</li> <li><code>Internal</code>: LoadBalancer that allocates and routes network-internal, stable IPs.</li> </ul> </li> <li><code>ipFamilies</code>(<code>list</code>): ipFamilies are the IP families the LoadBalancer should have(Supported values are <code>IPv4</code> and <code>IPv6</code>). </li> <li><code>ips</code>(<code>list</code>): The ips are the list of IPs to use. This can only be used when the type is LoadBalancerTypeInternal.</li> <li><code>networkRef</code>(<code>string</code>): networkRef is the Network this LoadBalancer should belong to.</li> <li><code>networkInterfaceSelector</code>(<code>labelSelector</code>): networkInterfaceSelector defines the NetworkInterfaces for which this LoadBalancer should be applied</li> <li><code>ports</code>(<code>list</code>): ports are the list of LoadBalancer ports should allow<ul> <li><code>protocol</code>(<code>string</code>): protocol is the protocol the load balancer should allow. Supported protocols are <code>UDP</code>, <code>TCP</code>, and <code>SCTP</code>, if not specified defaults to TCP.</li> <li><code>port</code>(<code>int</code>): port is the port to allow.</li> <li><code>endPort</code>(<code>int</code>): endPort marks the end of the port range to allow. If unspecified, only a single port <code>port</code> will be allowed.</li> </ul> </li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/networking/loadbalancer/#reconciliation-process","title":"Reconciliation Process:","text":"<ul> <li> <p>NetworkInterfaces selection: LoadBalancerController continuously watches for <code>LoadBalancer</code> resources and reconciles. LoadBalancer resource dynamically selects multiple target <code>NetworkInterfaces</code> via a <code>networkInterfaceSelector</code> LabelSelector from the spec. Once the referenced Network is in <code>Available</code> state, the Loadbalancer destination IP list and referencing <code>NetworkInterface</code> is prepared by iterating over selected NetworkIntrefaces status information.</p> </li> <li> <p>Preparing Routing State Object: Once the destination list is available <code>LoadBalancerRouting</code> resource is created. <code>LoadBalancerRouting</code> describes <code>NetworkInterfaces</code> load balanced traffic is routed to. This object describes the state of the LoadBalancer and results of the LoadBalancer definition specifically <code>networkInterfaceSelector</code> and <code>networkRef</code>.  Later this information is used at the Ironcore API level to describe the explicit targets in a pool traffic is routed to.</p> </li> </ul> <p>Sample <code>LoadBalancerRouting</code> object(<code>Note</code>: it is created by LoadBalancerController) <pre><code>apiVersion: networking.ironcore.dev/v1alpha1\nkind: LoadBalancerRouting\nmetadata:\n  namespace: default\n  name: loadbalancer-sample # Same name as the load balancer it originates from.\n# networkRef references the exact network object the routing belongs to.\nnetworkRef:\n  name: network-sample\n# destinations list the target network interface instances (including UID) for load balancing.\ndestinations:\n  - name: my-machine-interface-1\n    uid: 2020dcf9-e030-427e-b0fc-4fec2016e73a\n  - name: my-machine-interface-2\n    uid: 2020dcf9-e030-427e-b0fc-4fec2016e73d\n</code></pre> LoadBalancer status update: The <code>LoadBalancerController</code> in ironcore-net takes care of allocating IPs for defined <code>ipFamilies</code> in the spec and updates them in its <code>status.ips</code>.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/networking/natgateway/","title":"NATGateway","text":"<p>In the <code>Ironcore</code> project, a <code>NATGateway</code> (Network Address Translation Gateway) facilitates outbound internet connectivity in private subnets, ensuring that instances in private subnets can access external services without exposing them to unauthorized inbound traffic.</p> <p>It is a critical network service that provides secure and controlled internet access for private resources in the <code>Ironcore</code> infrastructure. It is enforced by the underlying <code>Ironcore's</code> network plugin called  ironcore-net </p>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/networking/natgateway/#example-natgateway-resource","title":"Example NATGateway Resource","text":"<p>An example of how to define a <code>NATGateway</code> resource in <code>Ironcore</code></p> <pre><code>apiVersion: networking.ironcore.dev/v1alpha1\nkind: NATGateway\nmetadata:\n  namespace: default\n  name: natgateway-sample\nspec:\n  type: Public\n  ipFamily: IPv4\n  portsPerNetworkInterface: 64\n  networkRef:\n    name: network-sample\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/networking/natgateway/#key-fields","title":"Key Fields","text":"<ul> <li> <p><code>type</code>(<code>string</code>): This represents a NATGateway type that allocates and routes a stable public IP. The supported value for type is <code>public</code></p> </li> <li> <p><code>ipFamily</code>(<code>string</code>): <code>IPFamily</code> is the IP family of the <code>NATGateway</code>. Supported values for IPFamily are <code>IPv4</code> and <code>IPv6</code>.</p> </li> <li> <p><code>portsPerNetworkInterface</code>(<code>int32</code>): This Specifies the number of ports allocated per network interface and controls how many simultaneous connections can be handled per interface. </p> <p>If empty, 2048 (DefaultPortsPerNetworkInterface) is the default.</p> </li> <li> <p><code>networkRef</code>(<code>string</code>): It represents which network this <code>NATGateway</code> serves.</p> </li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/networking/natgateway/#example-use-case","title":"Example Use Case:","text":"<p>Imagine you have a private server in a private subnet without a public IP. It needs to download software updates from the internet. Instead of giving it direct internet access (which compromises security), the server sends its requests through the NAT Gateway. The NAT Gateway fetches the updates and returns them to the server while keeping the server's private IP hidden from the external world.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/networking/natgateway/#reconciliation-process","title":"Reconciliation Process:","text":"<ul> <li> <p>Fetch NATGateway Resource: It fetches the current state of <code>NATGateways</code>, Based on user specifications the desired state of <code>NATGateway</code> is determined. This includes the number of NAT Gateways, their types, associated subnets, and routing configurations.</p> </li> <li> <p>Compare and Reconcile: The reconciler keeps monitoring the state of NAT Gateways to detect any changes or drifts from the desired state, triggering the reconciliation process as needed.</p> <ul> <li> <p>Creation: If a NAT Gateway specified in the desired state does not exist in the current state, it is created. For instance, creating a public NAT Gateway in a public subnet to provide internet access to instances in private subnets.</p> </li> <li> <p>Update: If a NAT Gateway exists but its configuration differs from the desired state, it is updated accordingly. This may involve modifying routing tables or changing associated Elastic IPs.</p> </li> <li> <p>Deletion: If a NAT Gateway exists in the current state but is not present in the desired state, it is deleted to prevent unnecessary resource utilization.</p> </li> </ul> </li> <li> <p>Error Handling and Logging: Throughout the reconciliation process, any errors encountered are logged, schedule retries as necessary to ensure eventual consistency.</p> </li> <li> <p>Update Status: After reconciling all <code>NATGateways</code>, log the successful reconciliation and update the <code>NATGateways</code> status with the corresponding values for <code>ips</code>as shown below.</p> </li> </ul> <pre><code>status:\n  ips:\n  - name: ip1\n    ip: 10.0.0.1\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/networking/network/","title":"Network","text":"<p>A <code>Network</code> resource in <code>Ironcore</code> refers to a logically isolated network.  This further allows you to fully control your networking environment, including resource placement, connectivity, peering and security.  The <code>NetworkController</code> reconciler leverages this information to create a Network in Ironcore infrastructure. <code>Machine</code> type is provided with provision to integrate with the Network via <code>NetworkInterface</code>.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/networking/network/#example-network-resource","title":"Example Network Resource","text":"<p>An example of how to define a <code>Network</code> resource in <code>Ironcore</code> <pre><code>apiVersion: networking.ironcore.dev/v1alpha1\nkind: Network\nmetadata:\n  name: network-sample\nspec:\n  peerings:\n  - name: peering1\n    networkRef:\n      name: network-sample2\n</code></pre></p>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/networking/network/#key-fields","title":"Key Fields:","text":"<ul> <li><code>providerID</code>(<code>string</code>): providerID is the provider-internal ID of the network.</li> <li><code>peerings</code>(<code>list</code>): peerings are the list of network peerings with this network(Optional).</li> <li><code>incomingPeerings</code>(<code>list</code>): incomingPeerings is a list of PeeringClaimRefs which is nothing but peering claim references of other networks.</li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/networking/network/#reconciliation-process","title":"Reconciliation Process:","text":"<ul> <li>Network creation: <code>ironcore-net</code> which is the network provider for Ironcore realizes the <code>Network</code> resource via <code>apinetlet</code> controllers. When an Ironcore <code>Network</code> is created, a corresponding <code>core.apinet.ironcore.dev/Network</code> is created in the apinet cluster. The name of the Network in the apinet cluster is the uid of the Network in the Ironcore cluster.</li> </ul> <p>Once created and with an allocated ID, the Ironcore Network will be patched with the corresponding provider ID of the apinet Network and set to state: Available. The provider ID format &amp; parsing can be found in provider.go.   Once resource is in available state status is marked to <code>Available</code>. The format of a network provider ID is as follows:   <code>ironcore-net://&lt;namespace&gt;/&lt;name&gt;/&lt;id&gt;/&lt;uid&gt;</code></p> <ul> <li>Network peering process: Network peering is a technique used to interleave two isolated networks, allowing members of both networks to communicate with each  other as if they were in the same networking domain,  <code>NetworkPeeringController</code> facilitates this process.</li> <li>Information related to the referenced <code>Network</code> to be paired with is retrieved from the <code>peering</code> part of the spec.</li> <li>Validation is done to see if both Networks have specified a matching peering item (i.e. reference each other via <code>networkRef</code>) to mutually accept the peering.</li> <li> <p>The (binding) phase of a <code>spec.peerings</code> item is reflected in a corresponding <code>status.peerings</code> item with the same name.      The phase can either be <code>Pending</code>, meaning there is no active peering or <code>Bound</code> meaning the peering as described in the <code>spec.peerings</code> item is in place. </p> </li> <li> <p>Network Release Controller: <code>NetworkReleaseController</code> continuously checks if claiming Networks in other Network's peerings section still exist if not present it will be removed from the <code>incomingPeerings</code> list.</p> </li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/networking/networkinterface/","title":"NetworkInterface","text":"<p>A <code>NetworkInterface</code> resource in <code>Ironcore</code> represents a connection point between a virtual machine(VM) and a virtual network. It encapsulates the configuration and life cycle management of the virtual network interface, ensuring seamless connectivity for VMs.</p> <p>The <code>MachineEphemeralNetworkInterfaceReconciler</code> is responsible for managing the lifecycle of ephemeral network interfaces associated with machines. Its primary function is to ensure that the actual state of these network interfaces aligns with the desired state specified in each machine's configuration.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/networking/networkinterface/#example-networkpolicy-resource","title":"Example NetworkPolicy Resource","text":"<p>An example of how to define a <code>NetworkInterface</code> resource in <code>Ironcore</code></p> <p><pre><code>apiVersion: networking.ironcore.dev/v1alpha1\nkind: NetworkInterface\nmetadata:\n  name: networkinterface-sample\nspec:\n  networkRef:\n    name: network-sample\n  ipFamilies:\n    - IPv4\n  ips:\n    - value: 10.0.0.1 # internal IP\n  virtualIP:\n    virtualIPRef:\n      name: virtualip-sample\n</code></pre> Note: For a detailed end-to-end example to understand the ephemeral and non-ephemeral <code>NetworkInterface</code> resource, please refer E2E Examples</p>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/networking/networkinterface/#key-fields","title":"Key Fields","text":"<ul> <li> <p><code>networkRef</code>(<code>string</code>): <code>NetworkRef</code> is the Network this NetworkInterface is connected to</p> </li> <li> <p><code>ipFamilies</code>(<code>list</code>): <code>IPFamilies</code> defines the list of IPFamilies this <code>NetworkInterface</code> supports. Supported values for IPFamily are <code>IPv4</code> and <code>IPv6</code>.</p> </li> <li> <p><code>ips</code>(<code>list</code>): <code>IPs</code> are the list of provided internal IPs which should be assigned to this NetworkInterface</p> </li> <li> <p><code>virtualIP</code>: <code>VirtualIP</code> specifies the public ip that should be assigned to this NetworkInterface.</p> </li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/networking/networkinterface/#reconciliation-process","title":"Reconciliation Process:","text":"<ul> <li> <p>Fetch Machine Resource: Retrieve the specified Machine resource from the reconciliation request. If the Machine is marked for deletion (indicated by a non-zero DeletionTimestamp), exit the process without further action.</p> </li> <li> <p>Generate Desired Ephemeral Network Interfaces: Analyze the Machine's specification to identify the desired ephemeral NetworkInterface resources. Construct a map detailing these desired NetworkInterfaces, including their configurations and expected states.</p> </li> <li> <p>Fetch Existing NetworkInterfaces: List all existing NetworkInterface resources within the same namespace as the Machine.</p> </li> <li> <p>Compare and Reconcile:</p> <ul> <li>For each existing Network Interface: Determine if it is managed by the current Machine and whether it matches the desired state.</li> <li>If unmanaged but should be managed, avoid adopting it to prevent conflicts.</li> <li>For each desired Network Interface not present: Create the missing <code>NetworkInterface</code> and establish the Machine as its controller.</li> </ul> </li> <li> <p>Handle Errors: Collect any errors encountered during the reconciliation of individual NetworkInterfaces. Log these errors and schedule retries as necessary to ensure eventual consistency.</p> </li> <li> <p>Update Status: After reconciling all NetworkInterfaces, log the successful reconciliation and update the <code>NetworkInterface</code> status with the corresponding values for <code>ips</code>, <code>state</code>, and <code>virtualIP</code>, as shown below.</p> </li> </ul> <p><pre><code>status:\n  ips:\n  - 10.0.0.1\n  lastStateTransitionTime: \"2025-01-13T11:39:17Z\"\n  state: Available\n  virtualIP: 172.89.244.23\n</code></pre> The <code>state</code> is updated as one of the following lifecycle states based on the reconciliation result - Pending - Available - Error</p>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/networking/networkpolicy/","title":"NetworkPolicy","text":"<p>In <code>Ironcore</code>, NetworkPolicies are implemented based on the standard Kubernetes <code>NetworkPolicy</code> approach, which is enforced by the underlying <code>Ironcore's</code> network plugin  ironcore-net  and other components. These policies use label selectors to define the source and destination of allowed traffic within the same network and can specify rules for both ingress (incoming) and egress (outgoing) traffic. </p> <p>In the <code>Ironcore</code> ecosystem, the <code>NetworkPolicy</code> has the following characteristics:</p> <ul> <li> <p>NetworkPolicy is applied exclusively to NetworkInterfaces selected using label selectors.</p> </li> <li> <p>These NetworkInterfaces must belong to the same network.</p> </li> <li> <p>The policy governs traffic to and from other <code>NetworkInterfaces</code>, <code>LoadBalancers</code>, etc., based on the rules defined in the NetworkPolicy.</p> </li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/networking/networkpolicy/#example-networkpolicy-resource","title":"Example NetworkPolicy Resource","text":"<p>An example of how to define a <code>NetworkPolicy</code> resource in <code>Ironcore</code></p> <p><pre><code>apiVersion: networking.ironcore.dev/v1alpha1\nkind: NetworkPolicy\nmetadata:\n  namespace: default\n  name: my-network-policy\nspec:\n  networkRef:\n    name: my-network\n  networkInterfaceSelector:\n    matchLabels:\n      app: db\n  policyTypes:\n  - Ingress\n  - Egress\n  ingress:\n  - from:\n    - ipBlock:\n        cidr: 172.17.0.0/16\n    - objectSelector:\n        kind: NetworkInterface\n        matchLabels:\n          app: web\n    - objectSelector:\n        kind: LoadBalancer\n        matchLabels:\n          app: web\n    # Ports always have to be specified. Only traffic matching the ports\n    # will be allowed.\n    ports:\n    - protocol: TCP\n      port: 5432\n  egress:\n  - to:\n    - ipBlock:\n        cidr: 10.0.0.0/24\n    ports:\n    - protocol: TCP\n      port: 8080\n</code></pre> https://github.com/ironcore-dev/ironcore/tree/main/config/samples/e2e/network-policy</p> <p>(<code>Note</code>: Refer to E2E Examples for more detailed example on networkpolicy to understant e2e flow)</p>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/networking/networkpolicy/#key-fields","title":"Key Fields","text":"<ul> <li> <p><code>networkRef</code>(<code>string</code>): NetworkRef is the Network to regulate using this NetworkPolicy.</p> </li> <li> <p><code>networkInterfaceSelector</code>(<code>labelSelector</code>): NetworkInterfaceSelector defines the target <code>NetworkInterfaces</code> for which this <code>NetworkPolicy</code> should be applied.</p> </li> <li> <p><code>policyTypes</code>(<code>list</code>): There are two supported policyTypes <code>Ingress</code> and <code>Egress</code>.</p> </li> <li> <p><code>ingress</code>(<code>list</code>): An Ingress section in a <code>NetworkPolicy</code> defines a list of <code>NetworkPolicyIngressRules</code> that specify which incoming traffic is allowed. Each <code>NetworkPolicy</code> can have multiple ingress rules, and each rule allows traffic that satisfies both the from and ports criteria.</p> </li> </ul> <p>For example, a <code>NetworkPolicy</code> with a single ingress rule may permit traffic on a specific port and only from one of the following sources:   - An IP range, defined using an ipBlock.   - A set of resources identified by an objectSelector.</p> <ul> <li><code>egress</code>(<code>list</code>): egress defines the list of <code>NetworkPolicyEgressRules</code>. Each NetworkPolicy may include a list of allowed egress rules. Each rule allows traffic that matches both <code>to</code> and <code>ports</code> sections. The example policy contains a single rule, which matches traffic on a single port to any destination in 10.0.0.0/24.</li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/networking/networkpolicy/#reconciliation-process","title":"Reconciliation Process:","text":"<p>The <code>NetworkPolicyReconciler</code> in the Ironcore project is responsible for managing the lifecycle of <code>NetworkPolicy</code> resources. Its primary function is to ensure that the rules specified by the user in the NetworkPolicy resource are enforced and applied on the target <code>NetworkInterface</code>.</p> <p>The  apinetlet  component in <code>ironcore-net</code> plugin is responsible for translating the policy rules into another APInet type resource <code>NetworkPolicyRule</code>. Finally, the  metalnetlet  component in <code>ironcore-net</code> and other components propagates these rules for enforcement at <code>dpservice</code> level in the Ironcore infrastucture.</p> <p>The reconciliation process involves several key steps:</p> <ul> <li> <p>Fetching the NetworkPolicy Resource: The reconciler retrieves the NetworkPolicy resource specified in the reconciliation request. If the resource is not found, it may have been deleted, and the reconciler will handle this scenario appropriately.</p> </li> <li> <p>Validating the NetworkPolicy: The retrieved NetworkPolicy is validated to ensure it confirms the expected specifications. This includes checking fields such as NetworkRef, NetworkInterfaceSelector, Ingress, Egress, and PolicyTypes to ensure they are correctly defined.</p> </li> <li> <p>Fetching Associated Network Interfaces: Using the NetworkInterfaceSelector, the reconciler identifies the network interfaces that are subject to the policy.</p> </li> <li> <p>Applying Policy Rules: The reconciler translates the ingress and egress rules defined in the NetworkPolicy into configurations that can be enforced by the underlying network infrastructure. This involves interacting with other components responsible for NetworkPolicy or Firewall rule enforcement.</p> </li> <li> <p>Handling Errors and Reconciliation Loops: If errors occur during any of the above steps, the reconciler will log the issues and may retry the reconciliation. </p> </li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/networking/virtualip/","title":"VirtualIP","text":"<p>A <code>Virtual IP (VIP)</code> in  the <code>Ironcore</code> ecosystem is an abstract network resource representing an IP address that is dynamically associated with an <code>ironcore</code> <code>networkInterface</code>, which in turn is linked to an <code>ironcore machine/vm</code>.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/networking/virtualip/#examaple-virtualip-resource","title":"Examaple VirtualIP Resource","text":"<pre><code>apiVersion: networking.ironcore.dev/v1alpha1\nkind: VirtualIP\nmetadata:\n  name: virtualip-sample\nspec:\n  type: Public\n  ipFamily: IPv4\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/networking/virtualip/#key-fields","title":"Key Fields","text":"<ul> <li> <p><code>type</code>(<code>string</code>):  Currently supported type is <code>public</code>, which allocates and routes a stable public IP.</p> </li> <li> <p><code>ipFamily</code>(<code>string</code>): <code>IPFamily</code> is the ip family of the VirtualIP. Supported values for IPFamily are <code>IPv4</code> and <code>IPv6</code>.</p> </li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/networking/virtualip/#reconciliation-process","title":"Reconciliation Process:","text":"<ul> <li> <p>VirtualIP Creation:  A VirtualIP resource is created, specifying attributes like <code>ipFamily</code>: IPv4 or IPv6 and <code>Type</code>: public </p> </li> <li> <p>Reconciliation and IP Assignment:  The VirtualIP reconciler Creates or updates a corresponding APINet IP in Ironcore's APINet system. Ensures the IP is dynamically allocated and made available for use.</p> </li> <li> <p>Error Handling: If the creation or update of the APINet IP fails, update the VirtualIP status to indicate it is unallocated. Requeue the reconciliation to retry the operation.</p> </li> <li> <p>Synchronize Status: Update the VirtualIP status to reflect the actual state of the APINet IP. If successfully allocated, update the status with the assigned IP address.</p> </li> </ul> <p>for example:   <pre><code>status:\n  ip: 10.0.0.1 # This will be populated by the corresponding controller.\n</code></pre> - Networking Configuration:      - VM Integration: The allocated VirtualIP is associated with the VM through network configuration mechanisms     - Load Balancer Integration: If a load balancer is used, the virtualIP is configured as the frontend IP to route requests to the VM.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/storage/bucket/","title":"Bucket","text":"<p>A <code>Bucket</code> in <code>Ironcore</code> refers to a storage resource that organizes and manages data, similar to the concept of buckets in cloud storage services like Amazon S3. Buckets are containers for storing objects, such as files or data blobs, and are crucial for managing storage workloads.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/storage/bucket/#example-bucket-resource","title":"Example Bucket Resource","text":"<p>An example of how to define a <code>Bucket</code> resource in <code>Ironcore</code></p> <pre><code>apiVersion: storage.ironcore.dev/v1alpha1\nkind: Bucket\nmetadata:\n  name: bucket-sample\nspec:\n  bucketClassRef:\n    name: bucketclass-sample\n#  bucketPoolRef:\n#    name: bucketpool-sample\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/storage/bucket/#key-fields","title":"Key Fields:","text":"<ul> <li><code>bucketClassRef</code>(<code>string</code>): </li> <li>Mandatory field</li> <li> <p><code>BucketClassRef</code> is the BucketClass of a bucket</p> </li> <li> <p><code>bucketPoolRef</code>(<code>string</code>):</p> </li> <li>Optional field</li> <li><code>bucketPoolRef</code> indicates which BucketPool to use for the bucket, if not specified the controller itself picks the available bucketPool</li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/storage/bucket/#usage","title":"Usage","text":"<ul> <li> <p>Data Storage: Use <code>Buckets</code> to store and organize data blobs, files, or any object-based data.</p> </li> <li> <p>Multi-Tenant Workloads: Leverage buckets for isolated and secure data storage in multi-tenant environments by using separate BucketClass or BucketPool references.</p> </li> <li> <p>Secure Access: Buckets store a reference to the <code>Secret</code> securely in their status, and the <code>Secret</code> has the access credentials, which applications can retrieve access details from the <code>Secret</code>.</p> </li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/storage/bucket/#reconciliation-process","title":"Reconciliation Process:","text":"<ul> <li> <p>The controller detects changes and fetches bucket details.</p> </li> <li> <p>Creation/Update ensures the backend bucket exists, metadata is synced, and credentials are updated.</p> </li> <li> <p>The bucket will automatically sync with the backend storage system, and update the Bucket's state (e.g., <code>Available</code>, <code>Pending</code>, or <code>Error</code>) in the bucket's status.</p> </li> <li> <p>Access details and credentials will be managed securely using Kubernetes <code>Secret</code> and the bucket status will track a reference to the <code>Secret</code>.</p> </li> <li> <p>During deletion, resources will be cleaned up gracefully without manual intervention.</p> </li> <li> <p>If the bucket is not ready (e.g., backend issues), reconciliation will retry</p> </li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/storage/bucketclass/","title":"BucketClass","text":"<p>A <code>BucketClass</code> is a concept used to define and manage different types of storage buckets, typically based on resource capabilities. It is conceptually similar to Kubernetes <code>StorageClass</code>, enabling users to specify the desired properties for an Ironcore <code>Bucket</code> resource creation.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/storage/bucketclass/#example-bucketclass-resource","title":"Example BucketClass Resource","text":"<p>An example of how to define a <code>BucketClass</code> resource in <code>Ironcore</code></p> <pre><code>apiVersion: storage.ironcore.dev/v1alpha1\nkind: BucketClass\nmetadata:\n  name: bucketclass-sample\ncapabilities:\n  tps: 100Mi\n  iops: 100\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/storage/bucketclass/#key-fields","title":"Key Fields:","text":"<ul> <li><code>capabilities</code>: Capabilities has <code>tps</code> and <code>iops</code> fields which need to be specified, it's a mandatory field,</li> <li> <p><code>tps</code>(<code>string</code>): The <code>tps</code> represents transactions per second.</p> </li> <li> <p><code>iops</code>(<code>string</code>):  <code>iops</code> is the number of input/output operations a storage device can complete per second.</p> </li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/storage/bucketclass/#usage","title":"Usage","text":"<ul> <li> <p>BucketClass Definition: Create a <code>BucketClass</code> to set storage properties based on resource capabilities.</p> </li> <li> <p>Associate with buckets: Link a <code>BucketClass</code> to a <code>Bucket</code> using a reference in the Bucket resource.</p> </li> <li> <p>Dynamic configuration: Update the <code>BucketClass</code> to modify storage properties for all its Buckets.</p> </li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/storage/bucketclass/#reconciliation-process","title":"Reconciliation Process:","text":"<ul> <li> <p>Fetches &amp; Validates: Retrieves the <code>BucketClass</code> from the cluster and checks if it exists.</p> </li> <li> <p>Synchronizes State: Keeps the <code>BucketClass</code> resource updated with its current state and dependencies.</p> </li> <li> <p>Monitors Dependencies: Watches for changes in dependent Bucket resources and reacts accordingly.</p> </li> <li> <p>Handles Errors: Requeues the reconciliation to handle errors and ensure successful completion.</p> </li> <li> <p>Handles Deletion: Cleans up references, removes the finalizer, and ensures no dependent Buckets exist before deletion.</p> </li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/storage/bucketpool/","title":"BucketPool","text":"<p>A <code>BucketPool</code> is a resource in <code>Ironcore</code> that represents a pool of storage buckets managed collectively. It defines the infrastructure's storage configuration used to provision and manage buckets, ensuring resource availability and compatibility with associated BucketClasses.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/storage/bucketpool/#example-bucketpool-resource","title":"Example BucketPool Resource","text":"<p>An example of how to define a <code>BucketPool</code> resource in <code>Ironcore</code></p> <pre><code>apiVersion: storage.ironcore.dev/v1alpha1\nkind: BucketPool\nmetadata:\n  name: bucketpool-sample\nspec:\n  providerID: ironcore://shared\n#status:\n#  state: Available\n#  availableBucketClasses:\n#    ironcore.dev/fast-class: 10Gi\n#    ironcore.dev/slow-class: 100Gi\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/storage/bucketpool/#key-fields","title":"Key Fields:","text":"<ul> <li> <p><code>ProviderID</code>(<code>string</code>):  The <code>providerId</code> helps the controller identify and communicate with the correct storage system within the specific backened storage porvider.</p> <p>for example <code>ironcore://shared</code></p> </li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/storage/bucketpool/#reconciliation-process","title":"Reconciliation Process:","text":"<ul> <li> <p>Bucket Type Discovery: It constantly checks what kinds of buckets (BucketClasses) are available in the <code>Ironcore</code> Infrastructure.</p> </li> <li> <p>Compatibility Check: Evaluating whether the BucketPool can create and manage each bucket type based on its capabilities.</p> </li> <li> <p>Status Update: Updating the BucketPool's status to indicate the bucket types it supports, like a menu of available options.</p> </li> <li> <p>Event Handling: Watches for changes in BucketClass resources and ensures the associated BucketPool is reconciled when relevant changes occur.</p> </li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/storage/volume/","title":"Volume","text":"<p>The <code>Ironcore</code> <code>Volume</code> is a storage abstraction provided by the <code>Ironcore Runtime Interface</code> <code>(IRI)</code> service, designed to integrate with external storage backend for managing persistent storage. It acts as a managed storage unit, ensuring consistency, scalability, and compatibility with Kubernetes workloads. By integrating Ironcore Volumes with Kubernetes, users benefit from seamless storage management, automation, and advanced features such as encryption and scalability, making it suitable for modern cloud-native and hybrid applications.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/storage/volume/#example-volume-resource","title":"Example Volume Resource","text":"<p>An example of how to define a <code>Volume</code> resource in <code>Ironcore</code></p> <pre><code>apiVersion: storage.ironcore.dev/v1alpha1\nkind: Volume\nmetadata:\n  name: volume-sample\nspec:\n  volumeClassRef:\n    name: volumeclass-sample\n  # volumePoolRef:\n  #   name: volumepool-sample\n  resources:\n    storage: 100Gi\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/storage/volume/#key-fields","title":"Key Fields:","text":"<ul> <li> <p><code>volumeClassRef</code>(<code>string</code>): <code>volumeClassRef</code> refers to the name of an Ironcore <code>volumeClass</code>( for eg: <code>slow</code>, <code>fast</code>, <code>super-fast</code> etc.) to create a volume,</p> </li> <li> <p><code>volumePoolRef</code> (<code>string</code>):   <code>VolumePoolRef</code> indicates which VolumePool to use for a volume. If unset, the scheduler will figure out a suitable <code>VolumePoolRef</code>.</p> </li> <li> <p><code>resources</code>: <code>Resources</code> is a description of the volume's resources and capacity.</p> </li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/storage/volume/#reconciliation-process","title":"Reconciliation Process:","text":"<ul> <li> <p>Fetch Volume Resource: Retrieve the <code>Volume</code> resource and clean up any orphaned <code>IRI</code> volumes if the resource is missing.</p> </li> <li> <p>Add Finalizer: Ensure a finalizer is added to manage cleanup during deletion.</p> </li> <li> <p>Check IRI Volumes: List and identify <code>IRI</code> volumes linked to the <code>Volume</code> resource.</p> </li> <li> <p>Create or Update Volume:</p> </li> <li>Create a new IRI volume if none exists.</li> <li> <p>Update existing IRI volumes if attributes like size or encryption need adjustments.</p> </li> <li> <p>Sync Status: Reflect the IRI volume's state (e.g., Pending, Available) in the Kubernetes Volume resource's status.</p> </li> <li> <p>Handle Deletion: Safely delete all associated IRI volumes and remove the finalizer to complete the resource lifecycle.</p> </li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/storage/volumeclass/","title":"VolumeClass","text":"<p>The <code>VolumeClass</code> in <code>Ironcore</code> is a Kubernetes-like abstraction that defines a set of parameters or configurations for provisioning storage resources through the <code>Ironcore Runtime Interface (IRI)</code>. It is conceptually similar to Kubernetes <code>StorageClass</code>, enabling users to specify the desired properties for an Ironcore <code>Volume</code> resource creation.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/storage/volumeclass/#example-volumeclass-resource","title":"Example VolumeClass Resource","text":"<p>An example of how to define a <code>VolumeClass</code> resource in <code>Ironcore</code></p> <pre><code>apiVersion: storage.ironcore.dev/v1alpha1\nkind: VolumeClass\nmetadata:\n  name: volumeclass-sample\ncapabilities:\n  tps: 100Mi\n  iops: 100\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/storage/volumeclass/#key-fields","title":"Key Fields:","text":"<ul> <li><code>capabilities</code>: Capabilities has tps and iops fields that need to be specified, it's a mandatory field,</li> <li> <p><code>tps</code>(<code>string</code>): The <code>tps</code> represents transactions per second.</p> </li> <li> <p><code>iops</code>(<code>string</code>): <code>iops</code> is the number of input/output operations a storage device can complete per second.</p> </li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/storage/volumeclass/#usage","title":"Usage","text":"<ul> <li> <p>VolumeClass Definition: Create a <code>VolumeClass</code> to set storage properties based on resource capabilities.</p> </li> <li> <p>Associate with Volume: Link a <code>VolumeClass</code> to a <code>Volume</code> using a reference in the Volume resource.</p> </li> <li> <p>Dynamic configuration: Update the <code>VolumeClass</code> to modify storage properties for all its Volumes.</p> </li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/storage/volumeclass/#reconciliation-process","title":"Reconciliation Process:","text":"<ul> <li> <p>Fetches &amp; Validates: Retrieves the VolumeClass from the cluster and checks if it exists.</p> </li> <li> <p>Synchronizes State: Keeps the VolumeClass resource updated with its current state and dependencies.</p> </li> <li> <p>Monitors Dependencies: Watches for changes in dependent Volume resources and reacts accordingly.</p> </li> <li> <p>Handles Errors: Requeues the reconciliation to handle errors and ensure successful completion.</p> </li> <li> <p>Handles Deletion: Cleans up references, removes the finalizer, and ensures no dependent Volumes exist before deletion.</p> </li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/storage/volumepool/","title":"VolumePool","text":"<p>A <code>VolumePool</code> is a resource in <code>Ironcore</code> that represents a pool of storage volume managed collectively. It defines the infrastructure's storage configuration used to provision and manage volumes, ensuring resource availability and compatibility with associated <code>VolumeClasses</code>.</p>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/storage/volumepool/#example-volumepool-resource","title":"Example VolumePool Resource","text":"<p>An example of how to define a <code>VolumePool</code> resource in <code>Ironcore</code></p> <pre><code>apiVersion: storage.ironcore.dev/v1alpha1\nkind: VolumePool\nmetadata:\n  name: volumepool-sample\nspec:\n  providerID: ironcore://shared\n#status:\n#  state: Available\n#  availableVolumeClasses:\n#    ironcore.dev/fast-class: 10Gi\n#    ironcore.dev/slow-class: 100Gi\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/storage/volumepool/#key-fields","title":"Key Fields:","text":"<ul> <li> <p><code>providerID</code>(<code>string</code>): The <code>providerId</code> helps the controller identify and communicate with the correct storage system within the specific backened storage porvider.</p> <p>for example <code>ironcore://shared</code></p> </li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore/usage/storage/volumepool/#reconciliation-process","title":"Reconciliation Process:","text":"<ul> <li> <p>Volume Type Discovery: It constantly checks what kinds of volumes (volumeClasses) are available in the <code>Ironcore</code> Infrastructure.</p> </li> <li> <p>Compatibility Check: Evaluating whether the volumePool can create and manage each volume type based on its capabilities.</p> </li> <li> <p>Status Update: Updating the VolumePool's status to indicate the volume types it supports, like a menu of available options.</p> </li> <li> <p>Event Handling: Watches for changes in VolumeClass resources and ensures the associated VolumePool is reconciled when relevant changes occur.</p> </li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore-net/","title":"ironcore-net Documentation","text":"<p>This page contains the documentation of the ironcore-net project which is part  of the ironcore-dev organization.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/","title":"Core","text":"<p>Packages:</p> <ul> <li> core.apinet.ironcore.dev/v1alpha1 </li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1","title":"core.apinet.ironcore.dev/v1alpha1","text":"<p>Package v1alpha1 is the v1alpha1 version of the API.</p> <p>Resource Types:</p> <ul><li> DaemonSet </li><li> IP </li><li> IPAddress </li><li> Instance </li><li> LoadBalancer </li><li> LoadBalancerRouting </li><li> NATGateway </li><li> NATGatewayAutoscaler </li><li> NATTable </li><li> Network </li><li> NetworkID </li><li> NetworkInterface </li><li> NetworkPolicy </li><li> NetworkPolicyRule </li><li> Node </li></ul>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.DaemonSet","title":"DaemonSet","text":"<p>DaemonSet is the schema for the daemonsets API.</p> Field Description <code>apiVersion</code> string <code> core.apinet.ironcore.dev/v1alpha1 </code> <code>kind</code> string  <code>DaemonSet</code> <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>spec</code>  DaemonSetSpec  <code>nodeSelector</code>  Kubernetes meta/v1.LabelSelector  <p>Selector selects all Instance that are managed by this daemon set.</p> <code>template</code>  InstanceTemplate  <p>Template is the instance template.</p> <code>status</code>  DaemonSetStatus"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.IP","title":"IP","text":"<p>IP is the schema for the ips API.</p> Field Description <code>apiVersion</code> string <code> core.apinet.ironcore.dev/v1alpha1 </code> <code>kind</code> string  <code>IP</code> <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>spec</code>  IPSpec  <code>type</code>  IPType  <code>ipFamily</code>  Kubernetes core/v1.IPFamily  <code>ip</code>  github.com/ironcore-dev/ironcore-net/apimachinery/api/net.IP  <code>claimRef</code>  IPClaimRef  <code>status</code>  IPStatus"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.IPAddress","title":"IPAddress","text":"<p>IPAddress is the schema for the ipaddresses API.</p> Field Description <code>apiVersion</code> string <code> core.apinet.ironcore.dev/v1alpha1 </code> <code>kind</code> string  <code>IPAddress</code> <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>spec</code>  IPAddressSpec  <code>ip</code>  github.com/ironcore-dev/ironcore-net/apimachinery/api/net.IP  <code>claimRef</code>  IPAddressClaimRef"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.Instance","title":"Instance","text":"<p>Instance is the schema for the instances API.</p> Field Description <code>apiVersion</code> string <code> core.apinet.ironcore.dev/v1alpha1 </code> <code>kind</code> string  <code>Instance</code> <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>spec</code>  InstanceSpec  <code>type</code>  InstanceType  <p>Type specifies the InstanceType to deploy.</p> <code>loadBalancerType</code>  LoadBalancerType  <p>LoadBalancerType is the load balancer type this instance is for.</p> <code>networkRef</code>  Kubernetes core/v1.LocalObjectReference  <p>NetworkRef references the network the instance is on.</p> <code>ips</code>  []github.com/ironcore-dev/ironcore-net/apimachinery/api/net.IP  <p>IPs are the IPs of the instance.</p> <code>loadBalancerPorts</code>  []LoadBalancerPort  <p>LoadBalancerPorts are the load balancer ports of this instance.</p> <code>affinity</code>  Affinity  <p>Affinity are affinity constraints.</p> <code>topologySpreadConstraints</code>  []TopologySpreadConstraint  <p>TopologySpreadConstraints describes how a group of instances ought to spread across topology domains. Scheduler will schedule instances in a way which abides by the constraints. All topologySpreadConstraints are ANDed.</p> <code>nodeRef</code>  Kubernetes core/v1.LocalObjectReference  <p>NodeRef references the node hosting the load balancer instance. Will be set by the scheduler if empty.</p> <code>status</code>  InstanceStatus"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.LoadBalancer","title":"LoadBalancer","text":"<p>LoadBalancer is the schema for the loadbalancers API.</p> Field Description <code>apiVersion</code> string <code> core.apinet.ironcore.dev/v1alpha1 </code> <code>kind</code> string  <code>LoadBalancer</code> <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>spec</code>  LoadBalancerSpec  <code>type</code>  LoadBalancerType  <p>Type specifies the type of load balancer.</p> <code>networkRef</code>  Kubernetes core/v1.LocalObjectReference  <p>NetworkRef references the network the load balancer is part of.</p> <code>ips</code>  []LoadBalancerIP  (Optional) <p>IPs specifies the IPs of the load balancer.</p> <code>ports</code>  []LoadBalancerPort  <p>Ports are the ports the load balancer should allow. If empty, the load balancer allows all ports.</p> <code>selector</code>  Kubernetes meta/v1.LabelSelector  <p>Selector selects all Instance that are managed by this daemon set.</p> <code>template</code>  InstanceTemplate  <p>Template is the instance template.</p> <code>status</code>  LoadBalancerStatus"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.LoadBalancerRouting","title":"LoadBalancerRouting","text":"<p>LoadBalancerRouting is the schema for the loadbalancerroutings API.</p> Field Description <code>apiVersion</code> string <code> core.apinet.ironcore.dev/v1alpha1 </code> <code>kind</code> string  <code>LoadBalancerRouting</code> <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>destinations</code>  []LoadBalancerDestination"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.NATGateway","title":"NATGateway","text":"<p>NATGateway is the schema for the natgateways API.</p> Field Description <code>apiVersion</code> string <code> core.apinet.ironcore.dev/v1alpha1 </code> <code>kind</code> string  <code>NATGateway</code> <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>spec</code>  NATGatewaySpec  <code>ipFamily</code>  Kubernetes core/v1.IPFamily  <p>IPFamily is the IP family of the NAT gateway.</p> <code>networkRef</code>  Kubernetes core/v1.LocalObjectReference  <p>NetworkRef references the network the NAT gateway is part of.</p> <code>ips</code>  []NATGatewayIP  (Optional) <p>IPs specifies the IPs of the NAT gateway.</p> <code>portsPerNetworkInterface</code>  int32  <p>PortsPerNetworkInterface specifies how many ports to allocate per network interface.</p> <code>status</code>  NATGatewayStatus"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.NATGatewayAutoscaler","title":"NATGatewayAutoscaler","text":"<p>NATGatewayAutoscaler is the schema for the natgatewayautoscalers API.</p> Field Description <code>apiVersion</code> string <code> core.apinet.ironcore.dev/v1alpha1 </code> <code>kind</code> string  <code>NATGatewayAutoscaler</code> <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>spec</code>  NATGatewayAutoscalerSpec  <code>natGatewayRef</code>  Kubernetes core/v1.LocalObjectReference  <p>NATGatewayRef points to the target NATGateway to scale.</p> <code>minPublicIPs</code>  int32  <p>MinPublicIPs is the minimum number of public IPs to allocate for a NAT Gateway.</p> <code>maxPublicIPs</code>  int32  <p>MaxPublicIPs is the maximum number of public IPs to allocate for a NAT Gateway.</p> <code>status</code>  NATGatewayAutoscalerStatus"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.NATTable","title":"NATTable","text":"<p>NATTable is the schema for the nattables API.</p> Field Description <code>apiVersion</code> string <code> core.apinet.ironcore.dev/v1alpha1 </code> <code>kind</code> string  <code>NATTable</code> <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>ips</code>  []NATIP  <p>IPs specifies how to NAT the IPs for the NAT gateway.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.Network","title":"Network","text":"<p>Network is the schema for the networks API.</p> Field Description <code>apiVersion</code> string <code> core.apinet.ironcore.dev/v1alpha1 </code> <code>kind</code> string  <code>Network</code> <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>spec</code>  NetworkSpec  <code>id</code>  string  <p>ID is the ID of the network.</p> <code>peerings</code>  []NetworkPeering  <p>Peerings are the network peerings with this network</p> <code>status</code>  NetworkStatus"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.NetworkID","title":"NetworkID","text":"<p>NetworkID is the schema for the networkids API.</p> Field Description <code>apiVersion</code> string <code> core.apinet.ironcore.dev/v1alpha1 </code> <code>kind</code> string  <code>NetworkID</code> <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>spec</code>  NetworkIDSpec  <code>claimRef</code>  NetworkIDClaimRef"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.NetworkInterface","title":"NetworkInterface","text":"<p>NetworkInterface is the schema for the networkinterfaces API.</p> Field Description <code>apiVersion</code> string <code> core.apinet.ironcore.dev/v1alpha1 </code> <code>kind</code> string  <code>NetworkInterface</code> <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>spec</code>  NetworkInterfaceSpec  <code>nodeRef</code>  Kubernetes core/v1.LocalObjectReference  <p>NodeRef is the node the network interface is hosted on.</p> <code>networkRef</code>  Kubernetes core/v1.LocalObjectReference  <p>NetworkRef references the network that the network interface is in.</p> <code>ips</code>  []github.com/ironcore-dev/ironcore-net/apimachinery/api/net.IP  <p>IPs are the internal IPs of the network interface.</p> <code>prefixes</code>  []github.com/ironcore-dev/ironcore-net/apimachinery/api/net.IPPrefix  <p>Prefixes are additional prefixes to route to the network interface.</p> <code>natGateways</code>  []NetworkInterfaceNAT  <p>NATs specify the NAT of the network interface IP family. Can only be set if there is no matching IP family in PublicIPs.</p> <code>publicIPs</code>  []NetworkInterfacePublicIP  (Optional) <p>PublicIPs are the public IPs the network interface should have.</p> <code>status</code>  NetworkInterfaceStatus"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.NetworkPolicy","title":"NetworkPolicy","text":"<p>NetworkPolicy is the Schema for the networkpolicies API.</p> Field Description <code>apiVersion</code> string <code> core.apinet.ironcore.dev/v1alpha1 </code> <code>kind</code> string  <code>NetworkPolicy</code> <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>spec</code>  NetworkPolicySpec  <code>networkRef</code>  Kubernetes core/v1.LocalObjectReference  <p>NetworkRef is the network to regulate using this policy.</p> <code>networkInterfaceSelector</code>  Kubernetes meta/v1.LabelSelector  <p>NetworkInterfaceSelector selects the network interfaces that are subject to this policy.</p> <code>priority</code>  int32  <p>Priority is an optional field that specifies the order in which the policy is applied. Policies with higher \u201corder\u201d are applied after those with lower order.  If the order is omitted, it may be considered to be \u201cinfinite\u201d - i.e. the policy will be applied last.  Policies with identical order will be applied in alphanumerical order based on the Policy \u201cName\u201d.</p> <code>ingress</code>  []NetworkPolicyIngressRule  <p>Ingress specifies rules for ingress traffic.</p> <code>egress</code>  []NetworkPolicyEgressRule  <p>Egress specifies rules for egress traffic.</p> <code>policyTypes</code>  []PolicyType  <p>PolicyTypes specifies the types of policies this network policy contains.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.NetworkPolicyRule","title":"NetworkPolicyRule","text":"<p>NetworkPolicyRule is the schema for the networkpolicyrules API.</p> Field Description <code>apiVersion</code> string <code> core.apinet.ironcore.dev/v1alpha1 </code> <code>kind</code> string  <code>NetworkPolicyRule</code> <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>networkRef</code>  LocalUIDReference  <p>NetworkRef is the network to which network policy is applied.</p> <code>targets</code>  []TargetNetworkInterface  <p>Targets are the targets of the network policy.</p> <code>priority</code>  int32  <p>Priority is an optional field that specifies the order in which the policy is applied.</p> <code>ingressRule</code>  []Rule  <p>IngressRules are the ingress rules.</p> <code>egressRule</code>  []Rule  <p>EgressRules are the egress rules.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.Node","title":"Node","text":"<p>Node is the schema for the nodes API.</p> Field Description <code>apiVersion</code> string <code> core.apinet.ironcore.dev/v1alpha1 </code> <code>kind</code> string  <code>Node</code> <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>spec</code>  NodeSpec  <code>status</code>  NodeStatus"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.Affinity","title":"Affinity","text":"<p> (Appears on:InstanceSpec) </p> Field Description <code>nodeAffinity</code>  NodeAffinity  <code>instanceAntiAffinity</code>  InstanceAntiAffinity"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.DaemonSetSpec","title":"DaemonSetSpec","text":"<p> (Appears on:DaemonSet) </p> Field Description <code>nodeSelector</code>  Kubernetes meta/v1.LabelSelector  <p>Selector selects all Instance that are managed by this daemon set.</p> <code>template</code>  InstanceTemplate  <p>Template is the instance template.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.DaemonSetStatus","title":"DaemonSetStatus","text":"<p> (Appears on:DaemonSet) </p> Field Description <code>collisionCount</code>  int32"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.IPAddressClaimRef","title":"IPAddressClaimRef","text":"<p> (Appears on:IPAddressSpec) </p> Field Description <code>group</code>  string  <code>resource</code>  string  <code>namespace</code>  string  <code>name</code>  string  <code>uid</code>  k8s.io/apimachinery/pkg/types.UID"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.IPAddressSpec","title":"IPAddressSpec","text":"<p> (Appears on:IPAddress) </p> Field Description <code>ip</code>  github.com/ironcore-dev/ironcore-net/apimachinery/api/net.IP  <code>claimRef</code>  IPAddressClaimRef"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.IPBlock","title":"IPBlock","text":"<p> (Appears on:NetworkPolicyPeer, Rule) </p> <p>IPBlock specifies an ip block with optional exceptions.</p> Field Description <code>cidr</code>  github.com/ironcore-dev/ironcore-net/apimachinery/api/net.IPPrefix  <p>CIDR is a string representing the ip block.</p> <code>except</code>  []github.com/ironcore-dev/ironcore-net/apimachinery/api/net.IPPrefix  <p>Except is a slice of CIDRs that should not be included within the specified CIDR. Values will be rejected if they are outside CIDR.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.IPClaimRef","title":"IPClaimRef","text":"<p> (Appears on:IPSpec) </p> Field Description <code>group</code>  string  <code>resource</code>  string  <code>name</code>  string  <code>uid</code>  k8s.io/apimachinery/pkg/types.UID"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.IPSpec","title":"IPSpec","text":"<p> (Appears on:IP) </p> Field Description <code>type</code>  IPType  <code>ipFamily</code>  Kubernetes core/v1.IPFamily  <code>ip</code>  github.com/ironcore-dev/ironcore-net/apimachinery/api/net.IP  <code>claimRef</code>  IPClaimRef"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.IPStatus","title":"IPStatus","text":"<p> (Appears on:IP) </p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.IPType","title":"IPType (<code>string</code> alias)","text":"<p> (Appears on:IPSpec) </p> Value Description <p>\"Public\"</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.InstanceAffinityTerm","title":"InstanceAffinityTerm","text":"<p> (Appears on:InstanceAntiAffinity) </p> <p>InstanceAffinityTerm defines a set of instances (namely those matching the labelSelector that this instance should be co-located (affinity) or not co-located (anti-affinity) with, where co-located is defined as running on a node whose value of the label with key  matches that of any node on which a instance of the set of instances is running. Field Description <code>labelSelector</code>  Kubernetes meta/v1.LabelSelector  <p>LabelSelector over a set of resources, in this case instances.</p> <code>topologyKey</code>  string  <p>TopologyKey indicates that this instance should be co-located (affinity) or not co-located (anti-affinity) with the instances matching the labelSelector, where co-located is defined as running on a node whose value of the label with key topologyKey matches that of any node on which any of the selected instances is running. Empty topologyKey is not allowed.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.InstanceAntiAffinity","title":"InstanceAntiAffinity","text":"<p> (Appears on:Affinity) </p> Field Description <code>requiredDuringSchedulingIgnoredDuringExecution</code>  []InstanceAffinityTerm  <p>RequiredDuringSchedulingIgnoredDuringExecution specifies anti-affinity requirements at scheduling time, that, if not met, will cause the instance not be scheduled onto the node. When there are multiple elements, the lists of nodes corresponding to each instanceAffinityTerm are intersected, i.e. all terms must be satisfied.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.InstanceSpec","title":"InstanceSpec","text":"<p> (Appears on:Instance, InstanceTemplate) </p> Field Description <code>type</code>  InstanceType  <p>Type specifies the InstanceType to deploy.</p> <code>loadBalancerType</code>  LoadBalancerType  <p>LoadBalancerType is the load balancer type this instance is for.</p> <code>networkRef</code>  Kubernetes core/v1.LocalObjectReference  <p>NetworkRef references the network the instance is on.</p> <code>ips</code>  []github.com/ironcore-dev/ironcore-net/apimachinery/api/net.IP  <p>IPs are the IPs of the instance.</p> <code>loadBalancerPorts</code>  []LoadBalancerPort  <p>LoadBalancerPorts are the load balancer ports of this instance.</p> <code>affinity</code>  Affinity  <p>Affinity are affinity constraints.</p> <code>topologySpreadConstraints</code>  []TopologySpreadConstraint  <p>TopologySpreadConstraints describes how a group of instances ought to spread across topology domains. Scheduler will schedule instances in a way which abides by the constraints. All topologySpreadConstraints are ANDed.</p> <code>nodeRef</code>  Kubernetes core/v1.LocalObjectReference  <p>NodeRef references the node hosting the load balancer instance. Will be set by the scheduler if empty.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.InstanceStatus","title":"InstanceStatus","text":"<p> (Appears on:Instance) </p> Field Description <code>ips</code>  []github.com/ironcore-dev/ironcore-net/apimachinery/api/net.IP  <code>collisionCount</code>  int32"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.InstanceTemplate","title":"InstanceTemplate","text":"<p> (Appears on:DaemonSetSpec, LoadBalancerSpec) </p> Field Description <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>spec</code>  InstanceSpec  <code>type</code>  InstanceType  <p>Type specifies the InstanceType to deploy.</p> <code>loadBalancerType</code>  LoadBalancerType  <p>LoadBalancerType is the load balancer type this instance is for.</p> <code>networkRef</code>  Kubernetes core/v1.LocalObjectReference  <p>NetworkRef references the network the instance is on.</p> <code>ips</code>  []github.com/ironcore-dev/ironcore-net/apimachinery/api/net.IP  <p>IPs are the IPs of the instance.</p> <code>loadBalancerPorts</code>  []LoadBalancerPort  <p>LoadBalancerPorts are the load balancer ports of this instance.</p> <code>affinity</code>  Affinity  <p>Affinity are affinity constraints.</p> <code>topologySpreadConstraints</code>  []TopologySpreadConstraint  <p>TopologySpreadConstraints describes how a group of instances ought to spread across topology domains. Scheduler will schedule instances in a way which abides by the constraints. All topologySpreadConstraints are ANDed.</p> <code>nodeRef</code>  Kubernetes core/v1.LocalObjectReference  <p>NodeRef references the node hosting the load balancer instance. Will be set by the scheduler if empty.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.InstanceType","title":"InstanceType (<code>string</code> alias)","text":"<p> (Appears on:InstanceSpec) </p> Value Description <p>\"LoadBalancer\"</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.LoadBalancerDestination","title":"LoadBalancerDestination","text":"<p> (Appears on:LoadBalancerRouting) </p> <p>LoadBalancerDestination is the destination of the load balancer.</p> Field Description <code>ip</code>  github.com/ironcore-dev/ironcore-net/apimachinery/api/net.IP  <p>IP is the target IP.</p> <code>targetRef</code>  LoadBalancerTargetRef  <p>TargetRef is the target providing the destination.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.LoadBalancerIP","title":"LoadBalancerIP","text":"<p> (Appears on:LoadBalancerSpec) </p> Field Description <code>name</code>  string  <p>Name is the name of the load balancer IP.</p> <code>ipFamily</code>  Kubernetes core/v1.IPFamily  <p>IPFamily is the IP family of the IP. Has to match IP if specified. If unspecified and IP is specified, will be defaulted by using the IP family of IP. If only IPFamily is specified, a random IP of that family will be allocated if possible.</p> <code>ip</code>  github.com/ironcore-dev/ironcore-net/apimachinery/api/net.IP  <p>IP specifies a specific IP to allocate. If empty, a random IP will be allocated if possible.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.LoadBalancerPort","title":"LoadBalancerPort","text":"<p> (Appears on:InstanceSpec, LoadBalancerSpec) </p> Field Description <code>protocol</code>  Kubernetes core/v1.Protocol  <p>Protocol is the protocol the load balancer should allow. If not specified, defaults to TCP.</p> <code>port</code>  int32  <p>Port is the port to allow.</p> <code>endPort</code>  int32  <p>EndPort marks the end of the port range to allow. If unspecified, only a single port, Port, will be allowed.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.LoadBalancerSpec","title":"LoadBalancerSpec","text":"<p> (Appears on:LoadBalancer) </p> Field Description <code>type</code>  LoadBalancerType  <p>Type specifies the type of load balancer.</p> <code>networkRef</code>  Kubernetes core/v1.LocalObjectReference  <p>NetworkRef references the network the load balancer is part of.</p> <code>ips</code>  []LoadBalancerIP  (Optional) <p>IPs specifies the IPs of the load balancer.</p> <code>ports</code>  []LoadBalancerPort  <p>Ports are the ports the load balancer should allow. If empty, the load balancer allows all ports.</p> <code>selector</code>  Kubernetes meta/v1.LabelSelector  <p>Selector selects all Instance that are managed by this daemon set.</p> <code>template</code>  InstanceTemplate  <p>Template is the instance template.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.LoadBalancerStatus","title":"LoadBalancerStatus","text":"<p> (Appears on:LoadBalancer) </p> Field Description <code>collisionCount</code>  int32  <p>CollisionCount is used to construct names for IP addresses for the load balancer.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.LoadBalancerTargetRef","title":"LoadBalancerTargetRef","text":"<p> (Appears on:LoadBalancerDestination) </p> <p>LoadBalancerTargetRef is a load balancer target.</p> Field Description <code>uid</code>  k8s.io/apimachinery/pkg/types.UID  <p>UID is the UID of the target.</p> <code>name</code>  string  <p>Name is the name of the target.</p> <code>nodeRef</code>  Kubernetes core/v1.LocalObjectReference  <p>NodeRef references the node the destination network interface is on.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.LoadBalancerType","title":"LoadBalancerType (<code>string</code> alias)","text":"<p> (Appears on:InstanceSpec, LoadBalancerSpec) </p> Value Description <p>\"Internal\"</p> <p>\"Public\"</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.LocalUIDReference","title":"LocalUIDReference","text":"<p> (Appears on:NetworkPolicyRule, TargetNetworkInterface) </p> <p>LocalUIDReference is a reference to another entity including its UID</p> Field Description <code>name</code>  string  <p>Name is the name of the referenced entity.</p> <code>uid</code>  k8s.io/apimachinery/pkg/types.UID  <p>UID is the UID of the referenced entity.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.NATGatewayAutoscalerSpec","title":"NATGatewayAutoscalerSpec","text":"<p> (Appears on:NATGatewayAutoscaler) </p> Field Description <code>natGatewayRef</code>  Kubernetes core/v1.LocalObjectReference  <p>NATGatewayRef points to the target NATGateway to scale.</p> <code>minPublicIPs</code>  int32  <p>MinPublicIPs is the minimum number of public IPs to allocate for a NAT Gateway.</p> <code>maxPublicIPs</code>  int32  <p>MaxPublicIPs is the maximum number of public IPs to allocate for a NAT Gateway.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.NATGatewayAutoscalerStatus","title":"NATGatewayAutoscalerStatus","text":"<p> (Appears on:NATGatewayAutoscaler) </p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.NATGatewayIP","title":"NATGatewayIP","text":"<p> (Appears on:NATGatewaySpec) </p> Field Description <code>name</code>  string  <p>Name is the semantic name of the NAT gateway IP.</p> <code>ip</code>  github.com/ironcore-dev/ironcore-net/apimachinery/api/net.IP  <p>IP specifies a specific IP to allocate. If empty, a random IP will be allocated if possible.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.NATGatewaySpec","title":"NATGatewaySpec","text":"<p> (Appears on:NATGateway) </p> Field Description <code>ipFamily</code>  Kubernetes core/v1.IPFamily  <p>IPFamily is the IP family of the NAT gateway.</p> <code>networkRef</code>  Kubernetes core/v1.LocalObjectReference  <p>NetworkRef references the network the NAT gateway is part of.</p> <code>ips</code>  []NATGatewayIP  (Optional) <p>IPs specifies the IPs of the NAT gateway.</p> <code>portsPerNetworkInterface</code>  int32  <p>PortsPerNetworkInterface specifies how many ports to allocate per network interface.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.NATGatewayStatus","title":"NATGatewayStatus","text":"<p> (Appears on:NATGateway) </p> Field Description <code>usedNATIPs</code>  int64  <p>UsedNATIPs is the number of NAT IPs in-use.</p> <code>requestedNATIPs</code>  int64  <p>RequestedNATIPs is the number of requested NAT IPs.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.NATIP","title":"NATIP","text":"<p> (Appears on:NATTable) </p> Field Description <code>ip</code>  github.com/ironcore-dev/ironcore-net/apimachinery/api/net.IP  <p>IP is the IP to NAT.</p> <code>sections</code>  []NATIPSection  <p>Sections are the sections of the NATIP.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.NATIPSection","title":"NATIPSection","text":"<p> (Appears on:NATIP) </p> Field Description <code>ip</code>  github.com/ironcore-dev/ironcore-net/apimachinery/api/net.IP  <p>IP is the source IP.</p> <code>port</code>  int32  <p>Port is the start port of the section.</p> <code>endPort</code>  int32  <p>EndPort is the end port of the section</p> <code>targetRef</code>  NATTableIPTargetRef  <p>TargetRef references the entity having the IP.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.NATTableIPTargetRef","title":"NATTableIPTargetRef","text":"<p> (Appears on:NATIPSection) </p> Field Description <code>uid</code>  k8s.io/apimachinery/pkg/types.UID  <p>UID is the UID of the target.</p> <code>name</code>  string  <p>Name is the name of the target.</p> <code>nodeRef</code>  Kubernetes core/v1.LocalObjectReference  <p>NodeRef references the node the destination network interface is on.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.NetworkIDClaimRef","title":"NetworkIDClaimRef","text":"<p> (Appears on:NetworkIDSpec) </p> Field Description <code>group</code>  string  <code>resource</code>  string  <code>namespace</code>  string  <code>name</code>  string  <code>uid</code>  k8s.io/apimachinery/pkg/types.UID"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.NetworkIDSpec","title":"NetworkIDSpec","text":"<p> (Appears on:NetworkID) </p> Field Description <code>claimRef</code>  NetworkIDClaimRef"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.NetworkInterfaceNAT","title":"NetworkInterfaceNAT","text":"<p> (Appears on:NetworkInterfaceSpec) </p> Field Description <code>ipFamily</code>  Kubernetes core/v1.IPFamily  <p>IPFamily is the IP family of the handling NAT gateway.</p> <code>claimRef</code>  NetworkInterfaceNATClaimRef  <p>ClaimRef references the NAT claim handling the network interface\u2019s NAT.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.NetworkInterfaceNATClaimRef","title":"NetworkInterfaceNATClaimRef","text":"<p> (Appears on:NetworkInterfaceNAT) </p> Field Description <code>name</code>  string  <p>Name is the name of the claiming NAT gateway.</p> <code>uid</code>  k8s.io/apimachinery/pkg/types.UID  <p>UID is the uid of the claiming NAT gateway.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.NetworkInterfacePublicIP","title":"NetworkInterfacePublicIP","text":"<p> (Appears on:NetworkInterfaceSpec) </p> Field Description <code>name</code>  string  <p>Name is the semantic name of the network interface public IP.</p> <code>ipFamily</code>  Kubernetes core/v1.IPFamily  <p>IPFamily is the IP family of the IP. Has to match IP if specified. If unspecified and IP is specified, will be defaulted by using the IP family of IP. If only IPFamily is specified, a random IP of that family will be allocated if possible.</p> <code>ip</code>  github.com/ironcore-dev/ironcore-net/apimachinery/api/net.IP  <p>IP specifies a specific IP to allocate. If empty, a random ephemeral IP will be allocated.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.NetworkInterfaceSpec","title":"NetworkInterfaceSpec","text":"<p> (Appears on:NetworkInterface) </p> Field Description <code>nodeRef</code>  Kubernetes core/v1.LocalObjectReference  <p>NodeRef is the node the network interface is hosted on.</p> <code>networkRef</code>  Kubernetes core/v1.LocalObjectReference  <p>NetworkRef references the network that the network interface is in.</p> <code>ips</code>  []github.com/ironcore-dev/ironcore-net/apimachinery/api/net.IP  <p>IPs are the internal IPs of the network interface.</p> <code>prefixes</code>  []github.com/ironcore-dev/ironcore-net/apimachinery/api/net.IPPrefix  <p>Prefixes are additional prefixes to route to the network interface.</p> <code>natGateways</code>  []NetworkInterfaceNAT  <p>NATs specify the NAT of the network interface IP family. Can only be set if there is no matching IP family in PublicIPs.</p> <code>publicIPs</code>  []NetworkInterfacePublicIP  (Optional) <p>PublicIPs are the public IPs the network interface should have.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.NetworkInterfaceState","title":"NetworkInterfaceState (<code>string</code> alias)","text":"<p> (Appears on:NetworkInterfaceStatus) </p> Value Description <p>\"Error\"</p> <p>NetworkInterfaceStateError is used for any NetworkInterface that is some error occurred.</p> <p>\"Pending\"</p> <p>NetworkInterfaceStatePending is used for any NetworkInterface that is in an intermediate state.</p> <p>\"Ready\"</p> <p>NetworkInterfaceStateReady is used for any NetworkInterface that is ready.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.NetworkInterfaceStatus","title":"NetworkInterfaceStatus","text":"<p> (Appears on:NetworkInterface) </p> <p>NetworkInterfaceStatus defines the observed state of NetworkInterface.</p> Field Description <code>state</code>  NetworkInterfaceState  <p>State is the state of the network interface.</p> <code>pciAddress</code>  PCIAddress  <p>PCIAddress is the PCI address of the network interface.</p> <code>tapDevice</code>  TAPDevice  <p>TAPDevice is the TAP device of the network interface.</p> <code>prefixes</code>  []github.com/ironcore-dev/ironcore-net/apimachinery/api/net.IPPrefix  <p>Prefixes are the prefixes of the network interface.</p> <code>publicIPs</code>  []github.com/ironcore-dev/ironcore-net/apimachinery/api/net.IP  <p>PublicIPs are the public IPs of the network interface.</p> <code>natIPs</code>  []github.com/ironcore-dev/ironcore-net/apimachinery/api/net.IP  <p>NATIPs are the NAT IPs of the network interface.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.NetworkPeering","title":"NetworkPeering","text":"<p> (Appears on:NetworkSpec) </p> <p>NetworkPeering defines a network peering with another network.</p> Field Description <code>name</code>  string  <p>Name is the semantical name of the network peering.</p> <code>id</code>  string  <p>ID is the ID of the network to peer with.</p> <code>prefixes</code>  []PeeringPrefix  <p>Prefixes is a list of prefixes that we want only to be exposed to the peered network, if no prefixes are specified no filtering will be done.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.NetworkPeeringState","title":"NetworkPeeringState (<code>string</code> alias)","text":"<p> (Appears on:NetworkPeeringStatus) </p> <p>NetworkPeeringState is the state a NetworkPeering can be in</p> Value Description <p>\"Error\"</p> <p>NetworkPeeringStateError signals that the network peering is in error state.</p> <p>\"Pending\"</p> <p>NetworkPeeringStatePending signals that the network peering is not applied.</p> <p>\"Ready\"</p> <p>NetworkPeeringStateReady signals that the network peering is ready.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.NetworkPeeringStatus","title":"NetworkPeeringStatus","text":"<p>NetworkPeeringStatus is the status of a network peering.</p> Field Description <code>id</code>  int32  <p>ID is the ID of network</p> <code>state</code>  NetworkPeeringState  <p>State represents the network peering state</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.NetworkPolicyEgressRule","title":"NetworkPolicyEgressRule","text":"<p> (Appears on:NetworkPolicySpec) </p> <p>NetworkPolicyEgressRule describes a rule to regulate egress traffic with.</p> Field Description <code>ports</code>  []NetworkPolicyPort  <p>Ports specifies the list of destination ports that can be called with this rule. Each item in this list is combined using a logical OR. Empty matches all ports. As soon as a single item is present, only these ports are allowed.</p> <code>to</code>  []NetworkPolicyPeer  <p>To specifies the list of destinations which the selected network interfaces should be able to send traffic to. Fields are combined using a logical OR. Empty matches all destinations. As soon as a single item is present, only these peers are allowed.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.NetworkPolicyIngressRule","title":"NetworkPolicyIngressRule","text":"<p> (Appears on:NetworkPolicySpec) </p> <p>NetworkPolicyIngressRule describes a rule to regulate ingress traffic with.</p> Field Description <code>from</code>  []NetworkPolicyPeer  <p>From specifies the list of sources which should be able to send traffic to the selected network interfaces. Fields are combined using a logical OR. Empty matches all sources. As soon as a single item is present, only these peers are allowed.</p> <code>ports</code>  []NetworkPolicyPort  <p>Ports specifies the list of ports which should be made accessible for this rule. Each item in this list is combined using a logical OR. Empty matches all ports. As soon as a single item is present, only these ports are allowed.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.NetworkPolicyPeer","title":"NetworkPolicyPeer","text":"<p> (Appears on:NetworkPolicyEgressRule, NetworkPolicyIngressRule) </p> <p>NetworkPolicyPeer describes a peer to allow traffic to / from.</p> Field Description <code>objectSelector</code>  ObjectSelector  <p>ObjectSelector selects peers with the given kind matching the label selector. Exclusive with other peer specifiers.</p> <code>ipBlock</code>  IPBlock  <p>IPBlock specifies the ip block from or to which network traffic may come.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.NetworkPolicyPort","title":"NetworkPolicyPort","text":"<p> (Appears on:NetworkPolicyEgressRule, NetworkPolicyIngressRule, Rule) </p> <p>NetworkPolicyPort describes a port to allow traffic on</p> Field Description <code>protocol</code>  Kubernetes core/v1.Protocol  <p>Protocol (TCP, UDP, or SCTP) which traffic must match. If not specified, this field defaults to TCP.</p> <code>port</code>  int32  <p>The port on the given protocol. If this field is not provided, this matches all port names and numbers. If present, only traffic on the specified protocol AND port will be matched.</p> <code>endPort</code>  int32  <p>EndPort indicates that the range of ports from Port to EndPort, inclusive, should be allowed by the policy. This field cannot be defined if the port field is not defined. The endPort must be equal or greater than port.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.NetworkPolicySpec","title":"NetworkPolicySpec","text":"<p> (Appears on:NetworkPolicy) </p> Field Description <code>networkRef</code>  Kubernetes core/v1.LocalObjectReference  <p>NetworkRef is the network to regulate using this policy.</p> <code>networkInterfaceSelector</code>  Kubernetes meta/v1.LabelSelector  <p>NetworkInterfaceSelector selects the network interfaces that are subject to this policy.</p> <code>priority</code>  int32  <p>Priority is an optional field that specifies the order in which the policy is applied. Policies with higher \u201corder\u201d are applied after those with lower order.  If the order is omitted, it may be considered to be \u201cinfinite\u201d - i.e. the policy will be applied last.  Policies with identical order will be applied in alphanumerical order based on the Policy \u201cName\u201d.</p> <code>ingress</code>  []NetworkPolicyIngressRule  <p>Ingress specifies rules for ingress traffic.</p> <code>egress</code>  []NetworkPolicyEgressRule  <p>Egress specifies rules for egress traffic.</p> <code>policyTypes</code>  []PolicyType  <p>PolicyTypes specifies the types of policies this network policy contains.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.NetworkSpec","title":"NetworkSpec","text":"<p> (Appears on:Network) </p> Field Description <code>id</code>  string  <p>ID is the ID of the network.</p> <code>peerings</code>  []NetworkPeering  <p>Peerings are the network peerings with this network</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.NetworkState","title":"NetworkState (<code>string</code> alias)","text":"<p>NetworkState is the state of a network.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.NetworkStatus","title":"NetworkStatus","text":"<p> (Appears on:Network) </p> Field Description <code>peerings</code>  map[string][]./api/core/v1alpha1.NetworkPeeringStatus  <p>Peerings contains the states of the network peerings for the network.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.NodeAffinity","title":"NodeAffinity","text":"<p> (Appears on:Affinity) </p> Field Description <code>requiredDuringSchedulingIgnoredDuringExecution</code>  NodeSelector"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.NodeSelector","title":"NodeSelector","text":"<p> (Appears on:NodeAffinity) </p> <p>NodeSelector represents the union of the results of one or more queries over a set of nodes; that is, it represents the OR of the selectors represented by the node selector terms.</p> Field Description <code>nodeSelectorTerms</code>  []NodeSelectorTerm  <p>Required. A list of node selector terms. The terms are ORed.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.NodeSelectorOperator","title":"NodeSelectorOperator (<code>string</code> alias)","text":"<p> (Appears on:NodeSelectorRequirement) </p> <p>NodeSelectorOperator is the set of operators that can be used in a node selector requirement.</p> Value Description <p>\"DoesNotExist\"</p> <p>\"Exists\"</p> <p>\"Gt\"</p> <p>\"In\"</p> <p>\"Lt\"</p> <p>\"NotIn\"</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.NodeSelectorRequirement","title":"NodeSelectorRequirement","text":"<p> (Appears on:NodeSelectorTerm) </p> <p>NodeSelectorRequirement is a requirement for a selector. It\u2019s a combination of the key to match, the operator to match with, and zero to n values, depending on the operator.</p> Field Description <code>key</code>  string  <p>Key is the key the selector applies to.</p> <code>operator</code>  NodeSelectorOperator  <p>Operator represents the key\u2019s relationship to the values. Valid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.</p> <code>values</code>  []string  <p>Values are the values to relate the key to via the operator.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.NodeSelectorTerm","title":"NodeSelectorTerm","text":"<p> (Appears on:NodeSelector) </p> <p>NodeSelectorTerm matches no objects if it\u2019s empty. The requirements of the selector are ANDed.</p> Field Description <code>matchExpressions</code>  []NodeSelectorRequirement  <p>MatchExpressions matches nodes by the label selector requirements.</p> <code>matchFields</code>  []NodeSelectorRequirement  <p>MatchFields matches the nodes by their fields.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.NodeSpec","title":"NodeSpec","text":"<p> (Appears on:Node) </p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.NodeStatus","title":"NodeStatus","text":"<p> (Appears on:Node) </p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.ObjectIP","title":"ObjectIP","text":"<p> (Appears on:Rule) </p> Field Description <code>ipFamily</code>  Kubernetes core/v1.IPFamily  <p>IPFamily is the IPFamily of the prefix. If unset but Prefix is set, this can be inferred.</p> <code>prefix</code>  github.com/ironcore-dev/ironcore-net/apimachinery/api/net.IPPrefix  <p>Prefix is the prefix of the IP.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.ObjectSelector","title":"ObjectSelector","text":"<p> (Appears on:NetworkPolicyPeer) </p> <p>ObjectSelector specifies how to select objects of a certain kind.</p> Field Description <code>kind</code>  string  <p>Kind is the kind of object to select.</p> <code>LabelSelector</code>  Kubernetes meta/v1.LabelSelector  <p> (Members of <code>LabelSelector</code> are embedded into this type.) </p> <p>LabelSelector is the label selector to select objects of the specified Kind by.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.PCIAddress","title":"PCIAddress","text":"<p> (Appears on:NetworkInterfaceStatus) </p> <p>PCIAddress is a PCI address.</p> Field Description <code>domain</code>  string  <code>bus</code>  string  <code>slot</code>  string  <code>function</code>  string"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.PeeringPrefix","title":"PeeringPrefix","text":"<p> (Appears on:NetworkPeering) </p> <p>PeeringPrefix defines prefixes to be exposed to the peered network</p> Field Description <code>name</code>  string  <p>Name is the semantical name of the peering prefixes</p> <code>prefix</code>  github.com/ironcore-dev/ironcore-net/apimachinery/api/net.IPPrefix  <p>CIDR to be exposed to the peered network</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.PolicyType","title":"PolicyType (<code>string</code> alias)","text":"<p> (Appears on:NetworkPolicySpec) </p> <p>PolicyType is a type of policy.</p> Value Description <p>\"Egress\"</p> <p>PolicyTypeEgress is a policy that describes egress traffic.</p> <p>\"Ingress\"</p> <p>PolicyTypeIngress is a policy that describes ingress traffic.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.Rule","title":"Rule","text":"<p> (Appears on:NetworkPolicyRule) </p> Field Description <code>ipBlock</code>  []IPBlock  <p>CIDRBlock specifies the CIDR block from which network traffic may come or go.</p> <code>ips</code>  []ObjectIP  <p>ObjectIPs are the object IPs the rule applies to.</p> <code>networkPolicyPorts</code>  []NetworkPolicyPort  <p>NetworkPolicyPorts are the protocol type and ports.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.TAPDevice","title":"TAPDevice","text":"<p> (Appears on:NetworkInterfaceStatus) </p> <p>TAPDevice is a TAP device.</p> Field Description <code>name</code>  string  <p>Name is the name of the TAP device.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.TargetNetworkInterface","title":"TargetNetworkInterface","text":"<p> (Appears on:NetworkPolicyRule) </p> <p>TargetNetworkInterface is the target of the network policy.</p> Field Description <code>ip</code>  github.com/ironcore-dev/ironcore-net/apimachinery/api/net.IP  <p>IP is the IP address of the target network interface.</p> <code>targetRef</code>  LocalUIDReference  <p>TargetRef is the target providing the destination.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.TopologySpreadConstraint","title":"TopologySpreadConstraint","text":"<p> (Appears on:InstanceSpec) </p> <p>TopologySpreadConstraint specifies how to spread matching instances among the given topology.</p> Field Description <code>maxSkew</code>  int32  <p>MaxSkew describes the degree to which instances may be unevenly distributed. When <code>whenUnsatisfiable=DoNotSchedule</code>, it is the maximum permitted difference between the number of matching instances in the target topology and the global minimum. The global minimum is the minimum number of matching instances in an eligible domain or zero if the number of eligible domains is less than MinDomains.</p> <code>topologyKey</code>  string  <p>TopologyKey is the key of node labels. Nodes that have a label with this key and identical values are considered to be in the same topology. We consider each  as a \u201cbucket\u201d, and try to put balanced number of instances into each bucket. We define a domain as a particular instance of a topology. Also, we define an eligible domain as a domain whose nodes meet the requirements of nodeAffinityPolicy and nodeTaintsPolicy. <code>whenUnsatisfiable</code>  UnsatisfiableConstraintAction  <p>WhenUnsatisfiable indicates how to deal with a instance if it doesn\u2019t satisfy the spread constraint. - DoNotSchedule (default) tells the scheduler not to schedule it. - ScheduleAnyway tells the scheduler to schedule the instance in any location, but giving higher precedence to topologies that would help reduce the skew.</p> <code>labelSelector</code>  Kubernetes meta/v1.LabelSelector  <p>LabelSelector is used to find matching instances. Instances that match this label selector are counted to determine the number of instances in their corresponding topology domain.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/api-reference/core/#core.apinet.ironcore.dev/v1alpha1.UnsatisfiableConstraintAction","title":"UnsatisfiableConstraintAction (<code>string</code> alias)","text":"<p> (Appears on:TopologySpreadConstraint) </p> Value Description <p>\"DoNotSchedule\"</p> <p>DoNotSchedule instructs the scheduler not to schedule the instance when constraints are not satisfied.</p> <p> Generated with <code>gen-crd-api-reference-docs</code> </p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/concepts/","title":"Concepts","text":"<ul> <li>Objects describes the objects available in   <code>ironcore-net</code>.</li> <li><code>Network</code> lifecycle describes the lifecycle   of a <code>Network</code> object.</li> <li><code>IP</code> lifecycle describes the lifecycle   of an <code>IP</code> object.</li> <li><code>ironcore</code> integration describes how   <code>ironcore-net</code> can be integrated with <code>ironcore</code>.</li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore-net/concepts/ip-lifecycle/","title":"IP lifecycle","text":"<p>An <code>IP</code> is a namespaced handle to a claimed IP address. All namespaced resources wanting an IP have to claim the corresponding <code>IP</code> object in order to use it.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/concepts/ip-lifecycle/#ip-management","title":"IP management","text":"<p>When creating an <code>IP</code>, a vacant IP address has to be allocated. This allocation is done via cluster-scoped <code>IPAddress</code> objects. An <code>IPAddress</code>es name is the IP it represents. As such, detecting whether an <code>IPAddress</code> is taken can be easily done by <code>Get</code>ting the <code>IPAddress</code> with the IP to check and inspecting the result: If the <code>IPAddress</code> is present, it means it's taken. Otherwise, at least during the time of inspection, the <code>IPAddress</code> is vacant and ready to be claimed.</p> <p>The <code>IPAddress</code> and <code>IP</code> are tied together in the <code>IP</code>'s store <code>BeforeCreate</code> hook using the <code>ipaddressallocator</code>.</p> <p>The <code>Allocator</code> tries to create <code>IPAddress</code>es with the <code>claimRef</code> pointing to the <code>IP</code> about to be created. It continues to do so until it either finds a vacant <code>IPAddress</code> (creation succeeds) or it times out after too many attempts fail (<code>AlreadyExists</code> errors).</p> <p>The valid public <code>IPAddress</code> prefixes can be configured using the <code>apiserver</code>s <code>public-prefix</code> flag.</p> <p>When deleting an <code>IP</code>, the corresponding <code>IPAddress</code> is cleaned up alongside the claiming <code>IP</code>.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/concepts/ip-lifecycle/#claiming-the-ip","title":"Claiming the IP","text":"<p>To claim an <code>IP</code>, claimer has to set the <code>spec.claimRef</code> of the <code>IP</code>. Once set, if the claimer wants to release it while it is present, the claimer has to actively delete the <code>spec.claimRef</code>.</p> <p>If a claimer does not exist anymore, the <code>IPGarbageCollector</code> will take care of releasing the <code>IP</code>.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/concepts/ip-lifecycle/#claiming-an-ip-for-apinet-objects","title":"Claiming an IP for <code>apinet</code> objects","text":"<p>For <code>apinet</code> objects (<code>NetworkInterface</code>, <code>NATGateway</code>, <code>LoadBalancer</code>), claiming <code>IP</code>s is simple: When creating the object, there usually are two 'modes' for acquiring an <code>IP</code>: Either only the <code>IPFamily</code> (if applicable) is specified, causing a dynamic <code>IP</code> object to be created and claimed, or the desired <code>IP</code> is specified, causing the <code>IP</code>s in the namespace to be searched for the <code>IP</code> in question and to be claimed if possible.</p> <p>For the <code>apinet</code> objects, this whole process is done directly during <code>Create</code> / <code>Update</code>. There is no eventual reconciliation of the IPs. This also means that if an <code>Update</code> causes an <code>IP</code> not to be used anymore, it will be released.</p> <p>Example network interface claiming a dynamic public IP:</p> <pre><code>apiVersion: core.apinet.ironcore.dev/v1alpha1\nkind: NetworkInterface\nmetadata:\n  namespace: default\n  name: my-public-nic\nspec:\n  networkRef:\n    name: my-network\n  nodeRef:\n    name: my-node\n  ips:\n  - 192.168.178.3\n  publicIPs:\n    - name: public-ip-1\n      ipFamily: IPv4\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ironcore-net/concepts/ironcore-integration/","title":"IronCore integration","text":"<p><code>ironcore-net</code> controls networking over multiple peers and intelligently manages functions. It can be operated and used independently of <code>ironcore</code>. The binding to <code>ironcore</code> is only realized via <code>apinetlet</code>.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/concepts/ironcore-integration/#mapped-objects-interaction","title":"Mapped objects / interaction","text":"<p>The <code>apinetlet</code> is a controller that has access to an <code>ironcore</code> enabled cluster and an <code>ironcore-net</code> enabled cluster. It maps objects of <code>ironcore</code>'s <code>networking</code> group to corresponding entities in <code>ironcore-net</code>, if possible.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/concepts/ironcore-integration/#network","title":"Network","text":"<p>When a <code>networking.ironcore.dev/Network</code> is created, a corresponding <code>core.apinet.ironcore.dev/Network</code> is created in the <code>apinet</code> cluster. The name of the <code>Network</code> in the <code>apinet</code> cluster is the <code>uid</code> of the <code>Network</code> in the <code>ironcore</code> cluster.</p> <p>Once created and with an allocated <code>ID</code>, the <code>ironcore</code> <code>Network</code> will be patched with the corresponding provider ID of the <code>apinet</code> <code>Network</code> and set to <code>state: Available</code>. The provider ID format &amp; parsing can be found in <code>provider.go</code>.</p> <p>If <code>ironcore</code> <code>Network</code> has peerings, then they will be translated and  patched into <code>apinet</code> <code>Network</code>. More details can be found here  <code>Network Peering</code></p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/concepts/ironcore-integration/#loadbalancer","title":"LoadBalancer","text":"<p>For a <code>networking.ironcore.dev/LoadBalancer</code> a corresponding <code>core.apinet.ironcore.dev/LoadBalancer</code> is created, also having the <code>uid</code> of the source object as its name.</p> <p>The <code>apinet</code> <code>LoadBalancer</code> is configured to have an IP per IP family if it's a <code>Public</code> load balancer. Otherwise, it simply uses the IPs specified via the <code>ironcore</code> <code>LoadBalancer</code>.</p> <p>For the routing targets, the <code>ironcore</code> <code>LoadBalancerRouting</code> is inspected and transformed into an <code>apinet</code> <code>LoadBalancerRouting</code>.</p> <p>For its instances, the <code>apinet</code> <code>LoadBalancer</code> is created with a <code>template</code> that specifies instance anti-affinity to ensure instances are distributed cross-zone.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/concepts/ironcore-integration/#networkpolicy","title":"NetworkPolicy","text":"<p>For a <code>networking.ironcore.dev/NetworkPolicy</code> a corresponding <code>core.apinet.ironcore.dev/NetworkPolicy</code> is created in the <code>apinet</code> cluster. The name of the <code>NetworkPolicy</code> in the <code>apinet</code> cluster is the <code>uid</code> of the <code>NetworkPolicy</code> in the <code>ironcore</code> cluster. The <code>NetworkPolicy</code> applies to <code>NetworkInterfaces</code> within a specific <code>Network</code>, filtered by the label specified in the <code>NetworkPolicy</code> spec.</p> <p>Based on the <code>PolicyTypes</code> (<code>egress</code> and/or <code>ingress</code>), rules can be specified to limit the traffic on the target object to and from various objects like <code>LoadBalancer</code>, <code>NetworkInterface</code> or <code>IPBlock</code> on certain <code>ports</code>.</p> <p>When a <code>NetworkPolicy</code> is applied, a <code>NetworkPolicyRule</code> object is created with the specified policy rules. <code>Metalnetlet</code> then reads the <code>NetworkPolicyRule</code> and enforces these policy (firewall) rules on the target <code>NetworkInterface</code>s.</p> <p>for example refer to NetworkPolicy object</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/concepts/ironcore-integration/#natgateway","title":"NATGateway","text":"<p>For a <code>networking.ironcore.dev/NATGateway</code> a corresponding <code>core.apinet.ironcore.dev/NATGateway</code> is created, also having the <code>uid</code> of the source object as its name. Additionally, a <code>NATGatewayAutoscaler</code> is created, ensuring there are enough public IPs available.</p> <p>The <code>apinet</code> <code>NATGateway</code> will try to target all <code>NetworkInterface</code>s in its <code>Network</code> that share an <code>IPFamily</code> but don't have a public IP for that family and no other <code>NATGateway</code> claiming it.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/concepts/ironcore-integration/#networkinterface","title":"NetworkInterface","text":"<p>Since the location of an <code>apinet</code> <code>NetworkInterface</code> depends on an <code>apinet</code> <code>Node</code>, <code>apinetlet</code> can not create a mapping <code>apinet</code> <code>NetworkInterface</code> for an <code>ironcore</code> <code>NetworkInterface</code>. Instead, the <code>MachinePool</code> implementing entity is responsible of doing so.</p> <p>The desired flow here is for the <code>MachinePool</code> implementor to create an <code>apinet</code> <code>NetworkInterface</code> for each desired <code>ironcore</code> <code>NetworkInterface</code> a <code>Machine</code> specifies. Then, upon successful creation, the <code>MachinePool</code> implementor has to patch the <code>ironcore</code>'s <code>NetworkInterface</code> <code>spec.providerID</code> to the provider ID of the <code>apinet</code> <code>NetworkInterface</code> (again, see <code>provider.go</code> on how to obtain / format the provider ID correctly).</p> <p>Once the <code>providerID</code> of the <code>ironcore</code> <code>NetworkInterface</code> is set, <code>apinetlet</code> takes care reporting the status of the <code>ironcore</code> <code>NetworkInterface</code> by observing the matching <code>apinet</code> <code>NetworkInterface</code>. <code>apinetlet</code> then also applies requested <code>VirtualIP</code>s and <code>LoadBalancer</code> targets to the <code>apinet</code> <code>NetworkInterface</code>.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/concepts/network-lifecycle/","title":"Network lifecycle","text":""},{"location":"infrastructure-as-a-service/components/ironcore-net/concepts/network-lifecycle/#id-management","title":"ID management","text":"<p>When creating a <code>Network</code>, a vacant network ID has to be allocated. This allocation is done via cluster-scoped <code>NetworkID</code> objects. A <code>NetworkID</code>s name is the ID it represents. As such, detecting whether a <code>NetworkID</code> is taken can be easily done by <code>Get</code>ting the <code>NetworkID</code> with the ID to check and inspecting the result: If the <code>NetworkID</code> is present, it means it's taken. Otherwise, at least during the time of inspection, the <code>NetworkID</code> is vacant and ready to be claimed.</p> <p>The <code>NetworkID</code> and <code>Network</code> are tied together in the <code>Network</code>'s store <code>BeforeCreate</code> hook using the <code>networkidallocator</code>.</p> <p>The <code>Allocator</code> tries to create <code>NetworkID</code>s with the <code>claimRef</code> pointing to the <code>Network</code> about to be created. It continues to do so until it either finds a vacant <code>NetworkID</code> (creation succeeds) or it times out after too many attempts fail (<code>AlreadyExists</code> errors).</p> <p>The valid <code>NetworkID</code> range can be configured using the <code>apiserver</code>s <code>min-vni</code> / <code>max-vni</code> flags.</p> <p>When deleting a <code>Network</code>, the corresponding <code>NetworkID</code> is cleaned up alongside the claiming <code>Network</code>.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/concepts/network-lifecycle/#network-peering","title":"Network Peering","text":"<p>When creating network peering both <code>ironcore</code> <code>Network</code>s has to specify matching,  <code>spec.peerings</code> referencing each other respectively. A <code>ironcore</code> <code>Network</code> can be peered with  multiple <code>network</code>s in any namespcae.</p> <p>The <code>apinetlet</code> <code>NetworkController</code> checks if there are any <code>peeringClaimRefs</code>  present in <code>ironcore</code> <code>Network</code>. If yes then get <code>ironcore-net</code> <code>Network</code>  using <code>UID</code> of <code>peeringClaimRef</code> and add <code>spec.ID</code> of that <code>ironcore-net</code> <code>Network</code>  along with corresponding peering name and peering prefixes into <code>spec.peerings</code>  of current <code>ironcore-net</code> <code>Network</code>.</p> <p>Once <code>ironcore-net</code> <code>Network</code> is updated with <code>spec.peerings</code>, <code>metalnetlet</code> <code>NetworkController</code>  updates <code>metalnet</code> <code>Network</code>'s <code>spec.peeredIDs</code> and <code>spec.peeredPrefixes</code>  from corresponding <code>ironcore-net</code> <code>Network</code> <code>spec.peerings</code></p> <p>The <code>metalnetlet</code> <code>NetworkController</code> also translates <code>status.peerings</code>  in <code>metalnet</code> <code>Network</code> to <code>ironcore-net</code> <code>Network</code>'s <code>status.peerings</code>.</p> <p>Then the <code>apinetlet</code> <code>NetworkController</code> also translates <code>status.peerings</code>  in <code>ironcore-net</code> <code>Network</code> to <code>ironcore</code> <code>Network</code>'s <code>status.peerings</code>.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/concepts/objects/","title":"Objects","text":"<p><code>ironcore-net</code> provides multiple objects to interact with. As <code>ironcore-net</code> is a Kubernetes-API, all objects are written in a declarative fashion, meaning that they represent the desired state and will be reconciled to eventually manifest that state in the real world.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/concepts/objects/#ip","title":"IP","text":"<p>An IP can be used to get a static hold of an IP. Currently, only public IPs can be obtained this way.</p> <p>Upon its creation, a public IP object gets assigned an available IP. When deleting the IP, the corresponding public IP is released again.</p> <p>Example manifest:</p> <pre><code>apiVersion: core.apinet.ironcore.dev/v1alpha1\nkind: IP\nmetadata:\n  namespace: default\n  name: my-public-ip\nspec:\n  type: Public\n  ip: 10.0.0.1 # This is allocated automatically.\n  # claimRef: # claimRef is set as soon as the IP is claimed.\n  #   name: my-nic\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ironcore-net/concepts/objects/#network","title":"Network","text":"<p>To set up a networking infrastructure, the primary object to create is a <code>Network</code>. A <code>Network</code> is an isolated networking domain. Communication within a <code>Network</code> happens on Layer 3 (no ethernet) via the IP protocol. Peers inside a <code>Network</code> can reach each other unless configured otherwise.</p> <p>Example manifest:</p> <pre><code>apiVersion: core.apinet.ironcore.dev/v1alpha1\nkind: Network\nmetadata:\n  namespace: default\n  name: my-network\n# spec:\n#   id: \"301\"\n</code></pre> <p>When creating a <code>Network</code>, its <code>spec.id</code> is automatically allocated.</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/concepts/objects/#networkinterface","title":"NetworkInterface","text":"<p>A <code>NetworkInterface</code> is the 'default' peer inside a <code>Network</code>. To create a <code>NetworkInterface</code>, the target <code>Node</code> and primary internal IPs have to be known in advance. Once created, a <code>NetworkInterface</code> can also dynamically claim and release <code>publicIPs</code> and be target of a <code>NATGateway</code> (via <code>spec.natGateways</code>).</p> <p>There are two ways to use <code>publicIPs</code>: Either the public IP literal is specified upon creation, which causes the namespace of the <code>NetworkInterface</code> to be searched for the corresponding <code>IP</code> object to be claimed. If no literal is specified, a dynamic <code>IP</code> object will be created that will have a controller reference set to the <code>NetworkInterface</code>, causing it to be deleted when the <code>NetworkInterface</code> is deleted.</p> <p>Once picked up by the target <code>Node</code>, the network interface is created and reports its PCI address and state as part of its <code>status</code>.</p> <p>Example manifest:</p> <pre><code>apiVersion: core.apinet.ironcore.dev/v1alpha1\nkind: NetworkInterface\nmetadata:\n  namespace: default\n  name: my-nic\nspec:\n  networkRef:\n    name: my-network\n  nodeRef:\n    name: my-node\n  ips:\n  - 192.168.178.1\n  publicIPs:\n  - name: ip-1\n    ip: 10.0.0.1\nstatus:\n  pciAddress:\n    bus: \"06\"\n    domain: \"0000\"\n    function: \"3\"\n    slot: \"00\"\n  state: Ready\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ironcore-net/concepts/objects/#instance","title":"Instance","text":"<p>An <code>Instance</code> allows deploying dynamic network functions onto <code>Node</code>s inside the cluster. Currently, only <code>Instance</code>s of <code>type: LoadBalancer</code> are available.</p> <p>To create a load balancer <code>Instance</code>, the load balancer type, the IPs and the network has to be specified.</p> <p>If the <code>nodeRef</code> field is empty, the <code>scheduler</code> automatically determines a suitable <code>Node</code> for the <code>Instance</code> to run on. Scheduling of <code>Instance</code>s can be influenced by using <code>spec.affinity</code>, allowing for node-affinity and instance anti-affinity. This is especially useful while deploying loadbalancer instances, when there should only be a single instance per topology domain.</p> <p>Example manifest:</p> <pre><code>apiVersion: core.apinet.ironcore.dev/v1alpha1\nkind: Instance\nmetadata:\n  namespace: default\n  name: my-instance\nspec:\n  type: LoadBalancer\n  loadBalancerType: Public\n  networkRef:\n    name: my-network\n  ips:\n  - 10.0.0.2\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ironcore-net/concepts/objects/#loadbalancer","title":"LoadBalancer","text":"<p>A <code>LoadBalancer</code> manages its <code>Instance</code>s and declares its routing by its corresponding <code>LoadBalancerRouting</code>. Under the hood, a <code>LoadBalancer</code> creates a <code>DaemonSet</code> managing its <code>Instance</code>s. Currently, <code>Instance</code>s can contain multiple IPs, but the desired architecture is to have an <code>Instance</code> containing only a single IP. This will eventually make the management of multiple <code>DaemonSet</code>s per <code>LoadBalancer</code> a requirement.</p> <p>For now, everytime the IPs of a <code>LoadBalancer</code> are updated, all its <code>Instance</code>s are updated (done by the <code>DaemonSet</code> controller).</p> <p>Example manifest:</p> <pre><code>apiVersion: core.apinet.ironcore.dev/v1alpha1\nkind: LoadBalancer\nmetadata:\n  namespace: default\n  name: my-instance\nspec:\n  type: Public\n  networkRef:\n    name: my-network\n  ips:\n  - name: ip-1\n    ip: 10.0.0.2\n  template: {}\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ironcore-net/concepts/objects/#networkpolicy","title":"NetworkPolicy","text":"<p>A <code>NetworkPolicy</code> limits traffic to and from various objects like <code>NetworkInterfaces</code>, <code>LoadBalancers</code> etc. for the target objects within a specific network. </p> <p>When a <code>NetworkPolicy</code> is applied, a <code>NetworkPolicyRule</code> object is created to contain the policy rules specified in the <code>NetworkPolicy</code>. </p> <p>Then, <code>metalnetlet</code> translates these policy rules from the <code>NetworkPolicyRule</code> object and applies them to the <code>NetworkInterface</code>s.</p> <p>Example manifest <pre><code>apiVersion: core.apinet.ironcore.dev/v1alpha1\nkind: NetworkPolicy\nmetadata:\n  namespace: default\n  name: my-networkpolicy\nspec:\n  networkRef:\n    name: my-network\n  networkInterfaceSelector:\n    matchLabels:\n      app: db\n  policyTypes:\n  - Ingress\n  - Egress\n  ingress:\n  - from:\n    - ipBlock:\n        cidr: 172.17.0.0/16\n    - objectSelector:\n        kind: NetworkInterface\n        matchLabels:\n    - objectSelector:\n        kind: LoadBalancer\n        matchLabels:\n          app: web\n    ports:\n    - protocol: TCP\n      port: 5432\n  egress:\n  - to:\n    - ipBlock:\n        cidr: 10.0.0.0/24\n    ports:\n    - protocol: TCP\n      port: 8080\n</code></pre></p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/concepts/objects/#natgateway","title":"NATGateway","text":"<p>A <code>NATGateway</code> allows NAT-ing external IPs to multiple target <code>NetworkInterface</code>s inside a network. The NATed IPs are managed using a <code>NATTable</code> the <code>NATGateway</code> controller updates depending on the amount of target <code>NetworkInterface</code>s.</p> <p>A <code>NATGateway</code> always tries to claim all <code>NetworkInterface</code>s inside its network that don't have a public IP of the IP family the <code>NATGateway</code> has. The claim is depicted by the <code>NetworkInterface</code>'s <code>spec.natGateways</code>.</p> <p>Example manifest:</p> <pre><code>apiVersion: core.apinet.ironcore.dev/v1alpha1\nkind: NATGateway\nmetadata:\n  namespace: default\n  name: my-nat-gateway\nspec:\n  networkRef:\n    name: my-network\n  ipFamily: IPv4\n  ips:\n  - name: ip-1\n    ip: 10.0.0.3\n  portsPerNetworkInterface: 1024\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ironcore-net/development/setup/","title":"Local Development Setup","text":""},{"location":"infrastructure-as-a-service/components/ironcore-net/development/setup/#requirements","title":"Requirements","text":"<ul> <li><code>go</code> &gt;= 1.20</li> <li><code>git</code>, <code>make</code> and <code>kubectl</code></li> <li>Kustomize</li> <li>Access to a Kubernetes cluster (Minikube, kind or a   real cluster)</li> </ul>"},{"location":"infrastructure-as-a-service/components/ironcore-net/development/setup/#clone-the-repository","title":"Clone the Repository","text":"<p>To bring up and start locally the <code>ironcore-net</code> project for development purposes clone the repository.</p> <pre><code>git clone git@github.com:ironcore-dev/ironcore-net.git\ncd ironcore-net\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ironcore-net/development/setup/#install-cert-manager","title":"Install cert-manager","text":"<p>If there is no cert-manager present in the cluster it needs to be installed.</p> <pre><code>kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.14.2/cert-manager.yaml\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ironcore-net/development/setup/#setup-ironcore","title":"Setup <code>ironcore</code>","text":"<p>Reference: ironcore docs</p>"},{"location":"infrastructure-as-a-service/components/ironcore-net/development/setup/#setup-ironcore-net-with-kind-cluster","title":"Setup <code>ironcore-net</code> with <code>kind</code> cluster","text":"<p>For local development with <code>kind</code>, a make target that builds and loads the apiserver/controller images and then applies the manifests is available via</p> <ol> <li>Build and apply ironcore-net apiserver and controller manager to the cluster</li> </ol> <pre><code>make kind-deploy\n</code></pre> <ol> <li>Build and apply apinetlet to the cluster</li> </ol> <pre><code>make kind-build-load-restart-apinetlet\nmake kind-apply-apinetlet\n</code></pre> <ol> <li>Build and apply metalnetlet to the cluster</li> </ol> <pre><code>make kind-build-load-restart-metalnetlet\nmake kind-apply-metalnetlet\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ironcore-net/development/setup/#cleanup-from-kind-cluster","title":"Cleanup from <code>kind</code> cluster","text":"<pre><code>make kind-delete\nmake kind-delete-apinetlet\nmake kind-delete-metalnetlet\n</code></pre>"},{"location":"infrastructure-as-a-service/components/libvirt-provider/","title":"Libvirt Provider","text":"<p>The <code>libvirt-provider</code> project is a Libvirt based provider implementation of the ironcore types</p> <pre><code>graph TD\n    libvirt-provider -. implements .-&gt; compute.ironcore.dev</code></pre> <p>Namely <code>libvirt-provider</code> implements the <code>Machine</code> type. Additionally, it announces the available <code>MachineClasses</code> which are supported by the <code>MachinePool</code> based on configured criteria.</p> <p>Further information about the architecture and concepts of the <code>libvirt-provider</code> project can be found in the architecture section.</p>"},{"location":"infrastructure-as-a-service/components/libvirt-provider/architecture/","title":"Architecture","text":"<p>This section covers the core concepts of the <code>libvirt-provider</code> project.</p> <p>The <code>libvirt-provider</code> is an implementor of the <code>ironcore runtime interface</code> (<code>IRI</code>) for <code>Machines</code>, it implements the MachineRuntime</p> <p>A <code>libvirt-provider</code> is usually deployed along with a poollet. A poollet resolves dependencies, e.g. a secrets, and calls with the consolidated resource the <code>libvirt-provider</code>.  The <code>libvirt-provider</code> persists the required state and reconciles the resource in an asynchronous manner. </p> <p>The <code>libvirt-provider</code> interacts directly with a defined <code>libvirt</code> instance on the host.  A <code>Machine</code> is provisioned by creating a <code>domain xml</code>. If needed, images are downloaded, NICs are configured and volumes are attached.</p> <p>The following diagram visualizes the interplay of the different components:  <pre><code>graph TD\n    C([libvirt-provider])\n    P([machinepoollet])\n\n    P -- announces --&gt; VP[MachinePool]\n    P -- watches --&gt; V[Machines]\n\n    P -- uses IRI --&gt; C\n\n    C -- creates --&gt; I[Libvirt Domain XML]\n    C -- defines --&gt; VC[Supported MachineClasses]</code></pre></p>"},{"location":"infrastructure-as-a-service/components/libvirt-provider/usage/","title":"Libvirt-provider - usage documentation","text":""},{"location":"infrastructure-as-a-service/components/libvirt-provider/usage/#overview","title":"Overview","text":"<p><code>libvirt-provider</code> enables interaction with <code>libvirt</code> for managing virtual machine instances, integrating with multiple plugins for networking, storage, and more. It provides a flexible architecture to handle resources like VMs, volumes, and networking interfaces, with built-in support for garbage collection, volume size resyncing, and health monitoring. This guide provides a comprehensive usage flow, including configuration, flags, and practical examples, to get your <code>libvirt-provider</code> instance running.</p>"},{"location":"infrastructure-as-a-service/components/libvirt-provider/usage/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, make sure you have the prerequisites described here.</p>"},{"location":"infrastructure-as-a-service/components/libvirt-provider/usage/#building-from-source","title":"Building from source","text":"<p>To build <code>libvirt-provider</code> from the source:</p> <ol> <li> <p>Clone the repository</p> <p>To bring up and start locally the libvirt-provider project, you first need to clone the repository.</p> <pre><code>git clone git@github.com:ironcore-dev/libvirt-provider.git\ncd libvirt-provider\n</code></pre> </li> <li> <p>Build the <code>libvirt-provider</code></p> <pre><code>make build\n</code></pre> </li> </ol>"},{"location":"infrastructure-as-a-service/components/libvirt-provider/usage/#configuration","title":"Configuration","text":"<p><code>libvirt-provider</code> is configured via command-line flags. To see the full list of configuration options, run:</p> <pre><code>libvirt-provider -h\n</code></pre>"},{"location":"infrastructure-as-a-service/components/libvirt-provider/usage/#required-flags","title":"Required flags","text":"<p>The following flags are required for the application to run properly:</p> <p><code>--supported-machine-classes</code> (Path to the supported machine classes file). Sample <code>machine-classes.json</code> can be found here.</p>"},{"location":"infrastructure-as-a-service/components/libvirt-provider/usage/#running-libvirt-provider","title":"Running libvirt-provider","text":"<p>Below is an example of configuring and running <code>libvirt-provider</code> with various flags:</p> <pre><code>go run cmd/libvirt-provider/main.go \\\n  --address /var/run/iri-machinebroker.sock \\\n  --streaming-address \":20251\" \\\n  --base-url \"http://localhost:20251\" \\\n  --libvirt-socket /var/run/libvirt/libvirt-sock \\\n  --libvirt-address \"unix:///var/run/libvirt/libvirt-sock\" \\\n  --libvirt-uri \"qemu:///system\" \\\n  --enable-hugepages \\\n  --qcow2-type \"qcow2\" \\\n  --volume-cache-policy \"writeback\" \\\n  --servers-metrics-address \":9090\" \\\n  --servers-health-check-address \":8080\" \\\n  --gc-vm-graceful-shutdown-timeout 5m \\\n  --gc-resync-interval 1m \\\n  --supported-machine-classes \"/home/libvirt-provider/machine-classes.json\"\n</code></pre> <p>Once the libvirt-provider is started, which will handle various tasks like connecting to libvirt, managing VMs, and exposing various HTTP and gRPC endpoints for metrics, health checks, and more.</p>"},{"location":"infrastructure-as-a-service/components/libvirt-provider/usage/#server-endpoints","title":"Server endpoints","text":"<ol> <li> <p>gRPC endpoint: Exposes various gRPC services to manage virtual machines. Default address: <code>unix:///var/run/iri-machinebroker.sock</code></p> </li> <li> <p>Metrics server: Provides Prometheus-compatible metrics for monitoring. Default address: <code>\"\"</code> (if configured)</p> </li> <li> <p>Health check server: Provides a simple liveness check endpoint. Default address: <code>:8181</code> (if configured)</p> </li> <li> <p>Streaming server: Streams VM status and events. Default address: <code>:20251</code> (if configured)</p> </li> </ol> <p>You can access these services by connecting to their respective addresses.</p>"},{"location":"infrastructure-as-a-service/components/libvirt-provider/usage/#logs-and-debugging","title":"Logs and debugging","text":"<p>The service logs are critical for troubleshooting issues. By default, the service uses the <code>zap</code> logging framework, which supports structured logging and multiple log levels.</p> <p>To change the logging level:</p> <pre><code>go run cmd/libvirt-provider/main.go --zap-log-level debug\n</code></pre> <p>For more advanced troubleshooting, you can enable additional logging at different points in the execution flow.</p>"},{"location":"infrastructure-as-a-service/components/libvirt-provider/usage/#troubleshooting","title":"Troubleshooting","text":"<p>Here are some common issues you might encounter:</p>"},{"location":"infrastructure-as-a-service/components/libvirt-provider/usage/#libvirt-connection-errors","title":"Libvirt connection errors","text":"<p>If the <code>libvirt</code> socket or URI is incorrectly configured, the service will fail to connect to the hypervisor. Ensure that:</p> <ol> <li> <p>The <code>libvirt</code> socket path is correct.</p> </li> <li> <p>The <code>libvirt</code> URI is accessible (e.g., <code>qemu:///system</code> or <code>unix:///var/run/libvirt/libvirt-sock</code>).</p> </li> </ol>"},{"location":"infrastructure-as-a-service/components/libvirt-provider/usage/#vm-launch-failures","title":"VM launch failures","text":"<p>If VMs fail to launch, check the logs for specific errors related to machine classes or network plugins. You may need to adjust the supported machine classes or verify your network plugin configuration.</p>"},{"location":"infrastructure-as-a-service/components/libvirt-provider/concepts/console/","title":"Console","text":""},{"location":"infrastructure-as-a-service/components/libvirt-provider/concepts/events/","title":"Machine Events","text":""},{"location":"infrastructure-as-a-service/components/libvirt-provider/concepts/plugins/nic/","title":"Networkinterface Plugins","text":""},{"location":"infrastructure-as-a-service/components/libvirt-provider/concepts/plugins/volume/","title":"Volume Plugins","text":""},{"location":"infrastructure-as-a-service/components/libvirt-provider/development/dev_docs/","title":"libvirt-provider documentation","text":""},{"location":"infrastructure-as-a-service/components/libvirt-provider/development/dev_docs/#local-dev-setup","title":"Local dev setup","text":"<p>You can run the documentation via:</p> <pre><code>make start-docs\n</code></pre> <p>You can remove the <code>mkdocs</code> container image by running:</p> <pre><code>make clean-docs\n</code></pre>"},{"location":"infrastructure-as-a-service/components/libvirt-provider/development/dev_setup/","title":"Local Development Setup","text":"<ul> <li>Prerequisites</li> <li>Preperation</li> <li>Run libvirt-provider for local development</li> <li>Interact with the <code>libvirt-provider</code></li> <li>Deploy <code>libvirt-provider</code></li> </ul> <p>\u2139\ufe0f NOTE: To be able to take exec console of the machine, you can follow any one of the below approaches: - Run the <code>libvirt-provider</code> as the <code>libvirt-qemu</code> user. - Add user to <code>tty</code> group and create an entry with <code>devpts /dev/pts devpts rw,nosuid,noexec,relatime,gid=5,mode=0660 0 0</code> in <code>/etc/fstab</code>. - Manually ensure that you have <code>0660</code> access permissions on the character files created in <code>/dev/pts</code>.</p>"},{"location":"infrastructure-as-a-service/components/libvirt-provider/development/dev_setup/#prerequisites","title":"Prerequisites","text":"<ul> <li>Linux (code contains OS specific code)</li> <li>go &gt;= 1.20</li> <li><code>git</code>, <code>make</code> and <code>kubectl</code></li> <li>Access to a Kubernetes cluster (Minikube, kind or a   real cluster)</li> <li>libvirt</li> <li>QEMU</li> <li><code>irictl-machine</code> should be running locally or as container</li> </ul>"},{"location":"infrastructure-as-a-service/components/libvirt-provider/development/dev_setup/#preperation","title":"Preperation","text":""},{"location":"infrastructure-as-a-service/components/libvirt-provider/development/dev_setup/#setup-irictl-machine","title":"Setup <code>irictl-machine</code>","text":"<ol> <li> <p>Clone ironcore repository</p> <pre><code>git clone git@github.com:ironcore-dev/ironcore.git\ncd ironcore\n</code></pre> </li> <li> <p>Build <code>irictl-machine</code></p> <pre><code>go build -o bin/irictl-machine ./irictl-machine/cmd/irictl-machine/main.go\n</code></pre> </li> </ol>"},{"location":"infrastructure-as-a-service/components/libvirt-provider/development/dev_setup/#run-libvirt-provider-for-local-development","title":"Run libvirt-provider for local development","text":"<ol> <li> <p>Clone the Repository</p> <p>To bring up and start locally the libvirt-provider project for development purposes you first need to clone the repository.</p> <pre><code>git clone git@github.com:ironcore-dev/libvirt-provider.git\ncd libvirt-provider\n</code></pre> </li> <li> <p>Build the <code>libvirt-provider</code></p> <pre><code>make build\n</code></pre> </li> <li> <p>Run the <code>libvirt-provider</code></p> <p>The required libvirt-provider flags needs to be defined:</p> <pre><code>go run provider/cmd/main.go \\\n  --libvirt-provider-dir=&lt;path-to-initialize-libvirt-provider&gt; \\\n  --supported-machine-classes=&lt;path-to-machine-class-json&gt;/machine-classes.json \\\n  --network-interface-plugin-name=isolated \\\n  --address=&lt;local-path&gt;/iri-machinebroker.sock\n</code></pre> <p>Sample <code>machine-classes.json</code> can be found here.</p> </li> </ol>"},{"location":"infrastructure-as-a-service/components/libvirt-provider/development/dev_setup/#interact-with-the-libvirt-provider","title":"Interact with the <code>libvirt-provider</code>","text":"<ol> <li> <p>Creating machine</p> <pre><code>irictl-machine --address=unix:&lt;local-path-to-socket&gt;/iri-machinebroker.sock create machine -f &lt;path-to-machine-yaml&gt;/iri-machine.yaml\n</code></pre> <p>Sample <code>iri-machine.yaml</code>:</p> <pre><code>metadata:\n  id: 91076287116041d00fd421f43c3760389041dac4a8bd9201afba9a5baeb21c7\n  labels:\n    downward-api.machinepoollet.api.onmetal.de/root-machine-name: machine-hd4\n    downward-api.machinepoollet.api.onmetal.de/root-machine-namespace: default\n    downward-api.machinepoollet.api.onmetal.de/root-machine-uid: cab82eac-09d8-4428-9e6c-c98b40027b74\n    machinepoollet.api.onmetal.de/machine-name: machine-hd4\n    machinepoollet.api.onmetal.de/machine-namespace: default\n    machinepoollet.api.onmetal.de/machine-uid: cab82eac-09d8-4428-9e6c-c98b40027b74\nspec:\n  class: x3-small\n  image:\n    image: ghcr.io/ironcore-dev/ironcore-image/gardenlinux:rootfs-dev-20231206-v1\n  volumes:\n  - empty_disk:\n      size_bytes: 5368709120\n    name: ephe-disk\n    device: oda\n</code></pre> </li> <li> <p>Listing machines</p> <pre><code>irictl-machine --address=unix:&lt;local-path-to-socket&gt;/iri-machinebroker.sock get machine\n</code></pre> </li> <li> <p>Deleting machine</p> <pre><code>irictl-machine --address=unix:&lt;local-path-to-socket&gt;/iri-machinebroker.sock delete machine &lt;machine UUID&gt;\n</code></pre> </li> <li> <p>Taking machine console</p> <pre><code>irictl-machine --address=unix:&lt;local-path-to-socket&gt;/iri-machinebroker.sock exec &lt;machine UUID&gt;\n</code></pre> </li> </ol>"},{"location":"infrastructure-as-a-service/components/libvirt-provider/development/dev_setup/#deploy-libvirt-provider","title":"Deploy <code>libvirt-provider</code>","text":"<p>\u2139\ufe0f NOTE: If the <code>libvirt-uri</code> can not be auto-detected it can be defined via flag: e.g. <code>--libvirt-uri=qemu:///session</code> \u2139\ufe0f NOTE: For trying out the controller use the <code>isolated</code> network interface plugin: <code>--network-interface-plugin-name=isolated</code> \u2139\ufe0f NOTE: Libvirt-provider can run directly as binary program on worker node</p> <ol> <li> <p>Make docker images</p> <pre><code>make docker-build\n</code></pre> </li> <li> <p>Deploy virtlet as kubernetes</p> <pre><code>make deploy\n</code></pre> </li> </ol>"},{"location":"infrastructure-as-a-service/components/ceph-provider/","title":"Ceph Provider","text":"<p>The <code>ceph-provider</code> project is a Ceph based provider implementation of the ironcore types</p> <pre><code>graph TD\n    ceph-provider -. implements .-&gt; storage.ironcore.dev</code></pre> <p>Namely <code>ceph-provider</code> implements the <code>Volume</code>  and <code>VolumePool</code> types.  Additionally, it announces the available <code>VolumeClasses</code> which are supported by the <code>VolumePool</code> based on configured criteria.</p> <p>Further information about the architecture and concepts of the <code>ceph-provider</code> project can be found in the  architecture section.</p>"},{"location":"infrastructure-as-a-service/components/ceph-provider/architecture/","title":"Architecture","text":"<p>This section covers the core concepts of the <code>ceph-provider</code> project.</p> <p>The <code>ceph-provider</code> is an implementor of the <code>ironcore runtime interface</code> (<code>IRI</code>) for <code>Volumes</code> and <code>Buckets</code>. It consists of the <code>ceph-volume-provider</code> and <code>ceph-bucket-provider</code> in order to implement the VolumeRuntime respectively the BucketRuntime.</p> <p>A <code>ceph-provider</code> is usually deployed along with a poollet. A poollet resolves dependencies, e.g. an encryption secret, and calls with the consolidated resource the <code>ceph-provider</code>.  The <code>ceph-provider</code> persists the required state and reconciles the resource in an asynchronous manner. </p>"},{"location":"infrastructure-as-a-service/components/ceph-provider/architecture/#ceph-volume-provider","title":"ceph-volume-provider","text":"<p>The <code>ceph-volume-provider</code> interacts directly with a defined <code>ceph cluster</code>.  A <code>Volume</code> is provisioned by creating a <code>ceph image</code>. If needed, an image is created with a pre-defined <code>os image</code>.</p> <p>The following diagram visualizes the interplay of the different components:  <pre><code>graph TD\n    C([ceph-volume-provider])\n    P([volumepoollet])\n\n    P -- announces --&gt; VP[VolumePool]\n    P -- watches --&gt; V[Volumes]\n\n    P -- uses IRI --&gt; C\n\n    C -- creates --&gt; I[Ceph Image]\n    C -- defines --&gt; VC[Supported VolumeClasses]</code></pre></p>"},{"location":"infrastructure-as-a-service/components/ceph-provider/architecture/#ceph-bucket-provider","title":"ceph-bucket-provider","text":"<p>The <code>ceph-bucket-provider</code> utilizes <code>rook</code> CRD's to back the ironcore <code>Bucket</code> resource. Rook ensures that a <code>ObjectBucketClaim</code> (and an access secret) is being reconciled. </p> <p>The following diagram visualizes the interplay of the different components: <pre><code>graph TD\n    C([ceph-bucket-provider])\n    P([bucketpoollet])\n    R([rook])\n\n    P -- announces --&gt; BP[BucketPool]\n    P -- watches --&gt; B[Buckets]\n\n    P -- uses IRI --&gt; C\n\n    C -- defines --&gt; VC[Supported BucketClasses]\n    C -- creates --&gt; OBC[ObjectBucketClaim]\n    R -- reconciles --&gt; OBC</code></pre></p>"},{"location":"infrastructure-as-a-service/components/ceph-provider/development/setup/","title":"Local Development Setup","text":""},{"location":"infrastructure-as-a-service/components/ceph-provider/development/setup/#prerequisites","title":"Prerequisites","text":"<ul> <li>go &gt;= 1.19</li> <li><code>git</code>, <code>make</code> and <code>kubectl</code></li> <li>Kustomize</li> <li>Minikube or a real cluster</li> </ul>"},{"location":"infrastructure-as-a-service/components/ceph-provider/development/setup/#preperation","title":"Preperation","text":""},{"location":"infrastructure-as-a-service/components/ceph-provider/development/setup/#setup-ceph-cluster","title":"Setup Ceph Cluster","text":"<p>Reference:  rook docs</p>"},{"location":"infrastructure-as-a-service/components/ceph-provider/development/setup/#install-cert-manager","title":"Install cert-manager","text":"<p>If there is no cert-manager present in the cluster it needs to be installed.</p> <pre><code>kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.8.0/cert-manager.yaml\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ceph-provider/development/setup/#setup-ironcore","title":"Setup <code>ironcore</code>","text":"<p>Reference: ironcore docs</p>"},{"location":"infrastructure-as-a-service/components/ceph-provider/development/setup/#setup-rook","title":"Setup <code>Rook</code>","text":"<ol> <li> <p>Install Rook operator and <code>CRD</code>s <pre><code>kubectl apply -k ./rook\n</code></pre></p> </li> <li> <p>Verify the rook-ceph-operator is in the Running state before proceeding  <pre><code>kubectl -n rook-ceph get pod\n</code></pre></p> </li> <li> <p>Create a Rook Ceph Cluster see: Rook Docs</p> </li> <li> <p>Verify cluster installation. List all rook pods again:  <pre><code>kubectl -n rook-ceph get pod\n</code></pre> In the end you should see all pods <code>Running</code> or <code>Completed</code> and have at least one <code>rook-ceph-osd-*</code> Pod: <pre><code>NAME                                            READY   STATUS      RESTARTS   AGE\ncsi-cephfsplugin-b7ktv                          3/3     Running     0          63d\ncsi-cephfsplugin-provisioner-59499cbcdd-wvnfq   6/6     Running     0          63d\ncsi-rbdplugin-bs4tn                             3/3     Running     6          63d\ncsi-rbdplugin-provisioner-857d65496c-mxjp4      6/6     Running     0          63d\nrook-ceph-mgr-a-769964c967-9kmxq                1/1     Running     0          26d\nrook-ceph-mon-a-66b5cfc47f-8d4ts                1/1     Running     0          63d\nrook-ceph-operator-75c6d6bbfc-b9q9n             1/1     Running     0          63d\nrook-ceph-osd-0-7464fbbd49-szdrp                1/1     Running     0          63d\nrook-ceph-osd-prepare-minikube-7t4mk            0/1     Completed   0          6d8h\n</code></pre></p> </li> <li> <p>Deploy a <code>CephCluster</code> <pre><code>kubectl apply -f ./rook/cluster.yaml\n</code></pre> Ensure that the cluster is in <code>Ready</code> phase</p> </li> </ol> <pre><code>kubectl get cephcluster -A\n</code></pre> <ol> <li>Deploy a <code>CephBlockPool</code>, <code>CephObjectStore</code> &amp; <code>StorageClass</code> <pre><code>kubectl apply -f ./rook/pool.yaml\n</code></pre></li> </ol>"},{"location":"infrastructure-as-a-service/components/ceph-provider/development/setup/#clone-the-repository","title":"Clone the Repository","text":"<p>To bring up and start locally the <code>ceph-provider</code> project for development purposes you first need to clone the repository.</p> <pre><code>git clone git@github.com:ironcore-dev/ceph-provider.git\ncd ceph-provider\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ceph-provider/development/setup/#build-the-ceph-provider","title":"Build the <code>ceph-provider</code>","text":"<ol> <li> <p>Build the <code>ceph-volume-provider</code> <pre><code>make build-volume\n</code></pre></p> </li> <li> <p>Build the <code>ceph-bucket-provider</code> <pre><code>make build-bucket\n</code></pre></p> </li> </ol>"},{"location":"infrastructure-as-a-service/components/ceph-provider/development/setup/#run-the-ceph-volume-provider","title":"Run the <code>ceph-volume-provider</code>","text":"<p>The required <code>ceph-provider</code> flags needs to be defined in order to connect to ceph. </p> <p>The following command starts a <code>ceph-volume-provider</code> and connects to a local <code>ceph</code> cluster. <pre><code>go run ./cmd/volumeprovider/main.go \\\n    --address=./iri-volume.sock\n    --supported-volume-classes=./classes.json\n    --zap-log-level=2\n    --ceph-key-file=./key\n    --ceph-monitors=192.168.64.23:6789\n    --ceph-user=admin\n    --ceph-pool=ceph-provider-pool\n    --ceph-client=client.ceph-provider-pool\n</code></pre></p> <p>Sample <code>supported-volume-classes.json</code> file:  <pre><code>[\n  {\n    \"name\": \"experimental\",\n    \"capabilities\": {\n      \"tps\": 262144000,\n      \"iops\": 15000\n    }\n  }\n]\n</code></pre></p> <p>The <code>ceph key</code> can be retrieved from the keyring by decoding (base64) the keyring and using only the <code>key</code>.  <pre><code>kubectl get secrets -n rook-ceph rook-ceph-admin-keyring -o yaml\n</code></pre></p>"},{"location":"infrastructure-as-a-service/components/ceph-provider/development/setup/#run-the-ceph-bucket-provider","title":"Run the <code>ceph-bucket-provider</code>","text":"<p>The required <code>ceph-provider</code> flags needs to be defined in order to work with rook.</p> <p>The following command starts a <code>ceph-bucket-provider</code>.  The flag <code>bucket-pool-storage-class-name</code> defines the <code>StorageClass</code> and hereby implicit the <code>CephBlockPool</code> (see rook docs).  <pre><code>go run ./cmd/bucketprovider/main.go \\\n    --address=./iri-bucket.sock\n    --bucket-pool-storage-class-name=rook-ceph-bucket\n</code></pre></p>"},{"location":"infrastructure-as-a-service/components/ceph-provider/development/setup/#interact-with-the-ceph-provider","title":"Interact with the  <code>ceph-provider</code>","text":""},{"location":"infrastructure-as-a-service/components/ceph-provider/development/setup/#prerequisites_1","title":"Prerequisites","text":"<ul> <li>irictl-volume<ul> <li>locally running or</li> <li>https://github.com/ironcore-dev/ironcore/pkgs/container/ironcore-irictl-volume</li> </ul> </li> <li>irictl-bucket<ul> <li>locally running or</li> <li>https://github.com/ironcore-dev/ironcore/pkgs/container/ironcore-irictl-bucket</li> </ul> </li> </ul>"},{"location":"infrastructure-as-a-service/components/ceph-provider/development/setup/#listing-supported-volumeclass","title":"Listing supported <code>VolumeClass</code>","text":"<pre><code>irictl-volume --address=unix:./iri-volume.sock get volumeclass\nName           TPS         IOPS\nexperimental   262144000   15000\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ceph-provider/development/setup/#listing-supported-volumeclass_1","title":"Listing supported <code>VolumeClass</code>","text":"<pre><code>irictl-volume --address=unix:./iri-volume.sock get volumeclass\nName           TPS         IOPS\nexperimental   262144000   15000\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ceph-provider/development/setup/#creating-a-volume","title":"Creating a  <code>Volume</code>","text":"<pre><code>irictl-volume --address=unix:./iri-volume.sock create volume -f ./volume.json\n\nCreated volume 796264618065bb31024ec509d4ed8a87ed098ee8e89b370c06b0522ba4bf1e2\n</code></pre> <p>Sample volume.json <pre><code>{\n  \"metadata\": {\n    \"labels\": {\n      \"test.api.ironcore.dev/volume-name\": \"test\"\n    }\n  },\n  \"spec\": {\n    \"class\":  \"experimental\",\n    \"resources\":  {\n      \"storage_bytes\": 10070703360\n    }\n  }\n}\n</code></pre></p>"},{"location":"infrastructure-as-a-service/components/ceph-provider/development/setup/#listing-volumes","title":"Listing <code>Volume</code>s","text":"<pre><code>irictl-volume --address=unix:./iri-volume.sock get  volume\nID                                                                Class          Image   State              Age\n796264618065bb31024ec509d4ed8a87ed098ee8e89b370c06b0522ba4bf1e2   experimental           VOLUME_AVAILABLE   2s\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ceph-provider/development/setup/#deleting-a-volumes","title":"Deleting a <code>Volume</code>s","text":"<pre><code>irictl-volume --address=unix:./iri-volume.sock delete  volume 796264618065bb31024ec509d4ed8a87ed098ee8e89b370c06b0522ba4bf1e2\nVolume 796264618065bb31024ec509d4ed8a87ed098ee8e89b370c06b0522ba4bf1e2 deleted\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ceph-provider/usage/","title":"Usage Guides","text":"<p>This section provides an overview on how <code>Volume</code>s from the ironcore project can be provisioned using the <code>ceph-provider</code> provider. The samples are equivalent for <code>Bucket</code>s. </p>"},{"location":"infrastructure-as-a-service/components/ceph-provider/usage/#available-pools-and-classes","title":"Available Pools and Classes","text":"<p>As a user you can request storage by creating a <code>Volume</code>. It will be allocated in the referenced <code>VolumePool</code>.  The <code>VolumeClasses</code> define the capabilities in terms of IOPS, BPS limits and other resource requirements. </p> <p>Get the available <code>VolumePools</code> with the corresponding <code>VolumeClasses</code></p> <pre><code>kubectl get volumeclasses \nNAME   AGE\nfast   4d18h\nslow   4d18h\n\nkubectl get volumepool\nNAME   VOLUMECLASSES   AGE\nceph   fast,slow       4d17h\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ceph-provider/usage/#creating-a-volume","title":"Creating a <code>Volume</code>","text":"<p>A <code>Volume</code> is referencing a <code>VolumePool</code> and a matching <code>VolumeClass</code> which the <code>VolumePool</code> supports.</p> <pre><code># sample-volume.yaml\napiVersion: storage.ironcore.dev/v1alpha1\nkind: Volume\nmetadata:\n  name: sample-volume\n  namespace: default\nspec:\n  volumeClassRef:\n    name: fast\n  volumePoolRef:\n    name: ceph\n  resources:\n    storage: 1Gi\n</code></pre> <pre><code>kubectl apply -f sample-volume.yaml \nvolume.storage.ironcore.dev/sample-volume created\n</code></pre>"},{"location":"infrastructure-as-a-service/components/ceph-provider/usage/#volume-status","title":"<code>Volume</code> Status","text":"<p>Once the <code>Volume</code> is provisioned the state will change to <code>Available</code>.</p> <pre><code>kubectl get volumes\nNAMESPACE       NAME            VOLUMEPOOLREF   VOLUMECLASS   STATE       PHASE     AGE\ndefault   sample-volume   ceph            fast          Available   Unbound   4m1s\n</code></pre> <p>The status of the <code>Volume</code> will contain the information which is needed to be able to consume the volume with a ceph client.</p> <pre><code>apiVersion: storage.ironcore.dev/v1alpha1\nkind: Volume\nmetadata:\n  name: sample-volume\n  namespace: default\nspec:\n  ...\nstatus:\n  access:\n    driver: ceph\n    secretRef:\n      name: sample-volume\n    volumeAttributes:\n      WWN: f1243b9a192c4825\n      image: ceph/csi-vol-ae2bb4d0-2cf1-11ed-a7db-b6307c819ad0\n      monitors: '[2a10:afc0:e013:4030::]:6789'\n  lastPhaseTransitionTime: \"2022-09-05T08:05:48Z\"\n  phase: Unbound\n  state: Available\n</code></pre> <p>The <code>secretRef</code> in the status defines the <code>secret</code> with the  access credentials for the specific <code>Volume</code>.</p> <pre><code>kubectl get secrets\nNAME            TYPE     DATA   AGE\nsample-volume   Opaque   2      93s\n</code></pre>"},{"location":"bare-metal-management/components/metal-operator/","title":"Metal-Operator Documentation","text":"<p>Welcome to the Metal-Operator Documentation!</p> <p>The <code>metal-operator</code> is a Kubernetes-native operator, part of the IronCore open-source project, designed for robust bare metal infrastructure management. By leveraging Baseboard Management Controllers (BMCs) and the Redfish API, <code>metal-operator</code> enables streamlined and automated server discovery, provisioning, and lifecycle management. Using the Kubernetes Controller pattern, <code>metal-operator</code> provides a CRD-based operational model that standardizes bare metal management across different hardware environments. Integration with vendor-specific tooling is also possible for enhanced functionality when needed.</p>"},{"location":"bare-metal-management/components/metal-operator/#key-features","title":"Key Features","text":""},{"location":"bare-metal-management/components/metal-operator/#1-discover-and-onboard-bare-metal-servers","title":"1. Discover and Onboard Bare Metal Servers","text":"<ul> <li>Automatically detect and register bare metal servers through BMCs and the Redfish API.</li> <li>Efficiently gather hardware specs, network configurations, and initial health checks directly from BMC interfaces.</li> </ul>"},{"location":"bare-metal-management/components/metal-operator/#2-provision-software-on-bare-metal-servers","title":"2. Provision Software on Bare Metal Servers","text":"<ul> <li>Deploy and configure software on registered servers using BMC interactions and standardized provisioning workflows.</li> <li>Support for dynamic software configuration and Redfish API-based management for consistent, vendor-neutral provisioning.</li> </ul>"},{"location":"bare-metal-management/components/metal-operator/#3-manage-server-reservations","title":"3. Manage Server Reservations","text":"<ul> <li>Reserve specific bare metal resources based on workload needs.</li> <li>Prevent resource conflicts by managing reservations via Kubernetes-native CRDs, ensuring that workloads align with available hardware resources.</li> </ul>"},{"location":"bare-metal-management/components/metal-operator/#4-perform-day-2-operations","title":"4. Perform Day 2 Operations","text":"<ul> <li>Utilize the Redfish API to manage BIOS, firmware, and driver updates.</li> <li>Automate ongoing maintenance tasks and operational workflows to maintain infrastructure resilience and uptime.</li> </ul>"},{"location":"bare-metal-management/components/metal-operator/#5-decommission-and-maintain-faulty-servers","title":"5. Decommission and Maintain Faulty Servers","text":"<ul> <li>Decommission servers via BMC controls for clean removal from active pools.</li> <li>Schedule and perform maintenance tasks with BMC data to optimize uptime and maintain hardware reliability.</li> </ul>"},{"location":"bare-metal-management/components/metal-operator/#how-it-works","title":"How It Works","text":"<p>The <code>metal-operator</code> relies on BMCs and the Redfish API to handle bare metal server management tasks. Through a CRD-based operational model, <code>metal-operator</code> provides Kubernetes-native management of bare metal infrastructure, enabling consistent, vendor-neutral interactions.</p>"},{"location":"bare-metal-management/components/metal-operator/#core-components","title":"Core Components","text":"<ul> <li>Custom Resources (CRs): Extend Kubernetes to manage server configurations, reservations, and operational workflows.</li> <li>Controllers: Automate lifecycle management through Redfish-enabled interactions, from provisioning to decommissioning.</li> <li>Reconcilers: Ensure the desired state matches the actual state by continuously monitoring hardware via BMC integrations.</li> </ul>"},{"location":"bare-metal-management/components/metal-operator/#architecture-overview","title":"Architecture Overview","text":"<ol> <li>Discovery: Register new bare metal servers through BMCs and Redfish API, creating CRDs for streamlined management.</li> <li>Provisioning: Apply software images and configurations using Redfish API, based on templates or custom configurations.</li> <li>Operations: Execute BIOS, firmware updates, and other maintenance tasks through standardized workflows.</li> <li>Decommissioning: Safely remove or maintain servers using Redfish and BMC controls, marking them for reuse or retirement as needed.</li> </ol> <p>The <code>metal-operator</code> is a core component of the IronCore project, designed to simplify and automate bare metal management across various hardware environments using BMC and Redfish API integrations. Expect continuous updates to expand capabilities and enhance usability.</p>"},{"location":"bare-metal-management/components/metal-operator/architecture/","title":"Metal-Operator Architectural Description","text":"<p>The metal-operator is a Kubernetes operator designed to manage bare metal servers within a Kubernetes environment. It automates the provisioning, configuration, and lifecycle management of physical servers by integrating them into Kubernetes using Custom Resource Definitions (CRDs) and controllers. The architecture promotes modularity, scalability, and flexibility, enabling seamless integration with various boot mechanisms and provisioning tools.</p>"},{"location":"bare-metal-management/components/metal-operator/architecture/#architectural-diagram","title":"Architectural Diagram","text":"<pre><code>flowchart LR\n    subgraph Out-of-Band Network\n        EndpointReconciler\n    end\n    EndpointReconciler -- Discovers --&gt; Endpoint\n    Endpoint -- Uses --&gt; MACPrefixDatabase\n    EndpointReconciler -- Creates --&gt; BMC &amp; BMCSecret\n\n    BMCReconciler -- Manages --&gt; BMC\n    BMCReconciler -- Uses --&gt; BMCSecret\n    BMCReconciler -- Discovers Servers --&gt; Server\n\n    ServerReconciler -- Manages --&gt; Server\n    ServerReconciler -- Uses --&gt; metalprobe\n    ServerReconciler -- Waits for --&gt; ServerBootConfiguration\n\n    ServerMaintenanceReconciler -- Manages --&gt; ServerMaintenance\n    ServerMaintenanceReconciler -- Creates/Deletes --&gt; ServerBootConfiguration\n    ServerMaintenanceReconciler -- Ensures Power --&gt; Server\n\n    ServerClaimReconciler -- Manages --&gt; ServerClaim\n    ServerClaim -- References --&gt; Server\n    ServerClaimReconciler -- Creates --&gt; ServerBootConfiguration\n\n    BootOperator -- Watches --&gt; ServerBootConfiguration\n    BootOperator -- Prepares --&gt; BootEnvironment\n    BootOperator -- Updates --&gt; ServerBootConfiguration\n\n    ServerReconciler -- Powers On --&gt; Server\n\n    classDef operator fill:#9575cd, stroke:#000, stroke-width:2px, color:#000;\n    classDef crd fill:#4db6ac, stroke:#000, stroke-width:2px, color:#000;\n    classDef external fill:#f48fb1, stroke:#000, stroke-width:2px, color:#000;\n\n    class EndpointReconciler,BMCReconciler,ServerReconciler,ServerClaimReconciler,ServerMaintenanceReconciler operator;\n    class Endpoint,BMC,BMCSecret,Server,ServerClaim,ServerBootConfiguration,ServerMaintenance crd;\n    class BootOperator external;</code></pre>"},{"location":"bare-metal-management/components/metal-operator/architecture/#key-components","title":"Key Components","text":""},{"location":"bare-metal-management/components/metal-operator/architecture/#1-custom-resource-definitions-crds","title":"1. Custom Resource Definitions (CRDs)","text":"<ul> <li>Endpoint: Represents devices on the out-of-band management network, identified by MAC and IP addresses.</li> <li>BMC: Models Baseboard Management Controllers (BMCs), allowing interaction with server hardware.</li> <li>BMCSecret: Securely stores credentials required to access BMCs.</li> <li>Server: Represents physical servers, managing their state, power, and configurations.</li> <li>ServerClaim: Allows users to reserve servers by specifying desired configurations and boot images.</li> <li>ServerBootConfiguration: Signals the need to prepare the boot environment for a server.</li> </ul>"},{"location":"bare-metal-management/components/metal-operator/architecture/#2-controllers","title":"2. Controllers","text":"<ul> <li> <p>EndpointReconciler: Discovers devices on the out-of-band network by processing <code>Endpoint</code> resources. It uses a MAC Prefix Database to identify device types, vendors, protocols, and default credentials. When a BMC is detected, it creates corresponding <code>BMC</code> and <code>BMCSecret</code> resources.</p> </li> <li> <p>BMCReconciler: Manages <code>BMC</code> resources by connecting to BMC devices using credentials from <code>BMCSecret</code>. It retrieves hardware information, updates the BMC status, and detects managed servers, creating <code>Server</code> resources for them.</p> </li> <li> <p>ServerReconciler: Manages <code>Server</code> resources and their lifecycle states. During the Discovery phase, it interacts with BMCs and uses the metalprobe agent to collect in-band hardware information, updating the server's status. It handles power management, BIOS configurations, and transitions servers through various states (e.g., Initial, Discovery, Available, Reserved).</p> </li> <li> <p>ServerClaimReconciler: Handles <code>ServerClaim</code> resources, allowing users to reserve servers. Upon creation of a <code>ServerClaim</code>, it allocates an available server, transitions it to the Reserved state, and creates a <code>ServerBootConfiguration</code>. When the claim is deleted, it releases the server, transitioning it to the Cleanup state for sanitization.</p> </li> <li> <p>Boot Operator (External Component): Monitors <code>ServerBootConfiguration</code> resources to prepare the boot environment (e.g., configuring DHCP, PXE servers). Once the boot environment is ready, it updates the <code>ServerBootConfiguration</code> status to Ready.</p> </li> </ul>"},{"location":"bare-metal-management/components/metal-operator/architecture/#workflow-summary","title":"Workflow Summary","text":"<ol> <li> <p>Discovery and Initialization:</p> <ul> <li>The EndpointReconciler discovers devices on the out-of-band network, creating <code>Endpoint</code> resources.</li> <li>BMCs are identified using the MAC Prefix Database, leading to the creation of <code>BMC</code> and <code>BMCSecret</code> resources.</li> <li>The BMCReconciler connects to BMCs, gathers hardware details, and creates <code>Server</code> resources for each managed server.</li> </ul> </li> <li> <p>Server Discovery Phase:</p> <ul> <li>The ServerReconciler enters the Discovery phase, interacting with BMCs and booting servers using a predefined ignition.</li> <li>The metalprobe agent runs on the servers, collecting detailed hardware information (e.g., network interfaces, storage devices) and reporting back to update the <code>Server</code> status.</li> </ul> </li> <li> <p>Server Availability:</p> <ul> <li>Once discovery is complete, servers transition to the Available state, ready to be claimed.</li> </ul> </li> <li> <p>Server Reservation and Boot Configuration:</p> <ul> <li>Users create <code>ServerClaim</code> resources to reserve servers, specifying desired OS images and ignition configurations.</li> <li>The ServerClaimReconciler allocates servers, transitions them to the Reserved state, and creates <code>ServerBootConfiguration</code> resources.</li> </ul> </li> <li> <p>Boot Environment Preparation:</p> <ul> <li>External components (e.g., boot-operator) watch for <code>ServerBootConfiguration</code> resources and prepare the boot environment accordingly.</li> <li>Once the environment is ready, they update the <code>ServerBootConfiguration</code> status to Ready.</li> </ul> </li> <li> <p>Server Power-On and Usage:</p> <ul> <li>The ServerReconciler detects the ready status and powers on the server.</li> <li>The server boots using the specified image and ignition configuration.</li> </ul> </li> <li> <p>Cleanup and Maintenance:</p> <ul> <li>When a <code>ServerClaim</code> is deleted, the server transitions to the Cleanup state.</li> <li>The ServerReconciler performs sanitization tasks (e.g., wiping disks, resetting configurations) before returning the server to the Available state.</li> <li>Servers can enter the Maintenance state for updates or repairs.</li> </ul> </li> </ol>"},{"location":"bare-metal-management/components/metal-operator/architecture/#architectural-benefits","title":"Architectural Benefits","text":"<ul> <li>Modularity: Separation of concerns allows for flexible integration with various boot mechanisms and provisioning tools (e.g., OpenStack Ironic, custom solutions).</li> <li>Scalability: Automates the management of large numbers of servers through Kubernetes CRDs and controllers.</li> <li>Extensibility: Supports customization through additional CRDs and operators, enabling adaptation to specific infrastructure needs.</li> <li>Security: Manages sensitive information like BMC credentials using Kubernetes Secrets and enforces access control via RBAC policies.</li> <li>Automation: Streamlines hardware provisioning, configuration, and lifecycle management, reducing manual intervention and potential errors.</li> </ul>"},{"location":"bare-metal-management/components/metal-operator/api-reference/api/","title":"API Reference","text":"<p>Packages:</p> <ul> <li> metal.ironcore.dev/v1alpha1 </li> </ul>"},{"location":"bare-metal-management/components/metal-operator/api-reference/api/#metal.ironcore.dev/v1alpha1","title":"metal.ironcore.dev/v1alpha1","text":"<p>Package v1alpha1 contains API Schema definitions for the settings.gardener.cloud API group</p> <p>Resource Types:</p>"},{"location":"bare-metal-management/components/metal-operator/api-reference/api/#metal.ironcore.dev/v1alpha1.BIOSSettings","title":"BIOSSettings","text":"<p> (Appears on:ServerSpec, ServerStatus) </p> <p>BIOSSettings represents the BIOS settings for a server.</p> Field Description <code>version</code>  string  <p>Version specifies the version of the server BIOS for which the settings are defined.</p> <code>settings</code>  map[string]string  <p>Settings is a map of key-value pairs representing the BIOS settings.</p>"},{"location":"bare-metal-management/components/metal-operator/api-reference/api/#metal.ironcore.dev/v1alpha1.BMC","title":"BMC","text":"<p>BMC is the Schema for the bmcs API</p> Field Description <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>spec</code>  BMCSpec  <code>endpointRef</code>  Kubernetes core/v1.LocalObjectReference  (Optional) <p>EndpointRef is a reference to the Kubernetes object that contains the endpoint information for the BMC. This reference is typically used to locate the BMC endpoint within the cluster.</p> <code>access</code>  InlineEndpoint  (Optional) <p>Endpoint allows inline configuration of network access details for the BMC. Use this field if access settings like address are to be configured directly within the BMC resource.</p> <code>bmcSecretRef</code>  Kubernetes core/v1.LocalObjectReference  <p>BMCSecretRef is a reference to the Kubernetes Secret object that contains the credentials required to access the BMC. This secret includes sensitive information such as usernames and passwords.</p> <code>protocol</code>  Protocol  <p>Protocol specifies the protocol to be used for communicating with the BMC. It could be a standard protocol such as IPMI or Redfish.</p> <code>consoleProtocol</code>  ConsoleProtocol  (Optional) <p>ConsoleProtocol specifies the protocol to be used for console access to the BMC. This field is optional and can be omitted if console access is not required.</p> <code>status</code>  BMCStatus"},{"location":"bare-metal-management/components/metal-operator/api-reference/api/#metal.ironcore.dev/v1alpha1.BMCAccess","title":"BMCAccess","text":"<p> (Appears on:ServerSpec) </p> <p>BMCAccess defines the access details for the BMC.</p> Field Description <code>protocol</code>  Protocol  <p>Protocol specifies the protocol to be used for communicating with the BMC.</p> <code>address</code>  string  <p>Address is the address of the BMC.</p> <code>bmcSecretRef</code>  Kubernetes core/v1.LocalObjectReference  <p>BMCSecretRef is a reference to the Kubernetes Secret object that contains the credentials required to access the BMC. This secret includes sensitive information such as usernames and passwords.</p>"},{"location":"bare-metal-management/components/metal-operator/api-reference/api/#metal.ironcore.dev/v1alpha1.BMCPowerState","title":"BMCPowerState (<code>string</code> alias)","text":"<p> (Appears on:BMCStatus) </p> <p>BMCPowerState defines the possible power states for a BMC.</p> Value Description <p>\"Off\"</p> <p>OffPowerState the system is powered off, although some components may continue to have AUX power such as management controller.</p> <p>\"On\"</p> <p>OnPowerState the system is powered on.</p> <p>\"Paused\"</p> <p>PausedPowerState the system is paused.</p> <p>\"PoweringOff\"</p> <p>PoweringOffPowerState A temporary state between On and Off. The power off action can take time while the OS is in the shutdown process.</p> <p>\"PoweringOn\"</p> <p>PoweringOnPowerState A temporary state between Off and On. This temporary state can be very short.</p>"},{"location":"bare-metal-management/components/metal-operator/api-reference/api/#metal.ironcore.dev/v1alpha1.BMCSecret","title":"BMCSecret","text":"<p>BMCSecret is the Schema for the bmcsecrets API</p> Field Description <code>metadata</code>  Kubernetes meta/v1.ObjectMeta  (Optional) <p>Standard object\u2019s metadata. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata</p> Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>immutable</code>  bool  (Optional) <p>Immutable, if set to true, ensures that data stored in the Secret cannot be updated (only object metadata can be modified). If not set to true, the field can be modified at any time. Defaulted to nil.</p> <code>data</code>  map[string][]byte  (Optional) <p>Data contains the secret data. Each key must consist of alphanumeric characters, \u2018-\u2019, \u2018_\u2019 or \u2018.\u2019. The serialized form of the secret data is a base64 encoded string, representing the arbitrary (possibly non-string) data value here. Described in https://tools.ietf.org/html/rfc4648#section-4</p> <code>stringData</code>  map[string]string  (Optional) <p>stringData allows specifying non-binary secret data in string form. It is provided as a write-only input field for convenience. All keys and values are merged into the data field on write, overwriting any existing values. The stringData field is never output when reading from the API.</p> <code>type</code>  Kubernetes core/v1.SecretType  (Optional) <p>Used to facilitate programmatic handling of secret data. More info: https://kubernetes.io/docs/concepts/configuration/secret/#secret-types</p>"},{"location":"bare-metal-management/components/metal-operator/api-reference/api/#metal.ironcore.dev/v1alpha1.BMCSpec","title":"BMCSpec","text":"<p> (Appears on:BMC) </p> <p>BMCSpec defines the desired state of BMC</p> Field Description <code>endpointRef</code>  Kubernetes core/v1.LocalObjectReference  (Optional) <p>EndpointRef is a reference to the Kubernetes object that contains the endpoint information for the BMC. This reference is typically used to locate the BMC endpoint within the cluster.</p> <code>access</code>  InlineEndpoint  (Optional) <p>Endpoint allows inline configuration of network access details for the BMC. Use this field if access settings like address are to be configured directly within the BMC resource.</p> <code>bmcSecretRef</code>  Kubernetes core/v1.LocalObjectReference  <p>BMCSecretRef is a reference to the Kubernetes Secret object that contains the credentials required to access the BMC. This secret includes sensitive information such as usernames and passwords.</p> <code>protocol</code>  Protocol  <p>Protocol specifies the protocol to be used for communicating with the BMC. It could be a standard protocol such as IPMI or Redfish.</p> <code>consoleProtocol</code>  ConsoleProtocol  (Optional) <p>ConsoleProtocol specifies the protocol to be used for console access to the BMC. This field is optional and can be omitted if console access is not required.</p>"},{"location":"bare-metal-management/components/metal-operator/api-reference/api/#metal.ironcore.dev/v1alpha1.BMCState","title":"BMCState (<code>string</code> alias)","text":"<p> (Appears on:BMCStatus) </p> <p>BMCState defines the possible states of a BMC.</p> Value Description <p>\"Enabled\"</p> <p>BMCStateEnabled indicates that the BMC is enabled and functioning correctly.</p> <p>\"Error\"</p> <p>BMCStateError indicates that there is an error with the BMC.</p>"},{"location":"bare-metal-management/components/metal-operator/api-reference/api/#metal.ironcore.dev/v1alpha1.BMCStatus","title":"BMCStatus","text":"<p> (Appears on:BMC) </p> <p>BMCStatus defines the observed state of BMC.</p> Field Description <code>macAddress</code>  string  <p>MACAddress is the MAC address of the BMC. The format is validated using a regular expression pattern.</p> <code>ip</code>  IP  <p>IP is the IP address of the BMC. The type is specified as string and is schemaless.</p> <code>manufacturer</code>  string  <p>Manufacturer is the name of the BMC manufacturer.</p> <code>model</code>  string  <p>Model is the model number or name of the BMC.</p> <code>sku</code>  string  <p>SKU is the stock keeping unit identifier for the BMC.</p> <code>serialNumber</code>  string  <p>SerialNumber is the serial number of the BMC.</p> <code>firmwareVersion</code>  string  <p>FirmwareVersion is the version of the firmware currently running on the BMC.</p> <code>state</code>  BMCState  <p>State represents the current state of the BMC.</p> <code>powerState</code>  BMCPowerState  <p>PowerState represents the current power state of the BMC.</p> <code>conditions</code>  []Kubernetes meta/v1.Condition  (Optional) <p>Conditions represents the latest available observations of the BMC\u2019s current state.</p>"},{"location":"bare-metal-management/components/metal-operator/api-reference/api/#metal.ironcore.dev/v1alpha1.BootOrder","title":"BootOrder","text":"<p> (Appears on:ServerSpec) </p> <p>BootOrder represents the boot order of the server.</p> Field Description <code>name</code>  string  <p>Name is the name of the boot device.</p> <code>priority</code>  int  <p>Priority is the priority of the boot device.</p> <code>device</code>  string  <p>Device is the device to boot from.</p>"},{"location":"bare-metal-management/components/metal-operator/api-reference/api/#metal.ironcore.dev/v1alpha1.ConsoleProtocol","title":"ConsoleProtocol","text":"<p> (Appears on:BMCSpec) </p> <p>ConsoleProtocol defines the protocol and port used for console access to the BMC.</p> Field Description <code>name</code>  ConsoleProtocolName  <p>Name specifies the name of the console protocol. This could be a protocol such as \u201cSSH\u201d, \u201cTelnet\u201d, etc.</p> <code>port</code>  int32  <p>Port specifies the port number used for console access. This port is used by the specified console protocol to establish connections.</p>"},{"location":"bare-metal-management/components/metal-operator/api-reference/api/#metal.ironcore.dev/v1alpha1.ConsoleProtocolName","title":"ConsoleProtocolName (<code>string</code> alias)","text":"<p> (Appears on:ConsoleProtocol) </p> <p>ConsoleProtocolName defines the possible names for console protocols.</p> Value Description <p>\"IPMI\"</p> <p>ConsoleProtocolNameIPMI represents the IPMI console protocol.</p> <p>\"SSH\"</p> <p>ConsoleProtocolNameSSH represents the SSH console protocol.</p> <p>\"SSHLenovo\"</p> <p>ConsoleProtocolNameSSHLenovo represents the SSH console protocol specific to Lenovo hardware.</p>"},{"location":"bare-metal-management/components/metal-operator/api-reference/api/#metal.ironcore.dev/v1alpha1.Endpoint","title":"Endpoint","text":"<p>Endpoint is the Schema for the endpoints API</p> Field Description <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>spec</code>  EndpointSpec  <code>macAddress</code>  string  <p>MACAddress is the MAC address of the endpoint.</p> <code>ip</code>  IP  <p>IP is the IP address of the endpoint.</p> <code>status</code>  EndpointStatus"},{"location":"bare-metal-management/components/metal-operator/api-reference/api/#metal.ironcore.dev/v1alpha1.EndpointSpec","title":"EndpointSpec","text":"<p> (Appears on:Endpoint) </p> <p>EndpointSpec defines the desired state of Endpoint</p> Field Description <code>macAddress</code>  string  <p>MACAddress is the MAC address of the endpoint.</p> <code>ip</code>  IP  <p>IP is the IP address of the endpoint.</p>"},{"location":"bare-metal-management/components/metal-operator/api-reference/api/#metal.ironcore.dev/v1alpha1.EndpointStatus","title":"EndpointStatus","text":"<p> (Appears on:Endpoint) </p> <p>EndpointStatus defines the observed state of Endpoint</p>"},{"location":"bare-metal-management/components/metal-operator/api-reference/api/#metal.ironcore.dev/v1alpha1.IP","title":"IP","text":"<p> (Appears on:BMCStatus, EndpointSpec, InlineEndpoint, NetworkInterface) </p> <p>IP is an IP address.</p> Field Description <code>-</code>  net/netip.Addr"},{"location":"bare-metal-management/components/metal-operator/api-reference/api/#metal.ironcore.dev/v1alpha1.IPPrefix","title":"IPPrefix","text":"<p>IPPrefix represents a network prefix.</p> Field Description <code>-</code>  net/netip.Prefix"},{"location":"bare-metal-management/components/metal-operator/api-reference/api/#metal.ironcore.dev/v1alpha1.IndicatorLED","title":"IndicatorLED (<code>string</code> alias)","text":"<p> (Appears on:ServerSpec, ServerStatus) </p> <p>IndicatorLED represents LED indicator states</p> Value Description <p>\"Blinking\"</p> <p>BlinkingIndicatorLED indicates the Indicator LED is blinking.</p> <p>\"Lit\"</p> <p>LitIndicatorLED indicates the Indicator LED is lit.</p> <p>\"Off\"</p> <p>OffIndicatorLED indicates the Indicator LED is off.</p> <p>\"Unknown\"</p> <p>UnknownIndicatorLED indicates the state of the Indicator LED cannot be determined.</p>"},{"location":"bare-metal-management/components/metal-operator/api-reference/api/#metal.ironcore.dev/v1alpha1.InlineEndpoint","title":"InlineEndpoint","text":"<p> (Appears on:BMCSpec) </p> <p>InlineEndpoint defines inline network access configuration for the BMC.</p> Field Description <code>macAddress</code>  string  <p>MACAddress is the MAC address of the endpoint.</p> <code>ip</code>  IP  <p>IP is the IP address of the BMC.</p>"},{"location":"bare-metal-management/components/metal-operator/api-reference/api/#metal.ironcore.dev/v1alpha1.NetworkInterface","title":"NetworkInterface","text":"<p> (Appears on:ServerStatus) </p> <p>NetworkInterface defines the details of a network interface.</p> Field Description <code>name</code>  string  <p>Name is the name of the network interface.</p> <code>ip</code>  IP  <p>IP is the IP address assigned to the network interface. The type is specified as string and is schemaless.</p> <code>macAddress</code>  string  <p>MACAddress is the MAC address of the network interface.</p>"},{"location":"bare-metal-management/components/metal-operator/api-reference/api/#metal.ironcore.dev/v1alpha1.Phase","title":"Phase (<code>string</code> alias)","text":"<p> (Appears on:ServerClaimStatus) </p> <p>Phase defines the possible phases of a ServerClaim.</p> Value Description <p>\"Bound\"</p> <p>PhaseBound indicates that the server claim is bound to a server.</p> <p>\"Unbound\"</p> <p>PhaseUnbound indicates that the server claim is not bound to any server.</p>"},{"location":"bare-metal-management/components/metal-operator/api-reference/api/#metal.ironcore.dev/v1alpha1.Power","title":"Power (<code>string</code> alias)","text":"<p> (Appears on:ServerClaimSpec, ServerMaintenanceSpec, ServerSpec) </p> <p>Power defines the possible power states for a device.</p> Value Description <p>\"Off\"</p> <p>PowerOff indicates that the device is powered off.</p> <p>\"On\"</p> <p>PowerOn indicates that the device is powered on.</p>"},{"location":"bare-metal-management/components/metal-operator/api-reference/api/#metal.ironcore.dev/v1alpha1.Protocol","title":"Protocol","text":"<p> (Appears on:BMCAccess, BMCSpec) </p> <p>Protocol defines the protocol and port used for communicating with the BMC.</p> Field Description <code>name</code>  ProtocolName  <p>Name specifies the name of the protocol. This could be a protocol such as \u201cIPMI\u201d, \u201cRedfish\u201d, etc.</p> <code>port</code>  int32  <p>Port specifies the port number used for communication. This port is used by the specified protocol to establish connections.</p> <code>scheme</code>  ProtocolScheme  <p>Scheme specifies the scheme used for communication.</p>"},{"location":"bare-metal-management/components/metal-operator/api-reference/api/#metal.ironcore.dev/v1alpha1.ProtocolName","title":"ProtocolName (<code>string</code> alias)","text":"<p> (Appears on:Protocol) </p> <p>ProtocolName defines the possible names for protocols used for communicating with the BMC.</p> Value Description <p>\"IPMI\"</p> <p>ProtocolNameIPMI represents the IPMI protocol.</p> <p>\"Redfish\"</p> <p>ProtocolNameRedfish represents the Redfish protocol.</p> <p>\"SSH\"</p> <p>ProtocolNameSSH represents the SSH protocol.</p>"},{"location":"bare-metal-management/components/metal-operator/api-reference/api/#metal.ironcore.dev/v1alpha1.ProtocolScheme","title":"ProtocolScheme (<code>string</code> alias)","text":"<p> (Appears on:Protocol) </p> <p>ProtocolScheme is a string that contains the protocol scheme</p> Value Description <p>\"http\"</p> <p>HTTPProtocolScheme is the http protocol scheme</p> <p>\"https\"</p> <p>HTTPSProtocolScheme is the https protocol scheme</p>"},{"location":"bare-metal-management/components/metal-operator/api-reference/api/#metal.ironcore.dev/v1alpha1.Server","title":"Server","text":"<p>Server is the Schema for the servers API</p> Field Description <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>spec</code>  ServerSpec  <code>uuid</code>  string  <p>UUID is the unique identifier for the server. Deprecated in favor of systemUUID.</p> <code>systemUUID</code>  string  <p>SystemUUID is the unique identifier for the server.</p> <code>power</code>  Power  <p>Power specifies the desired power state of the server.</p> <code>indicatorLED</code>  IndicatorLED  <p>IndicatorLED specifies the desired state of the server\u2019s indicator LED.</p> <code>serverClaimRef</code>  Kubernetes core/v1.ObjectReference  <p>ServerClaimRef is a reference to a ServerClaim object that claims this server. This field is optional and can be omitted if no claim is associated with this server.</p> <code>serverMaintenanceRef</code>  Kubernetes core/v1.ObjectReference  <p>ServerMaintenanceRef is a reference to a ServerMaintenance object that maintains this server.</p> <code>bmcRef</code>  Kubernetes core/v1.LocalObjectReference  <p>BMCRef is a reference to the BMC object associated with this server. This field is optional and can be omitted if no BMC is associated with this server.</p> <code>bmc</code>  BMCAccess  <p>BMC contains the access details for the BMC. This field is optional and can be omitted if no BMC access is specified.</p> <code>bootConfigurationRef</code>  Kubernetes core/v1.ObjectReference  <p>BootConfigurationRef is a reference to a BootConfiguration object that specifies the boot configuration for this server. This field is optional and can be omitted if no boot configuration is specified.</p> <code>maintenanceBootConfigurationRef</code>  Kubernetes core/v1.ObjectReference  <p>MaintenanceBootConfigurationRef is a reference to a BootConfiguration object that specifies the boot configuration for this server during maintenance. This field is optional and can be omitted</p> <code>bootOrder</code>  []BootOrder  <p>BootOrder specifies the boot order of the server.</p> <code>BIOS</code>  []BIOSSettings  <p>BIOS specifies the BIOS settings for the server.</p> <code>status</code>  ServerStatus"},{"location":"bare-metal-management/components/metal-operator/api-reference/api/#metal.ironcore.dev/v1alpha1.ServerBootConfiguration","title":"ServerBootConfiguration","text":"<p>ServerBootConfiguration is the Schema for the serverbootconfigurations API</p> Field Description <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>spec</code>  ServerBootConfigurationSpec  <code>serverRef</code>  Kubernetes core/v1.LocalObjectReference  <p>ServerRef is a reference to the server for which this boot configuration is intended.</p> <code>image</code>  string  <p>Image specifies the boot image to be used for the server. This field is optional and can be omitted if not specified.</p> <code>ignitionSecretRef</code>  Kubernetes core/v1.LocalObjectReference  <p>IgnitionSecretRef is a reference to the Kubernetes Secret object that contains the ignition configuration for the server. This field is optional and can be omitted if not specified.</p> <code>status</code>  ServerBootConfigurationStatus"},{"location":"bare-metal-management/components/metal-operator/api-reference/api/#metal.ironcore.dev/v1alpha1.ServerBootConfigurationSpec","title":"ServerBootConfigurationSpec","text":"<p> (Appears on:ServerBootConfiguration, ServerBootConfigurationTemplate) </p> <p>ServerBootConfigurationSpec defines the desired state of ServerBootConfiguration.</p> Field Description <code>serverRef</code>  Kubernetes core/v1.LocalObjectReference  <p>ServerRef is a reference to the server for which this boot configuration is intended.</p> <code>image</code>  string  <p>Image specifies the boot image to be used for the server. This field is optional and can be omitted if not specified.</p> <code>ignitionSecretRef</code>  Kubernetes core/v1.LocalObjectReference  <p>IgnitionSecretRef is a reference to the Kubernetes Secret object that contains the ignition configuration for the server. This field is optional and can be omitted if not specified.</p>"},{"location":"bare-metal-management/components/metal-operator/api-reference/api/#metal.ironcore.dev/v1alpha1.ServerBootConfigurationState","title":"ServerBootConfigurationState (<code>string</code> alias)","text":"<p> (Appears on:ServerBootConfigurationStatus) </p> <p>ServerBootConfigurationState defines the possible states of a ServerBootConfiguration.</p> Value Description <p>\"Error\"</p> <p>ServerBootConfigurationStateError indicates that there is an error with the boot configuration.</p> <p>\"Pending\"</p> <p>ServerBootConfigurationStatePending indicates that the boot configuration is pending and not yet ready.</p> <p>\"Ready\"</p> <p>ServerBootConfigurationStateReady indicates that the boot configuration is ready for use.</p>"},{"location":"bare-metal-management/components/metal-operator/api-reference/api/#metal.ironcore.dev/v1alpha1.ServerBootConfigurationStatus","title":"ServerBootConfigurationStatus","text":"<p> (Appears on:ServerBootConfiguration) </p> <p>ServerBootConfigurationStatus defines the observed state of ServerBootConfiguration.</p> Field Description <code>state</code>  ServerBootConfigurationState  <p>State represents the current state of the boot configuration.</p>"},{"location":"bare-metal-management/components/metal-operator/api-reference/api/#metal.ironcore.dev/v1alpha1.ServerBootConfigurationTemplate","title":"ServerBootConfigurationTemplate","text":"<p> (Appears on:ServerMaintenanceSpec) </p> <p>ServerBootConfigurationTemplate defines the parameters to be used for rendering a boot configuration.</p> Field Description <code>name</code>  string  <p>Name specifies the name of the boot configuration.</p> <code>spec</code>  ServerBootConfigurationSpec  <p>Parameters specifies the parameters to be used for rendering the boot configuration.</p> <code>serverRef</code>  Kubernetes core/v1.LocalObjectReference  <p>ServerRef is a reference to the server for which this boot configuration is intended.</p> <code>image</code>  string  <p>Image specifies the boot image to be used for the server. This field is optional and can be omitted if not specified.</p> <code>ignitionSecretRef</code>  Kubernetes core/v1.LocalObjectReference  <p>IgnitionSecretRef is a reference to the Kubernetes Secret object that contains the ignition configuration for the server. This field is optional and can be omitted if not specified.</p>"},{"location":"bare-metal-management/components/metal-operator/api-reference/api/#metal.ironcore.dev/v1alpha1.ServerClaim","title":"ServerClaim","text":"<p>ServerClaim is the Schema for the serverclaims API</p> Field Description <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>spec</code>  ServerClaimSpec  <code>power</code>  Power  <p>Power specifies the desired power state of the server.</p> <code>serverRef</code>  Kubernetes core/v1.LocalObjectReference  <p>ServerRef is a reference to a specific server to be claimed. This field is optional and can be omitted if the server is to be selected using ServerSelector.</p> <code>serverSelector</code>  Kubernetes meta/v1.LabelSelector  <p>ServerSelector specifies a label selector to identify the server to be claimed. This field is optional and can be omitted if a specific server is referenced using ServerRef.</p> <code>ignitionSecretRef</code>  Kubernetes core/v1.LocalObjectReference  <p>IgnitionSecretRef is a reference to the Kubernetes Secret object that contains the ignition configuration for the server. This field is optional and can be omitted if not specified.</p> <code>image</code>  string  <p>Image specifies the boot image to be used for the server.</p> <code>status</code>  ServerClaimStatus"},{"location":"bare-metal-management/components/metal-operator/api-reference/api/#metal.ironcore.dev/v1alpha1.ServerClaimSpec","title":"ServerClaimSpec","text":"<p> (Appears on:ServerClaim) </p> <p>ServerClaimSpec defines the desired state of ServerClaim.</p> Field Description <code>power</code>  Power  <p>Power specifies the desired power state of the server.</p> <code>serverRef</code>  Kubernetes core/v1.LocalObjectReference  <p>ServerRef is a reference to a specific server to be claimed. This field is optional and can be omitted if the server is to be selected using ServerSelector.</p> <code>serverSelector</code>  Kubernetes meta/v1.LabelSelector  <p>ServerSelector specifies a label selector to identify the server to be claimed. This field is optional and can be omitted if a specific server is referenced using ServerRef.</p> <code>ignitionSecretRef</code>  Kubernetes core/v1.LocalObjectReference  <p>IgnitionSecretRef is a reference to the Kubernetes Secret object that contains the ignition configuration for the server. This field is optional and can be omitted if not specified.</p> <code>image</code>  string  <p>Image specifies the boot image to be used for the server.</p>"},{"location":"bare-metal-management/components/metal-operator/api-reference/api/#metal.ironcore.dev/v1alpha1.ServerClaimStatus","title":"ServerClaimStatus","text":"<p> (Appears on:ServerClaim) </p> <p>ServerClaimStatus defines the observed state of ServerClaim.</p> Field Description <code>phase</code>  Phase  <p>Phase represents the current phase of the server claim.</p>"},{"location":"bare-metal-management/components/metal-operator/api-reference/api/#metal.ironcore.dev/v1alpha1.ServerMaintenance","title":"ServerMaintenance","text":"<p>ServerMaintenance is the Schema for the ServerMaintenance API</p> Field Description <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>spec</code>  ServerMaintenanceSpec  <code>policy</code>  ServerMaintenancePolicy  <p>Policy specifies the maintenance policy to be enforced on the server.</p> <code>serverRef</code>  Kubernetes core/v1.LocalObjectReference  <p>ServerRef is a reference to the server that is to be maintained.</p> <code>serverPower</code>  Power  <p>ServerPower specifies the power state of the server during maintenance.</p> <code>serverBootConfigurationTemplate</code>  ServerBootConfigurationTemplate  <p>ServerBootConfigurationTemplate specifies the boot configuration to be applied to the server during maintenance.</p> <code>status</code>  ServerMaintenanceStatus"},{"location":"bare-metal-management/components/metal-operator/api-reference/api/#metal.ironcore.dev/v1alpha1.ServerMaintenancePolicy","title":"ServerMaintenancePolicy (<code>string</code> alias)","text":"<p> (Appears on:ServerMaintenanceSpec) </p> <p>ServerMaintenancePolicy specifies the maintenance policy to be enforced on the server.</p> Value Description <p>\"Enforced\"</p> <p>ServerMaintenancePolicyEnforced specifies that the maintenance policy is enforced.</p> <p>\"OwnerApproval\"</p> <p>ServerMaintenancePolicyOwnerApproval specifies that the maintenance policy requires owner approval.</p>"},{"location":"bare-metal-management/components/metal-operator/api-reference/api/#metal.ironcore.dev/v1alpha1.ServerMaintenanceSpec","title":"ServerMaintenanceSpec","text":"<p> (Appears on:ServerMaintenance) </p> <p>ServerMaintenanceSpec defines the desired state of a ServerMaintenance</p> Field Description <code>policy</code>  ServerMaintenancePolicy  <p>Policy specifies the maintenance policy to be enforced on the server.</p> <code>serverRef</code>  Kubernetes core/v1.LocalObjectReference  <p>ServerRef is a reference to the server that is to be maintained.</p> <code>serverPower</code>  Power  <p>ServerPower specifies the power state of the server during maintenance.</p> <code>serverBootConfigurationTemplate</code>  ServerBootConfigurationTemplate  <p>ServerBootConfigurationTemplate specifies the boot configuration to be applied to the server during maintenance.</p>"},{"location":"bare-metal-management/components/metal-operator/api-reference/api/#metal.ironcore.dev/v1alpha1.ServerMaintenanceState","title":"ServerMaintenanceState (<code>string</code> alias)","text":"<p> (Appears on:ServerMaintenanceStatus) </p> <p>ServerMaintenanceState specifies the current state of the server maintenance.</p> Value Description <p>\"Completed\"</p> <p>ServerMaintenanceStateCompleted specifies that the server maintenance has been completed.</p> <p>\"Failed\"</p> <p>ServerMaintenanceStateFailed specifies that the server maintenance has failed.</p> <p>\"InMaintenance\"</p> <p>ServerMaintenanceStateInMaintenance specifies that the server is in maintenance.</p> <p>\"Pending\"</p> <p>ServerMaintenanceStatePending specifies that the server maintenance is pending.</p>"},{"location":"bare-metal-management/components/metal-operator/api-reference/api/#metal.ironcore.dev/v1alpha1.ServerMaintenanceStatus","title":"ServerMaintenanceStatus","text":"<p> (Appears on:ServerMaintenance) </p> <p>ServerMaintenanceStatus defines the observed state of a ServerMaintenance</p> Field Description <code>state</code>  ServerMaintenanceState  <p>State specifies the current state of the server maintenance.</p>"},{"location":"bare-metal-management/components/metal-operator/api-reference/api/#metal.ironcore.dev/v1alpha1.ServerPowerState","title":"ServerPowerState (<code>string</code> alias)","text":"<p> (Appears on:ServerStatus) </p> <p>ServerPowerState defines the possible power states for a server.</p> Value Description <p>\"Off\"</p> <p>ServerOffPowerState indicates that the system is powered off, although some components may continue to have auxiliary power such as the management controller.</p> <p>\"On\"</p> <p>ServerOnPowerState indicates that the system is powered on.</p> <p>\"Paused\"</p> <p>ServerPausedPowerState indicates that the system is paused.</p> <p>\"PoweringOff\"</p> <p>ServerPoweringOffPowerState indicates a temporary state between On and Off. The power off action can take time while the OS is in the shutdown process.</p> <p>\"PoweringOn\"</p> <p>ServerPoweringOnPowerState indicates a temporary state between Off and On. This temporary state can be very short.</p>"},{"location":"bare-metal-management/components/metal-operator/api-reference/api/#metal.ironcore.dev/v1alpha1.ServerSpec","title":"ServerSpec","text":"<p> (Appears on:Server) </p> <p>ServerSpec defines the desired state of a Server.</p> Field Description <code>uuid</code>  string  <p>UUID is the unique identifier for the server. Deprecated in favor of systemUUID.</p> <code>systemUUID</code>  string  <p>SystemUUID is the unique identifier for the server.</p> <code>power</code>  Power  <p>Power specifies the desired power state of the server.</p> <code>indicatorLED</code>  IndicatorLED  <p>IndicatorLED specifies the desired state of the server\u2019s indicator LED.</p> <code>serverClaimRef</code>  Kubernetes core/v1.ObjectReference  <p>ServerClaimRef is a reference to a ServerClaim object that claims this server. This field is optional and can be omitted if no claim is associated with this server.</p> <code>serverMaintenanceRef</code>  Kubernetes core/v1.ObjectReference  <p>ServerMaintenanceRef is a reference to a ServerMaintenance object that maintains this server.</p> <code>bmcRef</code>  Kubernetes core/v1.LocalObjectReference  <p>BMCRef is a reference to the BMC object associated with this server. This field is optional and can be omitted if no BMC is associated with this server.</p> <code>bmc</code>  BMCAccess  <p>BMC contains the access details for the BMC. This field is optional and can be omitted if no BMC access is specified.</p> <code>bootConfigurationRef</code>  Kubernetes core/v1.ObjectReference  <p>BootConfigurationRef is a reference to a BootConfiguration object that specifies the boot configuration for this server. This field is optional and can be omitted if no boot configuration is specified.</p> <code>maintenanceBootConfigurationRef</code>  Kubernetes core/v1.ObjectReference  <p>MaintenanceBootConfigurationRef is a reference to a BootConfiguration object that specifies the boot configuration for this server during maintenance. This field is optional and can be omitted</p> <code>bootOrder</code>  []BootOrder  <p>BootOrder specifies the boot order of the server.</p> <code>BIOS</code>  []BIOSSettings  <p>BIOS specifies the BIOS settings for the server.</p>"},{"location":"bare-metal-management/components/metal-operator/api-reference/api/#metal.ironcore.dev/v1alpha1.ServerState","title":"ServerState (<code>string</code> alias)","text":"<p> (Appears on:ServerStatus) </p> <p>ServerState defines the possible states of a server.</p> Value Description <p>\"Available\"</p> <p>ServerStateAvailable indicates that the server is available for use.</p> <p>\"Discovery\"</p> <p>ServerStateDiscovery indicates that the server is in its discovery state.</p> <p>\"Error\"</p> <p>ServerStateError indicates that there is an error with the server.</p> <p>\"Initial\"</p> <p>ServerStateInitial indicates that the server is in its initial state.</p> <p>\"Maintenance\"</p> <p>ServerStateMaintenance indicates that the server is in maintenance.</p> <p>\"Reserved\"</p> <p>ServerStateReserved indicates that the server is reserved for a specific use or user.</p>"},{"location":"bare-metal-management/components/metal-operator/api-reference/api/#metal.ironcore.dev/v1alpha1.ServerStatus","title":"ServerStatus","text":"<p> (Appears on:Server) </p> <p>ServerStatus defines the observed state of Server.</p> Field Description <code>manufacturer</code>  string  <p>Manufacturer is the name of the server manufacturer.</p> <code>model</code>  string  <p>Model is the model of the server.</p> <code>sku</code>  string  <p>SKU is the stock keeping unit identifier for the server.</p> <code>serialNumber</code>  string  <p>SerialNumber is the serial number of the server.</p> <code>powerState</code>  ServerPowerState  <p>PowerState represents the current power state of the server.</p> <code>indicatorLED</code>  IndicatorLED  <p>IndicatorLED specifies the current state of the server\u2019s indicator LED.</p> <code>state</code>  ServerState  <p>State represents the current state of the server.</p> <code>networkInterfaces</code>  []NetworkInterface  <p>NetworkInterfaces is a list of network interfaces associated with the server.</p> <code>totalSystemMemory</code>  k8s.io/apimachinery/pkg/api/resource.Quantity  <p>TotalSystemMemory is the total amount of memory in bytes available on the server.</p> <code>storages</code>  []Storage  <p>Storages is a list of storages associated with the server.</p> <code>BIOS</code>  BIOSSettings  <code>conditions</code>  []Kubernetes meta/v1.Condition  (Optional) <p>Conditions represents the latest available observations of the server\u2019s current state.</p>"},{"location":"bare-metal-management/components/metal-operator/api-reference/api/#metal.ironcore.dev/v1alpha1.Storage","title":"Storage","text":"<p> (Appears on:ServerStatus) </p> <p>Storage defines the details of one storage device</p> Field Description <code>name</code>  string  <p>Name is the name of the storage interface.</p> <code>state</code>  StorageState  <p>State specifies the state of the storage device.</p> <code>volumes</code>  []StorageVolume  <p>Volumes is a collection of volumes associated with this storage.</p> <code>drives</code>  []StorageDrive  <p>Drives is a collection of drives associated with this storage.</p>"},{"location":"bare-metal-management/components/metal-operator/api-reference/api/#metal.ironcore.dev/v1alpha1.StorageDrive","title":"StorageDrive","text":"<p> (Appears on:Storage) </p> <p>StorageDrive defines the details of one storage drive</p> Field Description <code>name</code>  string  <p>Name is the name of the storage interface.</p> <code>mediaType</code>  string  <p>MediaType specifies the media type of the storage device.</p> <code>type</code>  string  <p>Type specifies the type of the storage device.</p> <code>capacity</code>  k8s.io/apimachinery/pkg/api/resource.Quantity  <p>Capacity specifies the size of the storage device in bytes.</p> <code>vendor</code>  string  <p>Vendor specifies the vendor of the storage device.</p> <code>model</code>  string  <p>Model specifies the model of the storage device.</p> <code>state</code>  StorageState  <p>State specifies the state of the storage device.</p>"},{"location":"bare-metal-management/components/metal-operator/api-reference/api/#metal.ironcore.dev/v1alpha1.StorageState","title":"StorageState (<code>string</code> alias)","text":"<p> (Appears on:Storage, StorageDrive, StorageVolume) </p> <p>StorageState represents Storage states</p> Value Description <p>\"Absent\"</p> <p>StorageStateAbsent indicates that the storage device is absent.</p> <p>\"Disabled\"</p> <p>StorageStateDisabled indicates that the storage device is disabled.</p> <p>\"Enabled\"</p> <p>StorageStateEnabled indicates that the storage device is enabled.</p>"},{"location":"bare-metal-management/components/metal-operator/api-reference/api/#metal.ironcore.dev/v1alpha1.StorageVolume","title":"StorageVolume","text":"<p> (Appears on:Storage) </p> <p>StorageVolume defines the details of one storage volume</p> Field Description <code>name</code>  string  <p>Name is the name of the storage interface.</p> <code>capacity</code>  k8s.io/apimachinery/pkg/api/resource.Quantity  <p>Capacity specifies the size of the storage device in bytes.</p> <code>state</code>  StorageState  <p>Status specifies the status of the volume.</p> <code>raidType</code>  string  <p>RAIDType specifies the RAID type of the associated Volume.</p> <code>volumeUsage</code>  string  <p>VolumeUsage specifies the volume usage type for the Volume.</p> <p> Generated with <code>gen-crd-api-reference-docs</code> </p>"},{"location":"bare-metal-management/components/metal-operator/concepts/bmcs/","title":"BMCs","text":"<p>The BMC Custom Resource Definition (CRD) represents a Baseboard Management Controller.  It is designed to manage and monitor the state of BMC devices and the systems (servers) they control. The primary  purpose of the BMC resource is to reconcile the BMC state and detect all systems it manages by creating the  corresponding <code>Server</code> resources.</p>"},{"location":"bare-metal-management/components/metal-operator/concepts/bmcs/#example-bmc-resource","title":"Example BMC Resource","text":"<p>Using <code>endpointRef</code>:</p> <pre><code>apiVersion: metal.ironcore.dev/v1alpha1\nkind: BMC\nmetadata:\n  name: my-bmc\nspec:\n  endpointRef:\n    name: my-bmc-endpoint\n  bmcSecretRef:\n    name: my-bmc-secret\n  protocol:\n    name: Redfish\n    port: 8000\n    scheme: http\n  consoleProtocol:\n    name: SSH\n    port: 22\n</code></pre> <p>Using inline <code>endpoint</code>:</p> <pre><code>apiVersion: metal.ironcore.dev/v1alpha1\nkind: BMC\nmetadata:\n  name: my-bmc-inline\nspec:\n  access:\n    macAddress: \"00:1A:2B:3C:4D:5E\"\n    ip: \"192.168.100.10\"\n  bmcSecretRef:\n    name: my-bmc-secret\n  protocol:\n    name: Redfish\n    port: 8000\n  consoleProtocol:\n    name: SSH\n    port: 22\n</code></pre>"},{"location":"bare-metal-management/components/metal-operator/concepts/bmcs/#usage","title":"Usage","text":"<p>The BMC CRD is essential for managing and monitoring BMC devices. It is used to:</p> <ul> <li>Reconcile BMC State: Continuously monitor the BMC's status and update its state.</li> <li>Detect Managed Systems: Identify all systems (servers) managed by the BMC and create corresponding <code>Server</code> resources.</li> <li>Automate Hardware Management: Enable automated power control, firmware updates, and health monitoring of physical servers through the BMC.</li> </ul>"},{"location":"bare-metal-management/components/metal-operator/concepts/bmcs/#reconciliation-process","title":"Reconciliation Process","text":"<p>The <code>BMCReconciler</code> is a controller that processes BMC resources to:</p> <ol> <li> <p>Access BMC Device: Uses the <code>endpointRef</code> or <code>endpoint</code>, along with <code>bmcSecretRef</code>, to establish a connection  with the BMC using the specified <code>protocol</code>.</p> </li> <li> <p>Retrieve BMC Information: Gathers details such as manufacturer, model, serial number, firmware version, and  power state.</p> </li> <li> <p>Update BMCStatus: Populates the <code>status</code> field of the BMC resource with the retrieved information.</p> </li> <li> <p>Detect Managed Systems: Identifies all systems (servers) that the BMC manages.</p> </li> <li> <p>Create Server Resources: For each detected system, the <code>BMCReconciler</code> creates a corresponding <code>Server</code> resource to represent the physical server.</p> </li> </ol>"},{"location":"bare-metal-management/components/metal-operator/concepts/bmcsecrets/","title":"BMCSecrets","text":"<p>The <code>BMCSecret</code> Custom Resource Definition (CRD) is a Kubernetes resource used to store sensitive credentials required  to access a Baseboard Management Controller (BMC). This resource holds the <code>username</code> and <code>password</code> needed for  authentication with the BMC devices. The <code>BMCSecret</code> is utilized by the <code>BMCReconciler</code> to construct clients that  interact with BMCs.</p>"},{"location":"bare-metal-management/components/metal-operator/concepts/bmcsecrets/#example-bmcsecret-resource","title":"Example BMCSecret Resource","text":"<p>An example of how to define an <code>BMCSecret</code> resource:</p> <pre><code>apiVersion: v1alpha1\nkind: BMCSecret\nmetadata:\n  name: my-bmc-secret\nstringData:\n  username: admin\n  password: supersecretpassword\ntype: Opaque\n</code></pre>"},{"location":"bare-metal-management/components/metal-operator/concepts/bmcsecrets/#usage","title":"Usage","text":"<p>The <code>BMCSecret</code> resource is essential for securely managing credentials required to access BMC devices. It is used by  the <code>BMCReconciler</code> to:</p> <ul> <li>Construct BMC Clients: Utilize the credentials to authenticate and establish connections with BMC devices.</li> <li>Automate Hardware Management: Enable automated operations such as power control, firmware updates, and  health monitoring by authenticating with the BMC.</li> </ul>"},{"location":"bare-metal-management/components/metal-operator/concepts/bmcsecrets/#credential-sources","title":"Credential Sources","text":"<ul> <li>Endpoint-Based Discovery: When BMCs are discovered through an <code>Endpoint</code> resource and a MAC Prefix Database,  the credentials (<code>username</code> and <code>password</code>) are derived automatically based on the MAC address prefixes.</li> <li>Manual Configuration: Users can manually create BMCSecret resources with the required credentials to interact with specific BMCs.</li> </ul>"},{"location":"bare-metal-management/components/metal-operator/concepts/bmcsecrets/#reconciliation-process","title":"Reconciliation Process","text":"<p>The <code>BMCReconciler</code> uses the <code>bmcSecretRef</code> field in the BMC resource's specification to reference the corresponding <code>BMCSecret</code>. It retrieves the credentials from the BMCSecret to authenticate with the BMC device.</p>"},{"location":"bare-metal-management/components/metal-operator/concepts/endpoints/","title":"Endpoints","text":"<p>The Endpoint Custom Resource Definition (CRD) is a Kubernetes resource used to represent and identify devices or  entities within an out-of-band (OOB) network. It serves as a means to catalog and manage devices such as Baseboard  Management Controllers (BMCs) by capturing their unique identifiers, specifically the MAC address and IP address.  The <code>EndpointReconciler</code> leverages this information to determine the nature of the device, its vendor, and any initial  credentials required for further interactions.</p>"},{"location":"bare-metal-management/components/metal-operator/concepts/endpoints/#example-endpoint-resource","title":"Example Endpoint Resource","text":"<p>An example of how to define an Endpoint resource:</p> <pre><code>apiVersion: metal.ironcore.dev/v1alpha1\nkind: Endpoint\nmetadata:\n  name: device-12345\nspec:\n  macAddress: \"00:1A:2B:3C:4D:5E\"\n  ip: \"192.168.100.10\"\n</code></pre>"},{"location":"bare-metal-management/components/metal-operator/concepts/endpoints/#mac-prefix-database-and-endpointreconciler-configuration","title":"MAC Prefix Database and EndpointReconciler Configuration","text":"<p>The <code>EndpointReconciler</code> can be configured with a MAC Prefix Database to determine the characteristics of devices based on their MAC addresses. This database maps MAC address prefixes to device information such as the manufacturer,  protocol, port, type, default credentials, and console settings.</p>"},{"location":"bare-metal-management/components/metal-operator/concepts/endpoints/#configuration","title":"Configuration","text":"<p>The MAC Prefix Database is typically configured using a YAML file, which is passed to the <code>metal-operator</code> using the  <code>--mac-prefixes-file</code> flag. This file contains mappings of MAC address prefixes to device specifications.</p> <p>Example YAML Configuration:</p> <pre><code>macPrefixes:\n  - macPrefix: \"23\"\n    manufacturer: \"Foo\"\n    protocol: \"Redfish\"\n    port: 8000\n    type: \"bmc\"\n    defaultCredentials:\n      - username: \"foo\"\n        password: \"bar\"\n    console:\n      type: \"ssh\"\n      port: 22\n</code></pre> <p>Key Fields:</p> <ul> <li>macPrefix (<code>string</code>): The prefix of the MAC address used to identify the device manufacturer or type.</li> <li>manufacturer (<code>string</code>): The name of the device manufacturer.</li> <li>protocol (<code>string</code>): The communication protocol used (e.g., <code>Redfish</code>).</li> <li>port (<code>int</code>): The network port used for communication.</li> <li>type (<code>string</code>): The type of device (e.g., <code>bmc</code>).</li> <li>defaultCredentials (<code>list</code>): A list of default credentials for accessing the device.<ul> <li>username (<code>string</code>): The default username.</li> <li>password (<code>string</code>): The default password.</li> </ul> </li> <li>console (<code>dict</code>): Console access configuration.<ul> <li>type (string): The console protocol (e.g., ssh).</li> <li>port (int): The port used for console access.</li> </ul> </li> </ul>"},{"location":"bare-metal-management/components/metal-operator/concepts/endpoints/#using-mac-prefixes-file-flag","title":"Using <code>--mac-prefixes-file</code> Flag","text":"<p>The <code>metal-operator</code> accepts the <code>--mac-prefixes-file</code> flag to specify the path to the MAC Prefix Database YAML file:</p> <pre><code>metal-operator --mac-prefixes-file /path/to/mac_prefixes.yaml\n</code></pre>"},{"location":"bare-metal-management/components/metal-operator/concepts/endpoints/#reconciliation-process","title":"Reconciliation Process","text":"<ol> <li> <p>MAC Address Matching: When the <code>EndpointReconciler</code> processes an <code>Endpoint</code> resource, it extracts the <code>macAddress</code> from the <code>spec</code>.</p> </li> <li> <p>Prefix Lookup: It compares the MAC address prefix against the entries in the MAC Prefix Database.</p> </li> <li> <p>Device Identification: If a matching prefix is found, the device is identified with the associated manufacturer,  type, and protocol.</p> </li> <li> <p>Credential Assignment: The default credentials specified in the database are used for initial authentication with  the device.</p> </li> <li> <p>BMC and BMCSecret Creation: When the <code>EndpointReconciler</code> detects that the device is a Baseboard Management Controller (<code>type: \"bmc\"</code>), it automatically creates a <code>BMC</code> and a <code>BMCSecret</code> object using the data from the MAC Prefix Database. These objects are used to manage and authenticate with the BMC device.</p> </li> <li> <p>Configuration Application: Additional settings such as console access and communication ports are applied based  on the database entries.</p> </li> </ol>"},{"location":"bare-metal-management/components/metal-operator/concepts/serverbootconfigurations/","title":"ServerBootConfigurations","text":"<p>The <code>ServerBootConfiguration</code> Custom Resource Definition (CRD) is a Kubernetes resource used to signal the need to  initiate a boot process for a bare metal server. It serves as an indicator for external components responsible for  configuring network boot environments, such as PXE or HTTPBoot servers. The <code>ServerBootConfiguration</code> resource allows  the <code>metal-operator</code> to delegate the boot preparation process to third-party operators like the  <code>boot-operator</code> or tools like OpenStack Ironic.</p>"},{"location":"bare-metal-management/components/metal-operator/concepts/serverbootconfigurations/#example-serverbootconfiguration-resource","title":"Example ServerBootConfiguration Resource","text":"<pre><code>apiVersion: metal.ironcore.dev/v1alpha1\nkind: ServerBootConfiguration\nmetadata:\n  name: my-server-boot-config\n  namespace: defauilt\nspec:\n  serverRef:\n    name: my-server\n  image: my-osimage:latest\n  ignitionSecretRef:\n    name: my-ignition-secret\n</code></pre>"},{"location":"bare-metal-management/components/metal-operator/concepts/serverbootconfigurations/#integration-with-third-party-components","title":"Integration with Third-Party Components","text":"<p>The actual preparation of the boot environment is performed by external components, which may include: - boot-operator: A custom operator that handles boot environment preparation as part of the IronCore project. - OpenStack Ironic: A service for managing and provisioning bare metal servers.</p> <p>These components watch for <code>ServerBootConfiguration</code> resources and perform the necessary actions to set up the boot  environment according to the specifications provided.</p>"},{"location":"bare-metal-management/components/metal-operator/concepts/serverbootconfigurations/#why-externalizing-the-boot-preparation-to-a-third-party","title":"Why externalizing the boot preparation to a Third-Party?","text":"<p>Separation of Concerns: By abstracting the boot preparation into a separate resource, the <code>metal-operator</code>  remains agnostic to the specifics of the boot process, allowing for flexibility in different deployment scenarios.</p> <p>Custom Implementations: Users can implement their own components to handle the <code>ServerBootConfiguration</code>, enabling  integration with various provisioning systems or custom workflows.</p>"},{"location":"bare-metal-management/components/metal-operator/concepts/serverbootconfigurations/#reconciliation-process","title":"Reconciliation Process","text":"<p>The <code>ServerReconciler</code> checks the <code>ServerBootConfiguration</code> status before powering on the server. Servers are not  powered on until the boot environment is confirmed to be <code>ready</code>.</p>"},{"location":"bare-metal-management/components/metal-operator/concepts/serverclaims/","title":"ServerClaims","text":"<p>The <code>ServerClaim</code> Custom Resource Definition (CRD) is a Kubernetes resource used to claim ownership of a bare metal  <code>Server</code> resource that is in the <code>Available</code> state. It allows users to specify the desired  operating system image and ignition configuration for booting the server. The <code>ServerClaimReconciler</code> handles the  allocation of servers to claims and manages the lifecycle of the claim and the server.</p>"},{"location":"bare-metal-management/components/metal-operator/concepts/serverclaims/#example-serverclaim-resource","title":"Example ServerClaim Resource","text":"<p>Claiming a Specific Server with Ignition Configuration:</p> <pre><code>apiVersion: metal.ironcore.dev/v1alpha1\nkind: ServerClaim\nmetadata:\n  name: my-server-claim\n  namespace: default\nspec:\n  power: \"On\"\n  serverRef:\n    name: \"my-server\"\n  image: \"my-osimage:latest\"\n  ignitionSecretRef:\n    name: \"my-ignition-secret\"\n</code></pre> <p>Claiming a Server Using a Selector:</p> <pre><code>apiVersion: metal.ironcore.dev/v1alpha1\nkind: ServerClaim\nmetadata:\n  name: selector-server-claim\n  namespace: default\nspec:\n  power: \"On\"\n  serverSelector:\n    matchLabels:\n      hardwareType: gpu-node\n      location: datacenter-1\n  image: my-osimage:latest\n  ignitionSecretRef:\n    name: my-ignition-secret\n</code></pre>"},{"location":"bare-metal-management/components/metal-operator/concepts/serverclaims/#reconciliation-process","title":"Reconciliation Process","text":"<ul> <li> <p><code>ServerBootConfiguration</code>:</p> <ul> <li>The <code>ServerClaimReconciler</code> creates a <code>ServerBootConfiguration</code> resource under the hood.</li> <li>This resource specifies how the server should be booted, including the image and ignition configuration.</li> </ul> </li> <li> <p>State Transitions:</p> <ul> <li>Available \u2192 Reserved: When a server is successfully claimed.</li> <li>Reserved \u2192 Cleanup: When the <code>ServerClaim</code> is deleted.</li> <li>Cleanup \u2192 Available: After cleanup tasks are completed.</li> </ul> </li> <li> <p>Cleanup Process:</p> <ul> <li>Ensures that servers are sanitized before being made available again.</li> <li>Tasks may include wiping disks, resetting BIOS settings, and clearing configurations.</li> </ul> </li> </ul>"},{"location":"bare-metal-management/components/metal-operator/concepts/servermaintenance/","title":"ServerMaintenance","text":"<p><code>ServerMaintenance</code> represents a maintenance operation for a physical server. It transitions a <code>Server</code> from its  current operational state (e.g., Available/Reserved) into a Maintenance state. Each <code>ServerMaintenance</code> object tracks the lifecycle of a maintenance task, ensuring servers are properly taken offline, updated, and restored.</p>"},{"location":"bare-metal-management/components/metal-operator/concepts/servermaintenance/#key-points","title":"Key Points","text":"<ul> <li><code>ServerMaintenance</code> is namespaced and may represent various maintenance operations.</li> <li>Only one <code>ServerMaintenance</code> can be active per <code>Server</code> at a time. Others remain pending.</li> <li>When the active <code>ServerMaintenance</code> completes, the next pending one (if any) starts.</li> <li>If no more maintenance tasks are pending, the <code>Server</code> returns to its previous operational state.</li> <li><code>policy</code> determines how maintenance starts:<ul> <li>OwnerApproval: Requires a label (e.g., <code>ok-to-maintenance: \"true\"</code>) on the <code>ServerClaim</code>.</li> <li>Enforced: Does not require owner approval.</li> </ul> </li> </ul>"},{"location":"bare-metal-management/components/metal-operator/concepts/servermaintenance/#workflow","title":"Workflow","text":"<ol> <li>A separate operator (e.g., <code>foo-maintenance-operator</code>) or user creates a <code>ServerMaintenance</code> resource referencing a     specific <code>Server</code>.</li> <li>If a <code>Server</code> is claimed, a label <code>metal.ironcore.dev/maintanence-needed: \"true\"</code> is added to the <code>ServerClaim</code>.</li> <li>If <code>policy</code> is <code>OwnerApproval</code> and no <code>ok-to-maintenance</code> label is set on the <code>ServerClaim</code>, the <code>ServerMaintenance</code>    stays in <code>Pending</code>. The <code>Server</code> also remains unchanged.</li> <li>If <code>policy</code> is <code>OwnerApproval</code> and the <code>ok-to-maintenance</code> label is present (or if <code>alwaysPerformMaintenance</code> is     enabled), or if the policy is <code>Enforced</code>, the <code>metal-operator</code> transitions the <code>Server</code> into <code>Maintenance</code> and     updates the <code>ServerMaintenance</code> state accordingly.</li> <li>The <code>ServerMaintenanceReconciler</code> creates a <code>ServerBootConfiguration</code> out of the <code>ServerMaintenance</code>'s     <code>ServerBootConfigurationTemplate</code> and applies it to the <code>Server</code>. The power state of the <code>Server</code> can set by providing the    <code>ServerPower</code> field in the <code>ServerMaintenance</code> object. Once the maintenance task is complete, the maintenance operator    sets the <code>ServerMaintenance</code> state to <code>Completed</code>.</li> <li>(optional) In case no <code>ServerBootConfigurationTemplate</code> is provided, the maintenance operator powers off the <code>Server</code>,     applies a <code>ServerBootConfiguration</code> (if needed), performs the maintenance, and sets <code>ServerMaintenance</code> to <code>Completed</code>.</li> <li>The <code>metal-operator</code> transitions the <code>Server</code> back to its prior state. If additional <code>ServerMaintenance</code> objects are    pending, the next one is processed.</li> </ol>"},{"location":"bare-metal-management/components/metal-operator/concepts/servermaintenance/#example","title":"Example","text":"<pre><code>apiVersion: metal.ironcore.dev/v1alpha1\nkind: ServerMaintenance\nmetadata:\n  name: bios-update\n  namespace: ops\n  annotations:\n    metal.ironcore.dev/reason: \"BIOS update\"\nspec:\n  policy: OwnerApproval\n  serverRef:\n    name: server-foo\n  serverPower: On # or Off\n  serverBootConfigurationTemplate:\n    name: bios-update-config\n    spec:\n      image: \"bios-update-image\"\n      serverRef:\n        name: server-foo\n      ignitionSecretRef:\n        name: bios-update-ignition\nstatus:\n  state: Pending\n</code></pre> <p>If <code>policy: OwnerApproval</code> and no <code>ok-to-maintenance</code> label exists on the <code>ServerClaim</code>, this <code>ServerMaintenance</code>  remains <code>Pending</code>, and the <code>Server</code> stays as is. Once the label is added (or if the operator setting  <code>alwaysPerformMaintenance</code> is enabled), the <code>metal-operator</code> transitions the <code>Server</code> to <code>Maintenance</code>, and the  maintenance operator performs the maintenance task.</p>"},{"location":"bare-metal-management/components/metal-operator/concepts/servers/","title":"Servers","text":"<p>The <code>Server</code> Custom Resource Definition (CRD) represents a bare metal server. It manages the state and lifecycle of  physical servers, enabling automated hardware management tasks such as power control, BIOS configuration, and  firmware updates. Interaction with a <code>Server</code> resource is facilitated through its associated Baseboard Management  Controller (BMC), either by referencing a <code>BMC</code> resource or by providing direct BMC configuration.</p>"},{"location":"bare-metal-management/components/metal-operator/concepts/servers/#example-server-resource","title":"Example Server Resource","text":"<pre><code>apiVersion: metal.ironcore.dev/v1alpha1\nkind: Server\nmetadata:\n  name: my-server\nspec:\n  uuid: \"123e4567-e89b-12d3-a456-426614174000\"\n  power: \"Off\"\n  bmcRef:\n    name: my-bmc\n  bootOrder:\n    - name: PXE\n      priority: 1\n      device: Network\n  BIOS:\n    - version: \"1.0.3\"\n      settings:\n        BootMode: UEFI\n        Virtualization: Enabled\n</code></pre>"},{"location":"bare-metal-management/components/metal-operator/concepts/servers/#usage","title":"Usage","text":"<p>The <code>Server</code> CRD is central to managing bare metal servers. It allows for:</p> <ul> <li>Power Management: Powering servers on and off.</li> <li>BIOS Configuration: Changing BIOS settings and performing BIOS updates.</li> <li>Lifecycle Management: Handling the server's lifecycle through various states.</li> <li>Hardware Discovery: Gathering hardware information via BMC and in-band agents.</li> </ul>"},{"location":"bare-metal-management/components/metal-operator/concepts/servers/#lifecycle-and-states","title":"Lifecycle and States","text":"<p>A server undergoes the following phases:</p> <ol> <li> <p>Initial: The server object is created; hardware details are not yet known.</p> </li> <li> <p>Discovery:</p> <ul> <li>The <code>ServerReconciler</code> interacts with the BMC to retrieve hardware details.</li> <li>An initial boot is performed using a predefined ignition configuration.</li> <li>An agent called <code>metalprobe</code> runs on the server to collect additional data (e.g., network interfaces, disks).</li> <li>The collected data is reported back to the <code>metal-operator</code> and added to the <code>ServerStatus</code>.`</li> </ul> </li> <li> <p>Available: The server has completed discovery and is ready for use.</p> </li> <li> <p>Reserved:</p> <ul> <li>A <code>ServerClaim</code> resource is created to claim the server.</li> <li>The server transitions to the <code>Reserved</code> state.</li> <li>The server is allocated for a specific use or user.</li> </ul> </li> <li> <p>Cleanup:</p> <ul> <li>When the <code>ServerClaim</code> is removed, the server enters the Cleanup state.</li> <li>Sanitization processes are performed (e.g., wiping disks, resetting BIOS settings).</li> </ul> </li> <li> <p>Maintenance:</p> <ul> <li>Servers in the <code>Available</code> state can transition to <code>Maintenance</code>.</li> <li>Maintenance tasks such as BIOS updates or hardware repairs are performed.</li> </ul> </li> <li> <p>Error:</p> <ul> <li>The server has encountered an error.</li> <li>Requires intervention to resolve issues before it can return to <code>Available</code>.</li> </ul> </li> </ol> <p>The state diagram below represents the various server states and their transitions:</p> <pre><code>stateDiagram-v2\n    [*] --&gt; Initial\n    Initial --&gt; Discovery : Server object created\n    Discovery --&gt; Available : Discovery complete\n    Available --&gt; Reserved : ServerClaim created\n    Reserved --&gt; Cleanup : ServerClaim removed\n    Cleanup --&gt; Available : Cleanup complete\n    Available --&gt; Maintenance : Maintenance initiated\n    Maintenance --&gt; Available : Maintenance complete\n    Available --&gt; Error : Error detected\n    Reserved --&gt; Error : Error detected\n    Discovery --&gt; Error : Error detected\n    Cleanup --&gt; Error : Error detected\n    Maintenance --&gt; Error : Error detected\n    Error --&gt; Maintenance : Enter maintenance to fix error\n    Error --&gt; Available : Error resolved</code></pre>"},{"location":"bare-metal-management/components/metal-operator/concepts/servers/#interaction-with-bmc","title":"Interaction with BMC","text":"<p>Interaction with a server is done through its BMC:</p> <p>Via Reference: Reference a <code>BMC</code> resource using <code>bmcRef</code>.</p> <pre><code>apiVersion: metal.ironcore.dev/v1alpha1\nkind: Server\nmetadata:\n  name: server-with-bmc-ref\nspec:\n  uuid: \"123e4567-e89b-12d3-a456-426614174000\"\n  power: \"On\"\n  bmcRef:\n    name: my-bmc\n  bootOrder:\n    - name: PXE\n      priority: 1\n      device: Network\n  BIOS:\n    - version: \"1.0.3\"\n      settings:\n        BootMode: UEFI\n        HyperThreading: Enabled\n</code></pre> <p>Inline Configuration: Use the <code>bmc</code> field to provide direct BMC access details.</p> <pre><code>apiVersion: v1alpha1\nkind: BMC\nmetadata:\n  name: my-bmc\nspec:\n  endpointRef:\n    name: my-bmc-endpoint\n  bmcSecretRef:\n    name: my-bmc-secret\n  protocol:\n    name: Redfish\n    port: 8000\n  consoleProtocol:\n    name: SSH\n    port: 22\n</code></pre>"},{"location":"bare-metal-management/components/metal-operator/development/dev_docs/","title":"metal-operator documentation","text":""},{"location":"bare-metal-management/components/metal-operator/development/dev_docs/#local-dev-setup","title":"Local dev setup","text":"<p>You can run the documentation via:</p> <pre><code>make startdocs\n</code></pre> <p>You can remove the <code>mkdocs</code> container image by running:</p> <pre><code>make cleandocs\n</code></pre>"},{"location":"bare-metal-management/components/metal-operator/development/dev_setup/","title":"Local Dev Setup","text":""},{"location":"bare-metal-management/components/metal-operator/development/dev_setup/#prerequisites","title":"Prerequisites","text":"<ul> <li>go version v1.22.0+</li> <li>docker version 17.03+.</li> <li>kubectl version v1.28.0+.</li> </ul>"},{"location":"bare-metal-management/components/metal-operator/development/dev_setup/#overview","title":"Overview","text":"<p>The <code>metal-operator</code> is leveraging envtest to conduct and run unit test suites. Additionally, it is using the Redfish Mock Server to run a local mock Redfish instance to simulate operations performed by various reconcilers.</p> <pre><code>graph TD\n    A[Kubernetes Controller Runtime Based Reconcilers] --&gt;|Interacts with| B[envtest Kube-apiserver Environment]\n    A --&gt;|Interacts with| C[Redfish Mock Server]\n    C --&gt;|Runs as a| D[Docker Container]</code></pre>"},{"location":"bare-metal-management/components/metal-operator/development/dev_setup/#run-the-local-test-suite","title":"Run the local test suite","text":"<p>The local test suite can be run via </p> <pre><code>make test\n</code></pre> <p>This <code>Makefile</code> directive will start under the hood the Redfish mock server, instantiate the <code>envtest</code> environment and run <code>go test ./...</code> on the whole project.</p>"},{"location":"bare-metal-management/components/metal-operator/development/dev_setup/#startstop-redfish-mock-server","title":"Start/Stop Redfish Mock Server","text":"<p>The Redfish mock server can be started and stopped with the following command</p> <pre><code>make startbmc\nmake stopbmc\n</code></pre>"},{"location":"bare-metal-management/components/metal-operator/development/dev_setup/#run-the-local-tilt-development-environment","title":"Run the local Tilt development environment","text":""},{"location":"bare-metal-management/components/metal-operator/development/dev_setup/#prerequisites_1","title":"Prerequisites","text":"<ul> <li>Tilt v0.33.17+</li> <li>Kind v0.23.0+</li> </ul> <p>The local development environment can be started via</p> <pre><code>make tilt-up\n</code></pre> <p>This <code>Makefile</code> directive will: - create a local Kind cluster with local registry - install cert-manager - install boot-operator to reconcile the <code>ServerBootConfiguration</code> CRD - start the <code>metal-operator</code> controller and Redfish mock server as a sidecar container - an Endpoint resource is created to point to the Redfish mock server - this will result in <code>Server</code> resources being created and reconciled by the <code>metal-operator</code></p> <pre><code>\u2039kind-metal\u203a kubectl get server\nNAME                            UUID                                   MANUFACTURER   POWERSTATE   STATE       AGE\ncompute-0-bmc-endpoint-sample   38947555-7742-3448-3784-823347823834   Contoso        On           Available   3m21s\n</code></pre> <p>The local development environment can be deleted via</p> <pre><code>make kind-delete\n</code></pre>"},{"location":"bare-metal-management/components/metal-operator/usage/installation/","title":"Helm Installation Guide","text":"<p>This guide will help you install the Metal Operator using Helm.</p>"},{"location":"bare-metal-management/components/metal-operator/usage/installation/#prerequisites","title":"Prerequisites","text":"<ul> <li>Kubernetes cluster (v1.16+)</li> <li>Helm (v3.0.0+)</li> </ul>"},{"location":"bare-metal-management/components/metal-operator/usage/installation/#steps","title":"Steps","text":"<ol> <li>Install the Chart</li> </ol> <p>Install the Metal Operator chart with the default values.</p> <pre><code>helm install metal-operator dist/chart\n</code></pre> <p>To customize the installation, you can override the default values using a <code>values.yaml</code> file or the <code>--set</code> flag.</p> <pre><code>helm install metal-operator dist/chart -f /path/to/your/values.yaml\n</code></pre> <ol> <li>Verify the Installation</li> </ol> <p>Check the status of the Helm release to ensure that the Metal Operator is installed successfully.</p> <pre><code>helm status metal-operator\n</code></pre> <p>You should see output indicating that the Metal Operator pods are running.</p>"},{"location":"bare-metal-management/components/metal-operator/usage/installation/#configuration","title":"Configuration","text":"<p>The <code>values.yaml</code> file allows you to configure various aspects of the Metal Operator. Below are some of the key configurations:</p>"},{"location":"bare-metal-management/components/metal-operator/usage/installation/#controller-manager","title":"Controller Manager","text":"Key Description Default Value <code>controllerManager.replicas</code> Number of replicas for the manager deployment <code>1</code> <code>controllerManager.container.image.repository</code> Image repository for the manager container <code>registry/metal-operator</code> <code>controllerManager.container.image.tag</code> Image tag for the manager container <code>\"v0.1.0\"</code> <code>controllerManager.container.args</code> Arguments for the manager container <code>--probe-image=probe-image</code>, <code>--probe-os-image=probe-os-image</code>, <code>--registry-url=registry-url</code> <code>controllerManager.container.resources</code> Resource requests and limits for the manager container <code>{cpu: 500m, memory: 128Mi}</code> (limits), <code>{cpu: 10m, memory: 64Mi}</code> (requests) <code>controllerManager.container.livenessProbe</code> Liveness probe configuration for the manager container <code>{initialDelaySeconds: 15, periodSeconds: 20, httpGet: {path: /healthz, port: 8081}}</code> <code>controllerManager.container.readinessProbe</code> Readiness probe configuration for the manager container <code>{initialDelaySeconds: 5, periodSeconds: 10, httpGet: {path: /readyz, port: 8081}}</code> <code>controllerManager.container.securityContext</code> Security context for the manager container <code>{allowPrivilegeEscalation: false, capabilities: {drop: [\"ALL\"]}}</code> <code>controllerManager.securityContext</code> Security context for the manager pod <code>{runAsNonRoot: true, seccompProfile: {type: RuntimeDefault}}</code> <code>controllerManager.terminationGracePeriodSeconds</code> Termination grace period for the manager pod <code>10</code> <code>controllerManager.serviceAccountName</code> Service account name for the manager pod <code>metal-operator-controller-manager</code> <code>controllerManager.nodeSelector</code> Node selector for the manager pod <code>{kubernetes.io/os: linux, kubernetes.io/arch: arm64}</code> <code>controllerManager.tolerations</code> Tolerations for the manager pod <code>[{key: node-role.kubernetes.io/control-plane, effect: NoSchedule}]</code> <ul> <li>rbac: Enable or disable RBAC.</li> <li>crd: Enable or disable CRDs.</li> <li>metrics: Enable or disable metrics export.</li> <li>webhook: Enable or disable webhooks.</li> <li>prometheus: Enable or disable Prometheus ServiceMonitor.</li> <li>certmanager: Enable or disable cert-manager injection.</li> <li>networkPolicy: Enable or disable NetworkPolicies.</li> </ul> <p>Refer to the <code>values.yaml</code> file for more details on each configuration option.</p>"},{"location":"bare-metal-management/components/metal-operator/usage/installation/#uninstallation","title":"Uninstallation","text":"<p>To uninstall the Metal Operator, run the following command:</p> <pre><code>helm uninstall metal-operator\n</code></pre> <p>This will remove all the resources associated with the Metal Operator.</p>"},{"location":"bare-metal-management/components/metal-operator/usage/installation/#additional-information","title":"Additional Information","text":"<p>For more detailed information, refer to the official documentation and Helm chart repository.</p>"},{"location":"bare-metal-management/components/metal-operator/usage/metalctl/","title":"metalctl","text":""},{"location":"bare-metal-management/components/metal-operator/usage/metalctl/#installation","title":"Installation","text":"<p>Install the <code>metalctl</code> CLI from source without cloning the repository. Requires Go to be installed.</p> <pre><code>go install https://github.com/ironcore-dev/metal-operator/cmd/metalctl@latest\n</code></pre>"},{"location":"bare-metal-management/components/metal-operator/usage/metalctl/#commands","title":"Commands","text":""},{"location":"bare-metal-management/components/metal-operator/usage/metalctl/#console","title":"console","text":"<p>The <code>metalctl console</code> command allows you to access the serial console of a <code>Server</code>.</p> <p>To open a connection to the <code>Servers</code> serial console run</p> <pre><code>metalctl console my-server\n</code></pre> <p>In order to authenticate against the API server you need either to provide a path to a <code>kubeconfig</code> via <code>--kubeconfig</code> or set the <code>KUBECONFIG</code> environment variable by pointing to an effective <code>kubeconfig</code> file.</p> <p>By default, the serial console on <code>ttyS1</code> will be opened. You can override this by setting <code>--serial-console-number</code>.</p> <p>Additionally, you can skip the host validation by providing the <code>--skip-host-key-validation=true</code> flag. If set to <code>false</code> it is possible provide a custom <code>known_hosts</code> file via the <code>--known-hosts-file</code> flag.</p>"},{"location":"bare-metal-management/components/metal-operator/usage/metalctl/#move","title":"move","text":"<p>The <code>metalctl move</code> command allows to move the metal Custom Resources, like e.g. <code>Endpoint</code>, <code>BMC</code>, <code>Server</code>, etc. from one cluster to another.</p> <p>Warning!: Before running <code>metalctl move</code>, the user should take care of preparing the target cluster, including also installing all the required Custom Resources Definitions.</p> <p>You can use:</p> <p><pre><code>metalctl move --source-kubeconfig=\"path-to-source-kubeconfig.yaml\" --target-kubeconfig=\"path-to-target-kubeconfig.yaml\"\n</code></pre> to move the metal Custom Resources existing in all namespaces of the source cluster. In case you want to move the metal Custom Resources defined in a single namespace, you can use the <code>--namespace</code> flag.</p> <p>Status and ownership of a metal Custom Resource is also moved. If a metal Custom Resource present on the source cluster exists on the target cluster with identical specification it won't be moved and no ownership of this object will be set. In case of any errors during the process there will be performed a cleanup and the target cluster will be restored to its previous state.</p> <p>Warning!:  <code>metalctl move</code> has been designed and developed around the bootstrap use case described below, and currently this is the only use case verified .</p> <p>If someone intends to use <code>metalctl move</code> outside of this scenario, it's recommended to set up a custom validation pipeline of it before using the command on a production environment.</p> <p>Also, it is important to notice that move has not been designed for being used as a backup/restore solution and it has several limitation for this scenario, like e.g. the implementation assumes the cluster must be stable while doing the move operation, and possible race conditions happening while the cluster is upgrading, scaling up, remediating etc. has never been investigated nor addressed.</p>"},{"location":"bare-metal-management/components/metal-operator/usage/metalctl/#pivot","title":"Pivot","text":"<p>Pivoting is a process for moving the Custom Resources and install Custom Resource Definitions from a source cluster to a target cluster.</p> <p>This can now be achieved with the following procedure:</p> <ol> <li>Use <code>make install</code> to install the metal Custom Resource Definitions into the target cluster</li> <li>Use <code>metalctl move</code> to move the metal Custom Resources from a source cluster to a target cluster</li> </ol>"},{"location":"bare-metal-management/components/metal-operator/usage/metalctl/#dry-run","title":"Dry run","text":"<p>With <code>--dry-run</code> option you can dry-run the move action by only printing logs without taking any actual actions. Use <code>--verbose</code> flag to enable verbose logging.</p>"},{"location":"bare-metal-management/components/boot-operator/","title":"Boot-Operator Documentation","text":""},{"location":"bare-metal-management/components/boot-operator/#overview","title":"Overview","text":"<p>Boot Operator is a Kubernetes-based project designed to automate the deployment of tools required for booting bare metal servers. It integrates web servers and Kubernetes controllers to manage the entire process of provisioning, booting, and configuring the server.</p>"},{"location":"bare-metal-management/components/boot-operator/#problem-it-solves","title":"Problem It Solves","text":"<p>When a bare metal server boots with a network boot method (e.g., PXE or HTTP boot), it typically contacts a DHCP or proxy DHCP server to obtain the necessary information for booting. The DHCP server then provides the IP address of a TFTP server (for PXE) or a web server (for HTTP boot), along with additional boot parameters.</p> <p>Traditionally, managing these network boot servers requires manual configuration. Boot Operator automates this by incorporating the boot servers into Kubernetes deployments. By leveraging Kubernetes controllers, each machine's boot process is handled declaratively, making it simpler to manage and scale.</p>"},{"location":"bare-metal-management/components/boot-operator/#key-components","title":"Key Components","text":"<p>Boot Operator includes the following key components:</p> <ul> <li> <p>IPXE Boot Server </p> <ul> <li>Handles <code>/ipxe</code> requests  </li> <li>Responds with an iPXE script, which the bare metal server uses to download the necessary OS components  </li> <li>This endpoint is typically called directly by the server during boot and is commonly used in PXE boot scenarios</li> </ul> </li> <li> <p>HTTP Boot Server </p> <ul> <li>Handles <code>/httpboot</code> requests  </li> <li>Returns a JSON response containing the location of the UKI (Unified Kernel Image) that the server should download  </li> <li>The DHCP server extension typically handles the response and sends the UKI image location to the server  </li> <li>Common in modern cloud-native bare metal setups, especially for containers and minimal OS images</li> </ul> </li> <li> <p>Image Proxy Server </p> <ul> <li>Handles <code>/image</code> requests</li> <li>Extracts layers from public OCI (Open Container Initiative) images, with current support for GHCR (GitHub Container Registry) only </li> <li>Downloads specific layers based on the requested URI and image specifications  </li> <li>Example:</li> <li><code>wget http://SERVER_ADDRESS:30007/image?imageName=ghcr.io/ironcore-dev/os-images/gardenlinux&amp;version=1443.10&amp;layerName=application/vnd.ironcore.image.squashfs.v1alpha1.squashfs</code></li> </ul> </li> <li> <p>Ignition Server </p> <ul> <li>Handles <code>/ignition</code> requests  </li> <li>Responds with Ignition configuration content tailored to the client machine, identified by its UUID in the request URL.</li> </ul> </li> </ul> <p>These servers leverage Kubernetes controllers and API objects to manage the boot process and serve requests from bare metal machines. The architecture and specifics of the controllers and API objects are described in the architecture section of the documentation.</p>"},{"location":"bare-metal-management/components/boot-operator/architecture/","title":"Architecture","text":"<p>Boot Operator mainly consists of the a set webservers and controllers working together to fulfill the requirement of the boot process of the Baremetal machines. </p>"},{"location":"bare-metal-management/components/boot-operator/architecture/#kubernetes-api","title":"Kubernetes API","text":"<p>Following are the Kubernetes CR and related controllers used to manage the boot infrastructure of the baremetal servers.</p> <ul> <li> <p>IPXEBootConfig </p> <ul> <li>The purpose of this CR and related controller is to allow users to configure the system to provide customised ipxe-script replies to the requests made by the baremetal servers.</li> <li>It allows users with references tailored ignition content, and customised ipxe-scripts to the related IPXEBootConfig object. </li> <li>There is usually a single IPXEBootConfig object corresponding to each of the baremetal servers. </li> </ul> </li> <li> <p>HTTPBootConfig</p> <ul> <li>The purpose of this CR and related controller is to allow users to configure the system to provide customised httpboot replies to the requests typically made by the DHCP servers. </li> <li>It allows users to reference the ignition content and customised ukiURL. </li> </ul> </li> </ul>"},{"location":"bare-metal-management/components/boot-operator/architecture/#architectural-diagrams","title":"Architectural Diagrams","text":""},{"location":"bare-metal-management/components/boot-operator/architecture/#workflow","title":"Workflow","text":"<p>Although the components of Boot Operator can function independently, this section describes a typical usecases of how they work together. </p> <ul> <li> <p>IPXE Workflow </p> <ul> <li>The IPXE workflow involves a DHCP server (e.g., FeDHCP) and the Boot Operator deployment with the necessary IPXE configuration flags.  </li> <li>When a bare metal server boots with the IPXE network option, it requests the <code>/ipxe</code> endpoint from the IPXE web server within the Boot Operator deployment via dhcp server. The server receives the IPXE script configured in the corresponding <code>IPXEBootConfig</code> object.  </li> <li>The server then fetches the Ignition content from the <code>/ignition</code> endpoint, as specified in the IPXE script and the configured Ignition content for the server.</li> </ul> </li> <li> <p>HTTPBoot Workflow </p> <ul> <li>The HTTPBoot workflow involves a specialized DHCP server (e.g., FeDHCP), the Boot Operator with HTTPBoot configuration enabled, and a UKI OS image hosted on a web server or registry.  </li> <li>When a bare metal server boots with the HTTPBoot option, it contacts the FeDHCP server, which returns the UKI image location from the external web server. FeDHCP internally uses the <code>/httpboot</code> endpoint exposed by the Boot Operator, fetching the required information from the related <code>HTTPBootConfig</code> object.  </li> <li>The server can then retrieve the Ignition content from the <code>/ignition</code> endpoint, as configured for the desired OS.</li> </ul> </li> </ul>"},{"location":"bare-metal-management/components/boot-operator/api-reference/api/","title":"API Reference","text":"<p>Packages:</p> <ul> <li> boot.ironcore.dev/v1alpha1 </li> </ul>"},{"location":"bare-metal-management/components/boot-operator/api-reference/api/#boot.ironcore.dev/v1alpha1","title":"boot.ironcore.dev/v1alpha1","text":"<p>Package v1alpha1 contains API Schema definitions for the settings.gardener.cloud API group</p> <p>Resource Types:</p> <ul><li> HTTPBootConfig </li><li> IPXEBootConfig </li></ul>"},{"location":"bare-metal-management/components/boot-operator/api-reference/api/#boot.ironcore.dev/v1alpha1.HTTPBootConfig","title":"HTTPBootConfig","text":"<p>HTTPBootConfig is the Schema for the httpbootconfigs API</p> Field Description <code>apiVersion</code> string <code> boot.ironcore.dev/v1alpha1 </code> <code>kind</code> string  <code>HTTPBootConfig</code> <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>spec</code>  HTTPBootConfigSpec  <code>systemUUID</code>  string  <p>SystemUUID is the unique identifier (UUID) of the server.</p> <code>ignitionSecretRef</code>  Kubernetes core/v1.LocalObjectReference  <p>IgnitionSecretRef is a reference to the secret containing Ignition configuration.</p> <code>systemIPs</code>  []string  <p>SystemIPs is a list of IP addresses assigned to the server.</p> <code>ukiURL</code>  string  <p>UKIURL is the URL where the UKI (Unified Kernel Image) is hosted.</p> <code>status</code>  HTTPBootConfigStatus"},{"location":"bare-metal-management/components/boot-operator/api-reference/api/#boot.ironcore.dev/v1alpha1.IPXEBootConfig","title":"IPXEBootConfig","text":"<p>IPXEBootConfig is the Schema for the ipxebootconfigs API</p> Field Description <code>apiVersion</code> string <code> boot.ironcore.dev/v1alpha1 </code> <code>kind</code> string  <code>IPXEBootConfig</code> <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>spec</code>  IPXEBootConfigSpec  <code>systemUUID</code>  string  <p>SystemUUID is the unique identifier (UUID) of the server.</p> <code>systemIPs</code>  []string  <p>SystemIPs is a list of IP addresses assigned to the server.</p> <code>image</code>  string  <p>Image is deprecated and will be removed.</p> <code>kernelURL</code>  string  <p>KernelURL is the URL where the kernel of the OS is hosted, eg. the URL to the Kernel layer of the OS OCI image.</p> <code>initrdURL</code>  string  <p>InitrdURL is the URL where the Initrd (initial RAM disk) of the OS is hosted, eg. the URL to the Initrd layer of the OS OCI image.</p> <code>squashfsURL</code>  string  <p>SquashfsURL is the URL where the Squashfs of the OS is hosted, eg.  the URL to the Squashfs layer of the OS OCI image.</p> <code>ipxeServerURL</code>  string  <p>IPXEServerURL is deprecated and will be removed.</p> <code>ignitionSecretRef</code>  Kubernetes core/v1.LocalObjectReference  <p>IgnitionSecretRef is a reference to the secret containing the Ignition configuration.</p> <code>ipxeScriptSecretRef</code>  Kubernetes core/v1.LocalObjectReference  <p>IPXEScriptSecretRef is a reference to the secret containing the custom IPXE script.</p> <code>status</code>  IPXEBootConfigStatus"},{"location":"bare-metal-management/components/boot-operator/api-reference/api/#boot.ironcore.dev/v1alpha1.HTTPBootConfigSpec","title":"HTTPBootConfigSpec","text":"<p> (Appears on:HTTPBootConfig) </p> <p>HTTPBootConfigSpec defines the desired state of HTTPBootConfig</p> Field Description <code>systemUUID</code>  string  <p>SystemUUID is the unique identifier (UUID) of the server.</p> <code>ignitionSecretRef</code>  Kubernetes core/v1.LocalObjectReference  <p>IgnitionSecretRef is a reference to the secret containing Ignition configuration.</p> <code>systemIPs</code>  []string  <p>SystemIPs is a list of IP addresses assigned to the server.</p> <code>ukiURL</code>  string  <p>UKIURL is the URL where the UKI (Unified Kernel Image) is hosted.</p>"},{"location":"bare-metal-management/components/boot-operator/api-reference/api/#boot.ironcore.dev/v1alpha1.HTTPBootConfigState","title":"HTTPBootConfigState (<code>string</code> alias)","text":"<p> (Appears on:HTTPBootConfigStatus) </p> Value Description <p>\"Error\"</p> <p>HTTPBootConfigStateError indicates that an error occurred while processing the HTTPBootConfig.</p> <p>\"Pending\"</p> <p>HTTPBootConfigStatePending indicates that the HTTPBootConfig has not been processed yet.</p> <p>\"Ready\"</p> <p>HTTPBootConfigStateReady indicates that the HTTPBootConfig has been successfully processed, and the next step (e.g., booting the server) can proceed.</p>"},{"location":"bare-metal-management/components/boot-operator/api-reference/api/#boot.ironcore.dev/v1alpha1.HTTPBootConfigStatus","title":"HTTPBootConfigStatus","text":"<p> (Appears on:HTTPBootConfig) </p> <p>HTTPBootConfigStatus defines the observed state of HTTPBootConfig</p> Field Description <code>state</code>  HTTPBootConfigState"},{"location":"bare-metal-management/components/boot-operator/api-reference/api/#boot.ironcore.dev/v1alpha1.IPXEBootConfigSpec","title":"IPXEBootConfigSpec","text":"<p> (Appears on:IPXEBootConfig) </p> <p>IPXEBootConfigSpec defines the desired state of IPXEBootConfig</p> Field Description <code>systemUUID</code>  string  <p>SystemUUID is the unique identifier (UUID) of the server.</p> <code>systemIPs</code>  []string  <p>SystemIPs is a list of IP addresses assigned to the server.</p> <code>image</code>  string  <p>Image is deprecated and will be removed.</p> <code>kernelURL</code>  string  <p>KernelURL is the URL where the kernel of the OS is hosted, eg. the URL to the Kernel layer of the OS OCI image.</p> <code>initrdURL</code>  string  <p>InitrdURL is the URL where the Initrd (initial RAM disk) of the OS is hosted, eg. the URL to the Initrd layer of the OS OCI image.</p> <code>squashfsURL</code>  string  <p>SquashfsURL is the URL where the Squashfs of the OS is hosted, eg.  the URL to the Squashfs layer of the OS OCI image.</p> <code>ipxeServerURL</code>  string  <p>IPXEServerURL is deprecated and will be removed.</p> <code>ignitionSecretRef</code>  Kubernetes core/v1.LocalObjectReference  <p>IgnitionSecretRef is a reference to the secret containing the Ignition configuration.</p> <code>ipxeScriptSecretRef</code>  Kubernetes core/v1.LocalObjectReference  <p>IPXEScriptSecretRef is a reference to the secret containing the custom IPXE script.</p>"},{"location":"bare-metal-management/components/boot-operator/api-reference/api/#boot.ironcore.dev/v1alpha1.IPXEBootConfigState","title":"IPXEBootConfigState (<code>string</code> alias)","text":"<p> (Appears on:IPXEBootConfigStatus) </p> Value Description <p>\"Error\"</p> <p>IPXEBootConfigStateError indicates that an error occurred while processing the IPXEBootConfig.</p> <p>\"Pending\"</p> <p>IPXEBootConfigStatePending indicates that the IPXEBootConfig has not been processed yet.</p> <p>\"Ready\"</p> <p>IPXEBootConfigStateReady indicates that the IPXEBootConfig has been successfully processed, and the next step (e.g., booting the server) can proceed.</p>"},{"location":"bare-metal-management/components/boot-operator/api-reference/api/#boot.ironcore.dev/v1alpha1.IPXEBootConfigStatus","title":"IPXEBootConfigStatus","text":"<p> (Appears on:IPXEBootConfig) </p> <p>IPXEBootConfigStatus defines the observed state of IPXEBootConfig</p> Field Description <code>state</code>  IPXEBootConfigState  <p>Important: Run \u201cmake\u201d to regenerate code after modifying this file</p> <p> Generated with <code>gen-crd-api-reference-docs</code> </p>"},{"location":"bare-metal-management/components/boot-operator/development/create_uki/","title":"Create Sample UKI Image","text":""},{"location":"bare-metal-management/components/boot-operator/development/create_uki/#how-to-generate-a-uki-image-for-httpboot-with-gardenlinux","title":"How to Generate a UKI Image for HTTPBoot with Gardenlinux","text":""},{"location":"bare-metal-management/components/boot-operator/development/create_uki/#step-1-prerequisites","title":"Step 1: Prerequisites","text":"<ul> <li>Ensure you have the <code>ukify</code> tool installed on your system. This tool is essential for creating the UKI image.</li> <li>You will need administrative or root privileges to execute most of the commands described.</li> </ul>"},{"location":"bare-metal-management/components/boot-operator/development/create_uki/#step-2-download-and-prepare-gardenlinux-release","title":"Step 2: Download and Prepare Gardenlinux Release","text":"<ol> <li>Download the appropriate Gardenlinux release for your architecture. For example, a metal-based system with an AMD64 architecture, use the following command:    <pre><code>wget https://github.com/gardenlinux/gardenlinux/releases/download/1443.10/metal-gardener_prod_pxe-amd64-1443.10-8d098305.tar.xz\n</code></pre></li> <li>Extract the downloaded <code>.tar.xz</code> file:    <pre><code>tar -xvf metal-gardener_prod_pxe-amd64-1443.10-8d098305.tar.xz\n</code></pre></li> <li>Further extract the nested <code>*.pxe.tar.gz</code> which contains the kernel and initial RAM disk:    <pre><code>tar -xzf &lt;nested_tar_name&gt;.pxe.tar.gz\n</code></pre>    You should see files like <code>vmlinuz</code>, <code>initrd</code>, and <code>root.squashfs</code>.</li> </ol>"},{"location":"bare-metal-management/components/boot-operator/development/create_uki/#step-3-obtain-the-bootloader-stub","title":"Step 3: Obtain the Bootloader Stub","text":"<p>Download the EFI stub required for the UKI creation: <pre><code>tbd\n</code></pre></p>"},{"location":"bare-metal-management/components/boot-operator/development/create_uki/#step-4-create-the-uki-image","title":"Step 4: Create the UKI Image","text":"<p>Construct the UKI image using the <code>ukify</code> command. Ensure to replace placeholders with actual paths and URLs: <pre><code>ukify build --stub \"/path/to/stub\" --linux \"/path/to/vmlinuz\" --initrd \"/path/to/initrd\" --cmdline \"@cmdline\" --output \"/path/to/output/test.uki\"\n\n# Create file with the name cmdline, with following content\n# Use this as the sample command line, replace URLs and paths as necessary\ninitrd=/path/to/initrd gl.ovl=/:tmpfs gl.live=1 ip=dhcp console=ttyS0,115200 console=tty0 earlyprintk=ttyS0,115200 consoleblank=0 ignition.firstboot=1 ignition.config.url=IGNITION_URL ignition.platform.id=metal gl.url=SQUASHFS_URL\n</code></pre></p>"},{"location":"bare-metal-management/components/boot-operator/development/create_uki/#step-5-deploy-the-image-to-a-server","title":"Step 5: Deploy the Image to a Server","text":"<p>Copy the created <code>test.uki</code> to an Nginx server configured to serve the files: <pre><code>cp /path/to/output/test.uki /path/to/nginx/server/httpboot/test-uki.efi\n# Also, ensure the squashfs file is accessible via HTTP\ncp /path/to/root.squashfs /path/to/nginx/server/httpboot/squashfs\n</code></pre> Ensure EFI files are served by NGINX with the correct content-type. <pre><code> application/efi efi;\n</code></pre></p>"},{"location":"bare-metal-management/components/boot-operator/development/create_uki/#step-6-configure-httpboot","title":"Step 6: Configure HTTPBoot","text":"<p>Create a YAML configuration for the HTTPBoot client. Replace placeholders as required: <pre><code>apiVersion: boot.ironcore.dev/v1alpha1\nkind: HTTPBootConfig\nmetadata:\n  name: httpbootconfig-sample\n  namespace: boot-operator-system\nspec:\n  ignitionSecretRef:\n    name: ignition-http-sample\n    namespace: boot-operator-system\n  systemUUID: \"generate-this-uuid\"\n  systemIPs:\n    - \"1.1.1.1\"\n    - \"ip/mac-address-of-interfaces\"\n  ukiURL: \"http://[your-server-ip-or-domain]/httpboot/test-uki.efi\"\n</code></pre></p> <p>Apply this configuration to your cluster and ensure the metal machine is set to boot via HTTPBoot.</p>"},{"location":"bare-metal-management/components/boot-operator/development/dev_docs/","title":"metal-operator documentation","text":""},{"location":"bare-metal-management/components/boot-operator/development/dev_docs/#local-dev-setup","title":"Local dev setup","text":"<p>You can run the documentation via:</p> <pre><code>make startdocs\n</code></pre> <p>You can remove the <code>mkdocs</code> container image by running:</p> <pre><code>make cleandocs\n</code></pre>"}]}